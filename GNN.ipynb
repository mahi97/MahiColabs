{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPV38sARSCdcVkadOZ1hdRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahi97/MahiColabs/blob/master/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD3l-oiQ40pY"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "1. random, numpy -> simple random arrauys and numbers\n",
        "2. torch -> deseing and optimize GNN\n",
        "3. dgl -> Used to create GNN layers and model\n",
        "4. ray -> Just used for tuning hyper parameters\n",
        "5. networkx -> Generate random graphs \n",
        "6. matplotlib -> Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n39El8omMGEK",
        "outputId": "68c52684-315b-47d8-c60e-b26fde080513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "  \n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import HyperBandScheduler\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "\n",
        "from networkx.generators.random_graphs import erdos_renyi_graph\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhMalAvv5s6Q"
      },
      "source": [
        "### Easy Plotter Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruWHfynykkSl"
      },
      "source": [
        "def plot_me(x):\n",
        "  [plt.plot(l) for l in x]\n",
        "  plt.ylabel('Running Loss')\n",
        "  plt.show()\n",
        "  print([l[-1] for l in x])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V4P2jqa_MM_"
      },
      "source": [
        "# Generating Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkpkFbgS5w6B"
      },
      "source": [
        "### Generate Random Graphs\n",
        "\n",
        "For any number of nodes and probability of edge existance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeT-KEyfpi3E"
      },
      "source": [
        "def generate_random_graph(num_nodes, prob):\n",
        "  g = erdos_renyi_graph(num_nodes, prob)\n",
        "  [g.add_edge(i, i) for i in range(num_nodes)] # add self-loop\n",
        "\n",
        "  # Generate Adj. Matrix of Graph\n",
        "  a = torch.zeros(num_nodes, num_nodes)\n",
        "  for n in g.edges:\n",
        "    a[n[0]][n[1]] = 1.0\n",
        "    a[n[1]][n[0]] = 1.0\n",
        "    a[n[0]][n[0]] = 1.0\n",
        "    a[n[1]][n[1]] = 1.0\n",
        "\n",
        "  # Generate dgl object of graph \n",
        "  u = list(map(lambda x : x[0], g.edges))\n",
        "  v = list(map(lambda x : x[1], g.edges))  \n",
        "  g = dgl.graph((torch.tensor(u), torch.tensor(v)))\n",
        "  g = dgl.add_self_loop(g)\n",
        "\n",
        "  return g, a"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3057gzL6tAn"
      },
      "source": [
        "### Data Loader Function\n",
        "\n",
        "## Generate data dictionary for training GNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbEah08FMPUe"
      },
      "source": [
        "def data_loader(num_batch):\n",
        "  w = torch.Tensor([\n",
        "                  [2.7, 0.0, 1.0],\n",
        "                  [1.2, 1.3, 0.2],\n",
        "                  [0.0, 0.5, 0.0],\n",
        "                  [2.1, 0.0, 1.1],\n",
        "                  [0.0, 0.0, 0.7]])\n",
        "  for i in range(num_batch):\n",
        "    p = random.random()\n",
        "    g, a =  generate_random_graph(10, p)\n",
        "    x = torch.rand(10, 5)\n",
        "    \n",
        "    yield {\n",
        "        'feat': x,\n",
        "        'graph': g,\n",
        "        'label': torch.matmul(torch.matmul(a, x), w)\n",
        "        }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urkid7K7CPOg"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuewvoE5CRNS"
      },
      "source": [
        "##1. GNN With GraphConv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-awJmwNOOR7A"
      },
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, hid2_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.GraphConv(in_feats=in_feats, \n",
        "                                    out_feats=hid_feats) \n",
        "                                    # aggregator_type='mean')\n",
        "        self.conv2 = dglnn.GraphConv(in_feats=hid_feats, \n",
        "                                    out_feats=hid2_feats) \n",
        "        self.conv3 = dglnn.GraphConv(in_feats=hid2_feats, \n",
        "                                    out_feats=out_feats) \n",
        "                                    # aggregator_type='mean')\n",
        "                                    \n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(graph, h)\n",
        "        return h"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQmTBci3637G"
      },
      "source": [
        "## Simple Training Procedure\n",
        "#### Test Function for evaluationg hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PosYck1AkLyH"
      },
      "source": [
        "def test(config):\n",
        "  model = GNN(5, config['h1'], config['h2'], 3)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "\n",
        "  losses = []\n",
        "  running_loss = 0\n",
        "  iter = 0\n",
        "  for i, data in enumerate(data_loader(config['num_batch'])):\n",
        "    model.train()\n",
        "    iter += 1\n",
        "    g = data['graph']\n",
        "    x = data['feat']\n",
        "    labels = data['label']\n",
        "    outputs = model(g, x)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    # optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # print statistics\n",
        "    if i % 500 == 499:\n",
        "        # print(\"[%5d] loss: %.3f\" % (i + 1, running_loss / iter))\n",
        "        losses.append(running_loss / iter)\n",
        "        iter = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "    if i % config['batch_size'] == config['batch_size'] - 1:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "  return losses"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xP4-ezRkMui"
      },
      "source": [
        "l = test({\n",
        "    'h1' : 10,\n",
        "    'h2' : 10,\n",
        "    'lr' : 1e-3,\n",
        "    'momentum' : 0.9,\n",
        "    'num_batch': 50000,\n",
        "    'batch_size': 1\n",
        "})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZMdmk6_kwOl",
        "outputId": "bf1767cc-cf9b-4879-ca62-b0dc0845bb5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_me([l])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[13.15940514755249]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9qwSCWkor_7"
      },
      "source": [
        "# Tuning of Hyper-Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQcVuN8L-lXD"
      },
      "source": [
        "## Ray Tune Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLpKviWqLMc"
      },
      "source": [
        "def train(config):\n",
        "  model = GNN(5, config['h1'], config['h2'], 3)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "\n",
        "\n",
        "  running_loss = 0\n",
        "  final = 0\n",
        "  iter = 0\n",
        "  for i, data in enumerate(data_loader(config['num_batch'])):\n",
        "    model.train()\n",
        "    iter += 1\n",
        "    g = data['graph']\n",
        "    x = data['feat']\n",
        "    labels = data['label']\n",
        "    outputs = model(g, x)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    # optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # print statistics\n",
        "    final = running_loss / iter\n",
        "    # print statistics\n",
        "    if i % 5000 == 4999:\n",
        "        print(\"[%5d] loss: %.3f\" % (i + 1, running_loss / iter))\n",
        "        iter = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "    if i % config['batch_size'] == config['batch_size'] - 1:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "  tune.report(loss=final)\n",
        "  print(\"Finished Training\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhFUxs3-pEW"
      },
      "source": [
        "## Ray Tune Main Scenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0LwcP4gCadc"
      },
      "source": [
        "#### What we tune:\n",
        "\n",
        "1. Number of neurons in first hidden layer (2^n) [1 < n < 8]\n",
        "2. Number of neurons in second hidden layer (2^n) [1 < n < 8] \n",
        "3. Learning Rate [1e-5 < lr < 1e-1]\n",
        "4. Momentum of SGD [0.5 < m < 1]\n",
        "5. Batch Size 10^n [0 < n < 4]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vHrnQPipvcC",
        "outputId": "1d935d05-9bb9-4386-cce8-35c00d094fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_batch=50000\n",
        "num_samples = 100 \n",
        "config = {\n",
        "    \"h1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 8)),\n",
        "    \"h2\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 8)),\n",
        "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
        "    \"num_batch\": num_batch,\n",
        "    \"momentum\": tune.uniform(0.5, 0.99),\n",
        "    \"batch_size\": tune.sample_from(lambda _: 10 ** np.random.randint(0, 4))\n",
        "}\n",
        "\n",
        "hyperband = HyperBandScheduler(metric=\"loss\", mode=\"min\")\n",
        "\n",
        "reporter = CLIReporter(metric_columns=[\"loss\"])\n",
        "\n",
        "result = tune.run(\n",
        "    train,\n",
        "    config=config,\n",
        "    num_samples=num_samples,\n",
        "    scheduler=hyperband,\n",
        "    progress_reporter=reporter\n",
        "    )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:07:36,353\tWARNING tune.py:396 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 5.0/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=0.0%): {PENDING: 4, RUNNING: 1} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=0.0%): {PENDING: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 1/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (99 PENDING, 1 RUNNING)\n",
            "+-------------------+----------+-------+--------------+------+------+-------------+------------+\n",
            "| Trial name        | status   | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |\n",
            "|-------------------+----------+-------+--------------+------+------+-------------+------------|\n",
            "| train_771eb_00001 | PENDING  |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |\n",
            "| train_771eb_00002 | PENDING  |       |           10 |  128 |   32 | 0.0241017   |   0.565936 |\n",
            "| train_771eb_00003 | PENDING  |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |\n",
            "| train_771eb_00004 | PENDING  |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |\n",
            "| train_771eb_00005 | PENDING  |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |\n",
            "| train_771eb_00006 | PENDING  |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |\n",
            "| train_771eb_00007 | PENDING  |       |           10 |    8 |   16 | 0.000309116 |   0.554296 |\n",
            "| train_771eb_00008 | PENDING  |       |          100 |  128 |  128 | 0.00619614  |   0.860599 |\n",
            "| train_771eb_00009 | PENDING  |       |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |\n",
            "| train_771eb_00010 | PENDING  |       |          100 |  128 |   64 | 0.0728514   |   0.720064 |\n",
            "| train_771eb_00011 | PENDING  |       |            1 |   64 |   32 | 0.0333067   |   0.924837 |\n",
            "| train_771eb_00012 | PENDING  |       |         1000 |    8 |   64 | 0.0178356   |   0.838857 |\n",
            "| train_771eb_00013 | PENDING  |       |          100 |  128 |  128 | 0.00109204  |   0.500525 |\n",
            "| train_771eb_00014 | PENDING  |       |            1 |  128 |    8 | 0.000220337 |   0.565689 |\n",
            "| train_771eb_00015 | PENDING  |       |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |\n",
            "| train_771eb_00016 | PENDING  |       |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |\n",
            "| train_771eb_00017 | PENDING  |       |         1000 |   64 |  128 | 0.000423194 |   0.914008 |\n",
            "| train_771eb_00018 | PENDING  |       |          100 |   32 |   32 | 0.00138404  |   0.911168 |\n",
            "| train_771eb_00019 | PENDING  |       |         1000 |   32 |   32 | 0.00037243  |   0.885834 |\n",
            "| train_771eb_00000 | RUNNING  |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |\n",
            "+-------------------+----------+-------+--------------+------+------+-------------+------------+\n",
            "... 80 more trials not shown (80 PENDING)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [ 5000] loss: 37.072\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [ 5000] loss: 37.807\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [ 5000] loss: 120.498\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [ 5000] loss: 35.126\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [ 5000] loss: 25.466\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [ 5000] loss: 84.631\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [ 5000] loss: 38.295\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [ 5000] loss: 31.559\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [ 5000] loss: 41.620\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [10000] loss: 17.916\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [10000] loss: 30.491\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [10000] loss: 82.706\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [10000] loss: 36.220\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [10000] loss: 50.100\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [10000] loss: 12.514\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [10000] loss: 17.212\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [10000] loss: 30.470\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [10000] loss: 40.545\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [15000] loss: 14.958\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [15000] loss: 36.074\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [15000] loss: 36.403\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [15000] loss: 45.609\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [15000] loss: 37.314\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [15000] loss: 13.892\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [15000] loss: 35.568\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [15000] loss: 11.181\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [15000] loss: 39.829\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [20000] loss: 35.834\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [20000] loss: 13.838\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [20000] loss: 43.452\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [20000] loss: 36.690\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [20000] loss: 30.687\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [20000] loss: 12.848\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [20000] loss: 10.194\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [20000] loss: 33.726\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [20000] loss: 40.580\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [25000] loss: 35.763\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [25000] loss: 13.185\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [25000] loss: 40.357\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [25000] loss: 36.267\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [25000] loss: 27.052\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [25000] loss: 12.243\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [25000] loss: 10.192\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [25000] loss: 29.089\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [25000] loss: 40.046\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [30000] loss: 35.395\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [30000] loss: 12.562\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [30000] loss: 25.473\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [30000] loss: 36.415\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [30000] loss: 37.215\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [30000] loss: 11.368\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [30000] loss: 9.883\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [30000] loss: 34.433\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [30000] loss: 40.685\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [35000] loss: 35.807\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [35000] loss: 23.630\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [35000] loss: 12.233\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [35000] loss: 36.229\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [35000] loss: 30.901\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [35000] loss: 11.156\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [35000] loss: 9.651\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [35000] loss: 40.936\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [35000] loss: 35.706\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [40000] loss: 36.625\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [40000] loss: 22.100\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [40000] loss: 11.994\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [40000] loss: 36.306\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [40000] loss: 25.734\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [40000] loss: 11.318\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [40000] loss: 9.495\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [40000] loss: 36.624\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [40000] loss: 40.667\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [45000] loss: 35.708\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [45000] loss: 11.726\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [45000] loss: 21.292\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [45000] loss: 36.563\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [45000] loss: 24.210\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [45000] loss: 11.303\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [45000] loss: 9.336\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [45000] loss: 36.027\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [45000] loss: 39.957\n",
            "Result for train_771eb_00001:\n",
            "  date: 2020-10-18_18-13-44\n",
            "  done: false\n",
            "  experiment_id: 14365bd6542e438a879676d01988ebc5\n",
            "  experiment_tag: 1_batch_size=10,h1=8,h2=8,lr=0.0013267,momentum=0.53589\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.32019715886116\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21602\n",
            "  time_since_restore: 365.8115165233612\n",
            "  time_this_iter_s: 365.8115165233612\n",
            "  time_total_s: 365.8115165233612\n",
            "  timestamp: 1603032224\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00001\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m [50000] loss: 36.320\n",
            "\u001b[2m\u001b[36m(pid=21602)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=-0.2%): {RUNNING: 5} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=0.0%): {PENDING: 1, RUNNING: 7} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (88 PENDING, 12 RUNNING)\n",
            "+-------------------+----------+-------------------+--------------+------+------+-------------+------------+---------+\n",
            "| Trial name        | status   | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |    loss |\n",
            "|-------------------+----------+-------------------+--------------+------+------+-------------+------------+---------|\n",
            "| train_771eb_00012 | PENDING  |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 |         |\n",
            "| train_771eb_00013 | PENDING  |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |         |\n",
            "| train_771eb_00014 | PENDING  |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |         |\n",
            "| train_771eb_00015 | PENDING  |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |         |\n",
            "| train_771eb_00016 | PENDING  |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |         |\n",
            "| train_771eb_00017 | PENDING  |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 |         |\n",
            "| train_771eb_00018 | PENDING  |                   |          100 |   32 |   32 | 0.00138404  |   0.911168 |         |\n",
            "| train_771eb_00019 | PENDING  |                   |         1000 |   32 |   32 | 0.00037243  |   0.885834 |         |\n",
            "| train_771eb_00020 | PENDING  |                   |            1 |   64 |  128 | 0.0628102   |   0.748114 |         |\n",
            "| train_771eb_00021 | PENDING  |                   |          100 |   16 |   64 | 1.2933e-05  |   0.749235 |         |\n",
            "| train_771eb_00000 | RUNNING  |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |         |\n",
            "| train_771eb_00001 | RUNNING  | 192.168.1.4:21602 |           10 |    8 |    8 | 0.00132672  |   0.535895 | 36.3202 |\n",
            "| train_771eb_00002 | RUNNING  |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 |         |\n",
            "| train_771eb_00003 | RUNNING  |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |         |\n",
            "| train_771eb_00004 | RUNNING  |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |         |\n",
            "| train_771eb_00005 | RUNNING  |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |         |\n",
            "| train_771eb_00006 | RUNNING  |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |         |\n",
            "| train_771eb_00007 | RUNNING  |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |         |\n",
            "| train_771eb_00008 | RUNNING  |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 |         |\n",
            "| train_771eb_00009 | RUNNING  |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |         |\n",
            "+-------------------+----------+-------------------+--------------+------+------+-------------+------------+---------+\n",
            "... 80 more trials not shown (78 PENDING, 2 RUNNING)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00007:\n",
            "  date: 2020-10-18_18-13-48\n",
            "  done: false\n",
            "  experiment_id: 7280255dc44b4c0091d5b6bd12886c84\n",
            "  experiment_tag: 7_batch_size=10,h1=8,h2=16,lr=0.00030912,momentum=0.5543\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.52453355102539\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21610\n",
            "  time_since_restore: 370.13042402267456\n",
            "  time_this_iter_s: 370.13042402267456\n",
            "  time_total_s: 370.13042402267456\n",
            "  timestamp: 1603032228\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00007\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m [50000] loss: 11.525\n",
            "\u001b[2m\u001b[36m(pid=21610)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00003:\n",
            "  date: 2020-10-18_18-13-51\n",
            "  done: false\n",
            "  experiment_id: e9e39a7b2b724bfa85ad97225d1565c9\n",
            "  experiment_tag: 3_batch_size=10,h1=32,h2=16,lr=1.2771e-05,momentum=0.83398\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 20.023636805009843\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21598\n",
            "  time_since_restore: 372.1784291267395\n",
            "  time_this_iter_s: 372.1784291267395\n",
            "  time_total_s: 372.1784291267395\n",
            "  timestamp: 1603032231\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00003\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=-0.5%): {RUNNING: 4, TERMINATED: 1} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-0.3%): {RUNNING: 7, TERMINATED: 1} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 14, RUNNING: 1} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (86 PENDING, 12 RUNNING, 2 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+---------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |    loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+---------|\n",
            "| train_771eb_00014 | PENDING    |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |         |\n",
            "| train_771eb_00015 | PENDING    |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |         |\n",
            "| train_771eb_00016 | PENDING    |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |         |\n",
            "| train_771eb_00017 | PENDING    |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 |         |\n",
            "| train_771eb_00018 | PENDING    |                   |          100 |   32 |   32 | 0.00138404  |   0.911168 |         |\n",
            "| train_771eb_00019 | PENDING    |                   |         1000 |   32 |   32 | 0.00037243  |   0.885834 |         |\n",
            "| train_771eb_00020 | PENDING    |                   |            1 |   64 |  128 | 0.0628102   |   0.748114 |         |\n",
            "| train_771eb_00021 | PENDING    |                   |          100 |   16 |   64 | 1.2933e-05  |   0.749235 |         |\n",
            "| train_771eb_00022 | PENDING    |                   |          100 |  128 |   16 | 0.0796555   |   0.920876 |         |\n",
            "| train_771eb_00000 | RUNNING    |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |         |\n",
            "| train_771eb_00002 | RUNNING    |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 |         |\n",
            "| train_771eb_00003 | RUNNING    | 192.168.1.4:21598 |           10 |   32 |   16 | 1.27708e-05 |   0.833976 | 20.0236 |\n",
            "| train_771eb_00004 | RUNNING    |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |         |\n",
            "| train_771eb_00005 | RUNNING    |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |         |\n",
            "| train_771eb_00006 | RUNNING    |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |         |\n",
            "| train_771eb_00008 | RUNNING    |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 |         |\n",
            "| train_771eb_00009 | RUNNING    |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |         |\n",
            "| train_771eb_00010 | RUNNING    |                   |          100 |  128 |   64 | 0.0728514   |   0.720064 |         |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 | 36.3202 |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 | 11.5245 |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+---------+\n",
            "... 80 more trials not shown (77 PENDING, 3 RUNNING)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m [50000] loss: 20.024\n",
            "\u001b[2m\u001b[36m(pid=21598)\u001b[0m Finished Training\n",
            "Result for train_771eb_00006:\n",
            "  date: 2020-10-18_18-13-51\n",
            "  done: false\n",
            "  experiment_id: d1b6682b8ee845c7a4b7a821fc148dbf\n",
            "  experiment_tag: 6_batch_size=10,h1=8,h2=128,lr=0.024702,momentum=0.56093\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.643342893385885\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21618\n",
            "  time_since_restore: 372.81930232048035\n",
            "  time_this_iter_s: 372.81930232048035\n",
            "  time_total_s: 372.81930232048035\n",
            "  timestamp: 1603032231\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00006\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m [50000] loss: 36.643\n",
            "\u001b[2m\u001b[36m(pid=21618)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00009:\n",
            "  date: 2020-10-18_18-13-52\n",
            "  done: false\n",
            "  experiment_id: 95b0453927f74f829ae150282230995c\n",
            "  experiment_tag: 9_batch_size=1000,h1=8,h2=64,lr=2.1502e-05,momentum=0.68913\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 22.64038486329317\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21608\n",
            "  time_since_restore: 373.84846544265747\n",
            "  time_this_iter_s: 373.84846544265747\n",
            "  time_total_s: 373.84846544265747\n",
            "  timestamp: 1603032232\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00009\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m [50000] loss: 22.640\n",
            "\u001b[2m\u001b[36m(pid=21608)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00010:\n",
            "  date: 2020-10-18_18-13-56\n",
            "  done: false\n",
            "  experiment_id: 8930f7e99ace4e37a2ee90eb90a104bd\n",
            "  experiment_tag: 10_batch_size=100,h1=128,h2=64,lr=0.072851,momentum=0.72006\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21600\n",
            "  time_since_restore: 377.2366769313812\n",
            "  time_this_iter_s: 377.2366769313812\n",
            "  time_total_s: 377.2366769313812\n",
            "  timestamp: 1603032236\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00010\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21600)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.7/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=-0.5%): {RUNNING: 3, TERMINATED: 2} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-1.1%): {RUNNING: 5, TERMINATED: 3} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 11, RUNNING: 4} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (83 PENDING, 12 RUNNING, 5 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00017 | PENDING    |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 |          |\n",
            "| train_771eb_00018 | PENDING    |                   |          100 |   32 |   32 | 0.00138404  |   0.911168 |          |\n",
            "| train_771eb_00019 | PENDING    |                   |         1000 |   32 |   32 | 0.00037243  |   0.885834 |          |\n",
            "| train_771eb_00020 | PENDING    |                   |            1 |   64 |  128 | 0.0628102   |   0.748114 |          |\n",
            "| train_771eb_00021 | PENDING    |                   |          100 |   16 |   64 | 1.2933e-05  |   0.749235 |          |\n",
            "| train_771eb_00022 | PENDING    |                   |          100 |  128 |   16 | 0.0796555   |   0.920876 |          |\n",
            "| train_771eb_00023 | PENDING    |                   |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |          |\n",
            "| train_771eb_00024 | PENDING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |          |\n",
            "| train_771eb_00000 | RUNNING    |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |          |\n",
            "| train_771eb_00002 | RUNNING    |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 |          |\n",
            "| train_771eb_00004 | RUNNING    |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |          |\n",
            "| train_771eb_00005 | RUNNING    |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |          |\n",
            "| train_771eb_00008 | RUNNING    |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 |          |\n",
            "| train_771eb_00010 | RUNNING    | 192.168.1.4:21600 |          100 |  128 |   64 | 0.0728514   |   0.720064 | nan      |\n",
            "| train_771eb_00011 | RUNNING    |                   |            1 |   64 |   32 | 0.0333067   |   0.924837 |          |\n",
            "| train_771eb_00012 | RUNNING    |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 |          |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433 |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245 |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404 |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (75 PENDING, 4 RUNNING)\n",
            "\n",
            "\n",
            "Result for train_771eb_00004:\n",
            "  date: 2020-10-18_18-13-57\n",
            "  done: false\n",
            "  experiment_id: 01e23b5be813441598d73f5e332f1d40\n",
            "  experiment_tag: 4_batch_size=10,h1=16,h2=8,lr=0.00010487,momentum=0.86064\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.104302051252127\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21594\n",
            "  time_since_restore: 378.602383852005\n",
            "  time_this_iter_s: 378.602383852005\n",
            "  time_total_s: 378.602383852005\n",
            "  timestamp: 1603032237\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00004\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m [50000] loss: 11.104\n",
            "\u001b[2m\u001b[36m(pid=21594)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00002:\n",
            "  date: 2020-10-18_18-13-59\n",
            "  done: false\n",
            "  experiment_id: 51a8111ebcf242038dd37d183cc4b98d\n",
            "  experiment_tag: 2_batch_size=10,h1=128,h2=32,lr=0.024102,momentum=0.56594\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21606\n",
            "  time_since_restore: 380.4022946357727\n",
            "  time_this_iter_s: 380.4022946357727\n",
            "  time_total_s: 380.4022946357727\n",
            "  timestamp: 1603032239\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00002\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21606)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00008:\n",
            "  date: 2020-10-18_18-14-00\n",
            "  done: false\n",
            "  experiment_id: 16c21e0d64d540b6bc9c04aa980193ba\n",
            "  experiment_tag: 8_batch_size=100,h1=128,h2=128,lr=0.0061961,momentum=0.8606\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21620\n",
            "  time_since_restore: 381.9387664794922\n",
            "  time_this_iter_s: 381.9387664794922\n",
            "  time_total_s: 381.9387664794922\n",
            "  timestamp: 1603032240\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00008\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21620)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00005:\n",
            "  date: 2020-10-18_18-14-05\n",
            "  done: false\n",
            "  experiment_id: 39acfd3855394fa6bcebef7919dec1cf\n",
            "  experiment_tag: 5_batch_size=1,h1=128,h2=32,lr=0.00062355,momentum=0.59598\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.277377136972547\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21604\n",
            "  time_since_restore: 386.8605864048004\n",
            "  time_this_iter_s: 386.8605864048004\n",
            "  time_total_s: 386.8605864048004\n",
            "  timestamp: 1603032245\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00005\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m [50000] loss: 9.277\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=-1.0%): {RUNNING: 1, TERMINATED: 4} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-1.6%): {RUNNING: 3, TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 7, RUNNING: 8} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (79 PENDING, 12 RUNNING, 9 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00021 | PENDING    |                   |          100 |   16 |   64 | 1.2933e-05  |   0.749235 |           |\n",
            "| train_771eb_00022 | PENDING    |                   |          100 |  128 |   16 | 0.0796555   |   0.920876 |           |\n",
            "| train_771eb_00023 | PENDING    |                   |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |           |\n",
            "| train_771eb_00024 | PENDING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |           |\n",
            "| train_771eb_00025 | PENDING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | PENDING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | PENDING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00000 | RUNNING    |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |           |\n",
            "| train_771eb_00005 | RUNNING    | 192.168.1.4:21604 |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00011 | RUNNING    |                   |            1 |   64 |   32 | 0.0333067   |   0.924837 |           |\n",
            "| train_771eb_00012 | RUNNING    |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 |           |\n",
            "| train_771eb_00013 | RUNNING    |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |           |\n",
            "| train_771eb_00014 | RUNNING    |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |           |\n",
            "| train_771eb_00015 | RUNNING    |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |           |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (72 PENDING, 5 RUNNING, 2 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=21604)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00000:\n",
            "  date: 2020-10-18_18-14-08\n",
            "  done: false\n",
            "  experiment_id: 1bda86e3ad4348d284131f3d95420062\n",
            "  experiment_tag: 0_batch_size=1,h1=16,h2=64,lr=0.0049229,momentum=0.82045\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.47144813351631\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21592\n",
            "  time_since_restore: 389.97425365448\n",
            "  time_this_iter_s: 389.97425365448\n",
            "  time_total_s: 389.97425365448\n",
            "  timestamp: 1603032248\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00000\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m [50000] loss: 36.471\n",
            "\u001b[2m\u001b[36m(pid=21592)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00011:\n",
            "  date: 2020-10-18_18-14-10\n",
            "  done: false\n",
            "  experiment_id: ec5d231d7b0644c2893a8945578792bd\n",
            "  experiment_tag: 11_batch_size=1,h1=64,h2=32,lr=0.033307,momentum=0.92484\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 40.009833913826945\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21624\n",
            "  time_since_restore: 392.10332679748535\n",
            "  time_this_iter_s: 392.10332679748535\n",
            "  time_total_s: 392.10332679748535\n",
            "  timestamp: 1603032250\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00011\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m [50000] loss: 40.010\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-1.9%): {RUNNING: 2, TERMINATED: 6} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 5, RUNNING: 10} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (77 PENDING, 12 RUNNING, 11 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00023 | PENDING    |                   |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |           |\n",
            "| train_771eb_00024 | PENDING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |           |\n",
            "| train_771eb_00025 | PENDING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | PENDING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | PENDING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00028 | PENDING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00029 | PENDING    |                   |         1000 |   32 |   64 | 0.0851164   |   0.540514 |           |\n",
            "| train_771eb_00011 | RUNNING    | 192.168.1.4:21624 |            1 |   64 |   32 | 0.0333067   |   0.924837 |  40.0098  |\n",
            "| train_771eb_00012 | RUNNING    |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 |           |\n",
            "| train_771eb_00013 | RUNNING    |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |           |\n",
            "| train_771eb_00014 | RUNNING    |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |           |\n",
            "| train_771eb_00015 | RUNNING    |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |           |\n",
            "| train_771eb_00016 | RUNNING    |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |           |\n",
            "| train_771eb_00017 | RUNNING    |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (70 PENDING, 5 RUNNING, 4 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=21624)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [ 5000] loss: 53.105\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [ 5000] loss: 99.469\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [ 5000] loss: 41.277\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [ 5000] loss: 102.145\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [ 5000] loss: 24226743154992.934\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [ 5000] loss: 105.446\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [ 5000] loss: 52568989192513.531\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [ 5000] loss: 38.962\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [ 5000] loss: 95.369\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [ 5000] loss: 26.778\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [10000] loss: 35.958\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [10000] loss: 57.351\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [10000] loss: 58.361\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [10000] loss: 18.335\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [10000] loss: 37.062\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [10000] loss: 56.984\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [10000] loss: 38.946\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [10000] loss: 13.101\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [15000] loss: 35.338\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [15000] loss: 49.064\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [15000] loss: 51.472\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [15000] loss: 13.888\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [15000] loss: 37.048\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [15000] loss: 49.406\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [15000] loss: 38.588\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [15000] loss: 11.153\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [20000] loss: 43.069\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [20000] loss: 35.739\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [20000] loss: 41.423\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [20000] loss: 36.227\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [20000] loss: 12.193\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [20000] loss: 41.709\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [20000] loss: 38.430\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [20000] loss: 10.622\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [25000] loss: 42.033\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [25000] loss: 35.652\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [25000] loss: 36.167\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [25000] loss: 36.239\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [25000] loss: 11.425\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [25000] loss: 34.997\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [25000] loss: 38.287\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [25000] loss: 10.655\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [30000] loss: 38.366\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [30000] loss: 35.871\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [30000] loss: 35.849\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [30000] loss: 31.880\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [30000] loss: 11.281\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [30000] loss: 30.736\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [30000] loss: 38.283\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [30000] loss: 10.173\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [35000] loss: 36.035\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [35000] loss: 34.002\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [35000] loss: 35.960\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [35000] loss: 28.965\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [35000] loss: 11.261\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [35000] loss: 27.433\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [35000] loss: 10.184\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [35000] loss: 37.856\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [40000] loss: 35.686\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [40000] loss: 30.719\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [40000] loss: 36.414\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [40000] loss: 27.674\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [40000] loss: 11.116\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [40000] loss: 25.812\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [40000] loss: 9.761\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [40000] loss: 38.387\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [45000] loss: 27.586\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [45000] loss: 36.591\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [45000] loss: 35.955\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [45000] loss: 24.722\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [45000] loss: 10.892\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [45000] loss: 24.058\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [45000] loss: 9.731\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [45000] loss: 38.300\n",
            "Result for train_771eb_00012:\n",
            "  date: 2020-10-18_18-20-05\n",
            "  done: false\n",
            "  experiment_id: 5978d00e58d64bcfa8c0d421af9ff65b\n",
            "  experiment_tag: 12_batch_size=1000,h1=8,h2=64,lr=0.017836,momentum=0.83886\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21791\n",
            "  time_since_restore: 378.8571743965149\n",
            "  time_this_iter_s: 378.8571743965149\n",
            "  time_total_s: 378.8571743965149\n",
            "  timestamp: 1603032605\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00012\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21791)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-2.1%): {RUNNING: 1, TERMINATED: 7} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 4, RUNNING: 11} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (76 PENDING, 12 RUNNING, 12 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00024 | PENDING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |           |\n",
            "| train_771eb_00025 | PENDING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | PENDING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | PENDING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00028 | PENDING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00029 | PENDING    |                   |         1000 |   32 |   64 | 0.0851164   |   0.540514 |           |\n",
            "| train_771eb_00030 | PENDING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00012 | RUNNING    | 192.168.1.4:21791 |         1000 |    8 |   64 | 0.0178356   |   0.838857 | nan       |\n",
            "| train_771eb_00013 | RUNNING    |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |           |\n",
            "| train_771eb_00014 | RUNNING    |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |           |\n",
            "| train_771eb_00015 | RUNNING    |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |           |\n",
            "| train_771eb_00016 | RUNNING    |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |           |\n",
            "| train_771eb_00017 | RUNNING    |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 |           |\n",
            "| train_771eb_00018 | RUNNING    |                   |          100 |   32 |   32 | 0.00138404  |   0.911168 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (69 PENDING, 5 RUNNING, 5 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00013:\n",
            "  date: 2020-10-18_18-20-12\n",
            "  done: false\n",
            "  experiment_id: 973dce66489340498cc85a69561c2d36\n",
            "  experiment_tag: 13_batch_size=100,h1=128,h2=128,lr=0.001092,momentum=0.50053\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.478395044374466\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21684\n",
            "  time_since_restore: 382.23095059394836\n",
            "  time_this_iter_s: 382.23095059394836\n",
            "  time_total_s: 382.23095059394836\n",
            "  timestamp: 1603032612\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00013\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-0.2%): {PENDING: 3, RUNNING: 12} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (75 PENDING, 12 RUNNING, 13 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00025 | PENDING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | PENDING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | PENDING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00028 | PENDING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00029 | PENDING    |                   |         1000 |   32 |   64 | 0.0851164   |   0.540514 |           |\n",
            "| train_771eb_00030 | PENDING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00031 | PENDING    |                   |           10 |    8 |   32 | 1.81342e-05 |   0.564515 |           |\n",
            "| train_771eb_00013 | RUNNING    | 192.168.1.4:21684 |          100 |  128 |  128 | 0.00109204  |   0.500525 |  35.4784  |\n",
            "| train_771eb_00014 | RUNNING    |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |           |\n",
            "| train_771eb_00015 | RUNNING    |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |           |\n",
            "| train_771eb_00016 | RUNNING    |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |           |\n",
            "| train_771eb_00017 | RUNNING    |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 |           |\n",
            "| train_771eb_00018 | RUNNING    |                   |          100 |   32 |   32 | 0.00138404  |   0.911168 |           |\n",
            "| train_771eb_00019 | RUNNING    |                   |         1000 |   32 |   32 | 0.00037243  |   0.885834 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (68 PENDING, 5 RUNNING, 6 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m [50000] loss: 35.478\n",
            "\u001b[2m\u001b[36m(pid=21684)\u001b[0m Finished Training\n",
            "Result for train_771eb_00017:\n",
            "  date: 2020-10-18_18-20-12\n",
            "  done: false\n",
            "  experiment_id: 55a7471fdd0a4133b96bd9b96d772cec\n",
            "  experiment_tag: 17_batch_size=1000,h1=64,h2=128,lr=0.00042319,momentum=0.91401\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21700\n",
            "  time_since_restore: 374.59502625465393\n",
            "  time_this_iter_s: 374.59502625465393\n",
            "  time_total_s: 374.59502625465393\n",
            "  timestamp: 1603032612\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00017\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21700)\u001b[0m Finished Training\n",
            "Result for train_771eb_00015:\n",
            "  date: 2020-10-18_18-20-12\n",
            "  done: false\n",
            "  experiment_id: 02db0dddc25946ad8d06ae1e74579631\n",
            "  experiment_tag: 15_batch_size=100,h1=8,h2=64,lr=1.4163e-05,momentum=0.7107\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 26.472275235843657\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21721\n",
            "  time_since_restore: 379.3060214519501\n",
            "  time_this_iter_s: 379.3060214519501\n",
            "  time_total_s: 379.3060214519501\n",
            "  timestamp: 1603032612\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00015\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m [50000] loss: 26.472\n",
            "\u001b[2m\u001b[36m(pid=21721)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:20:13,477\tWARNING worker.py:1072 -- The actor or task with ID ffffffffffffffff5bc74a8d01000000 is pending and cannot currently be scheduled. It requires {CPU: 1.000000} for execution and {CPU: 1.000000} for placement, but this node only has remaining {CPU: 3.000000}, {node:192.168.1.4: 1.000000}, {memory: 6.884766 GiB}, {accelerator_type:GTX: 1.000000}, {GPU: 1.000000}, {object_store_memory: 2.343750 GiB}. In total there are 0 pending tasks and 3 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m 2020-10-18 18:20:13,726\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.11571639399880951 seconds\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m 2020-10-18 18:20:13,692\tINFO (unknown file):0 -- gc.collect() freed 15 refs in 0.08380095500069729 seconds\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m 2020-10-18 18:20:13,747\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.13260492799963686 seconds\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m 2020-10-18 18:20:13,777\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.1689094240009581 seconds\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m 2020-10-18 18:20:13,753\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.14309795100052725 seconds\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m 2020-10-18 18:20:13,793\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.17380039099953137 seconds\n",
            "2020-10-18 18:20:13,803\tINFO (unknown file):0 -- gc.collect() freed 79 refs in 0.1914561159992445 seconds\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m 2020-10-18 18:20:13,830\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.1885948899998766 seconds\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m 2020-10-18 18:20:13,830\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.20339157300077204 seconds\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m 2020-10-18 18:20:13,812\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.1754148210002313 seconds\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m 2020-10-18 18:20:13,862\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.25206399299895565 seconds\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00018:\n",
            "  date: 2020-10-18_18-20-15\n",
            "  done: false\n",
            "  experiment_id: 4803c45bbd46437f8be5875f50986f13\n",
            "  experiment_tag: 18_batch_size=100,h1=32,h2=32,lr=0.001384,momentum=0.91117\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.28796542248726\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21784\n",
            "  time_since_restore: 376.1563560962677\n",
            "  time_this_iter_s: 376.1563560962677\n",
            "  time_total_s: 376.1563560962677\n",
            "  timestamp: 1603032615\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00018\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m [50000] loss: 36.288\n",
            "\u001b[2m\u001b[36m(pid=21784)\u001b[0m Finished Training\n",
            "Result for train_771eb_00016:\n",
            "  date: 2020-10-18_18-20-16\n",
            "  done: false\n",
            "  experiment_id: 0cbe028699fc4cbb8d87732f1a9fe73b\n",
            "  experiment_tag: 16_batch_size=10,h1=128,h2=32,lr=1.572e-05,momentum=0.63636\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 24.250969193792344\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21773\n",
            "  time_since_restore: 382.0293400287628\n",
            "  time_this_iter_s: 382.0293400287628\n",
            "  time_total_s: 382.0293400287628\n",
            "  timestamp: 1603032616\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00016\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m [50000] loss: 24.251\n",
            "\u001b[2m\u001b[36m(pid=21773)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00019:\n",
            "  date: 2020-10-18_18-20-18\n",
            "  done: false\n",
            "  experiment_id: 217f8c808a964bd38d0dfe7ebc706360\n",
            "  experiment_tag: 19_batch_size=1000,h1=32,h2=32,lr=0.00037243,momentum=0.88583\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21733\n",
            "  time_since_restore: 378.3405730724335\n",
            "  time_this_iter_s: 378.3405730724335\n",
            "  time_total_s: 378.3405730724335\n",
            "  timestamp: 1603032618\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00019\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-1.4%): {RUNNING: 10, TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 32, RUNNING: 2} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (70 PENDING, 12 RUNNING, 18 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00030 | PENDING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00031 | PENDING    |                   |           10 |    8 |   32 | 1.81342e-05 |   0.564515 |           |\n",
            "| train_771eb_00032 | PENDING    |                   |            1 |   16 |   64 | 6.98617e-05 |   0.898306 |           |\n",
            "| train_771eb_00033 | PENDING    |                   |           10 |   16 |  128 | 0.00161962  |   0.898606 |           |\n",
            "| train_771eb_00034 | PENDING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00035 | PENDING    |                   |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |           |\n",
            "| train_771eb_00036 | PENDING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00014 | RUNNING    |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |           |\n",
            "| train_771eb_00019 | RUNNING    | 192.168.1.4:21733 |         1000 |   32 |   32 | 0.00037243  |   0.885834 | nan       |\n",
            "| train_771eb_00020 | RUNNING    |                   |            1 |   64 |  128 | 0.0628102   |   0.748114 |           |\n",
            "| train_771eb_00021 | RUNNING    |                   |          100 |   16 |   64 | 1.2933e-05  |   0.749235 |           |\n",
            "| train_771eb_00022 | RUNNING    |                   |          100 |  128 |   16 | 0.0796555   |   0.920876 |           |\n",
            "| train_771eb_00023 | RUNNING    |                   |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |           |\n",
            "| train_771eb_00024 | RUNNING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (63 PENDING, 5 RUNNING, 11 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21733)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00014:\n",
            "  date: 2020-10-18_18-20-20\n",
            "  done: false\n",
            "  experiment_id: 6e932512dc504953b79e259eee8a6a68\n",
            "  experiment_tag: 14_batch_size=1,h1=128,h2=8,lr=0.00022034,momentum=0.56569\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.056581822574138\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21746\n",
            "  time_since_restore: 388.0147912502289\n",
            "  time_this_iter_s: 388.0147912502289\n",
            "  time_total_s: 388.0147912502289\n",
            "  timestamp: 1603032620\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00014\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m [50000] loss: 11.057\n",
            "\u001b[2m\u001b[36m(pid=21746)\u001b[0m Finished Training\n",
            "Result for train_771eb_00021:\n",
            "  date: 2020-10-18_18-20-21\n",
            "  done: false\n",
            "  experiment_id: e293674bd9354ddba7c1ea0c4ce5bbde\n",
            "  experiment_tag: 21_batch_size=100,h1=16,h2=64,lr=1.2933e-05,momentum=0.74924\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 22.307362987327576\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21659\n",
            "  time_since_restore: 374.24225330352783\n",
            "  time_this_iter_s: 374.24225330352783\n",
            "  time_total_s: 374.24225330352783\n",
            "  timestamp: 1603032621\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00021\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m [50000] loss: 22.307\n",
            "\u001b[2m\u001b[36m(pid=21659)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00022:\n",
            "  date: 2020-10-18_18-20-24\n",
            "  done: false\n",
            "  experiment_id: fb619d46edac49d8bcfba1ef62094309\n",
            "  experiment_tag: 22_batch_size=100,h1=128,h2=16,lr=0.079655,momentum=0.92088\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21644\n",
            "  time_since_restore: 374.41202569007874\n",
            "  time_this_iter_s: 374.41202569007874\n",
            "  time_total_s: 374.41202569007874\n",
            "  timestamp: 1603032624\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00022\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-2.2%): {RUNNING: 7, TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 29, RUNNING: 5} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (67 PENDING, 12 RUNNING, 21 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00033 | PENDING    |                   |           10 |   16 |  128 | 0.00161962  |   0.898606 |           |\n",
            "| train_771eb_00034 | PENDING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00035 | PENDING    |                   |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |           |\n",
            "| train_771eb_00036 | PENDING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00037 | PENDING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | PENDING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | PENDING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00020 | RUNNING    |                   |            1 |   64 |  128 | 0.0628102   |   0.748114 |           |\n",
            "| train_771eb_00022 | RUNNING    | 192.168.1.4:21644 |          100 |  128 |   16 | 0.0796555   |   0.920876 | nan       |\n",
            "| train_771eb_00023 | RUNNING    |                   |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |           |\n",
            "| train_771eb_00024 | RUNNING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |           |\n",
            "| train_771eb_00025 | RUNNING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | RUNNING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | RUNNING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (60 PENDING, 5 RUNNING, 14 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=21644)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00023:\n",
            "  date: 2020-10-18_18-20-38\n",
            "  done: false\n",
            "  experiment_id: 8e772d1ad7b34019bd3f12f9ec3044f6\n",
            "  experiment_tag: 23_batch_size=1,h1=32,h2=32,lr=4.7867e-05,momentum=0.97382\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.330842914760114\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22253\n",
            "  time_since_restore: 384.55846095085144\n",
            "  time_this_iter_s: 384.55846095085144\n",
            "  time_total_s: 384.55846095085144\n",
            "  timestamp: 1603032638\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00023\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m [50000] loss: 9.331\n",
            "\u001b[2m\u001b[36m(pid=22253)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.7/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-2.4%): {RUNNING: 6, TERMINATED: 9} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 28, RUNNING: 6} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (66 PENDING, 12 RUNNING, 22 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00034 | PENDING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00035 | PENDING    |                   |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |           |\n",
            "| train_771eb_00036 | PENDING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00037 | PENDING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | PENDING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | PENDING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00040 | PENDING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00020 | RUNNING    |                   |            1 |   64 |  128 | 0.0628102   |   0.748114 |           |\n",
            "| train_771eb_00023 | RUNNING    | 192.168.1.4:22253 |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |   9.33084 |\n",
            "| train_771eb_00024 | RUNNING    |                   |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |           |\n",
            "| train_771eb_00025 | RUNNING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | RUNNING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | RUNNING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00028 | RUNNING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (59 PENDING, 5 RUNNING, 15 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00020:\n",
            "  date: 2020-10-18_18-20-40\n",
            "  done: false\n",
            "  experiment_id: cc6c6d3446554ac29c230644ac90de42\n",
            "  experiment_tag: 20_batch_size=1,h1=64,h2=128,lr=0.06281,momentum=0.74811\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 38.16943729383946\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 21671\n",
            "  time_since_restore: 397.7429223060608\n",
            "  time_this_iter_s: 397.7429223060608\n",
            "  time_total_s: 397.7429223060608\n",
            "  timestamp: 1603032640\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00020\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m [50000] loss: 38.169\n",
            "\u001b[2m\u001b[36m(pid=21671)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [ 5000] loss: 93.434\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [ 5000] loss: 491401871.359\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [ 5000] loss: 34.936\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [ 5000] loss: 132.163\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [ 5000] loss: 30.306\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [ 5000] loss: 27080986140564653432897536.000\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [ 5000] loss: 58.488\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [ 5000] loss: 106.797\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [ 5000] loss: 35.633\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [ 5000] loss: 35.393\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [ 5000] loss: 37.936\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [ 5000] loss: 117.248\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [10000] loss: 59.350\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [10000] loss: 15.538\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [10000] loss: 3524081021.301\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [10000] loss: 68.205\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [10000] loss: 15.970\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [10000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [10000] loss: 54.752\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [10000] loss: 29.793\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [10000] loss: 17.444\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [10000] loss: 35.613\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [10000] loss: 37.659\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [10000] loss: 65.504\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [15000] loss: 52.325\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [15000] loss: 951473096.275\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [15000] loss: 12.192\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [15000] loss: 55.406\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [15000] loss: 13.089\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [15000] loss: 48.353\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [15000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [15000] loss: 22.358\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [15000] loss: 36.333\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [15000] loss: 13.201\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [15000] loss: 38.272\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [15000] loss: 48.016\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [20000] loss: 48.231\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [20000] loss: 417969044.173\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [20000] loss: 11.249\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [20000] loss: 48.703\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [20000] loss: 44.575\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [20000] loss: 11.487\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [20000] loss: 36.715\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [20000] loss: 17.350\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [20000] loss: 11.522\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [20000] loss: 44.127\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [20000] loss: 38.048\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [25000] loss: 43.233\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [25000] loss: 171723155.212\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [25000] loss: 10.753\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [25000] loss: 45.461\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [25000] loss: 41.737\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [25000] loss: 10.803\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [25000] loss: 35.180\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [25000] loss: 15.010\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [25000] loss: 10.524\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [25000] loss: 42.435\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [30000] loss: 41.190\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [25000] loss: 37.926\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [30000] loss: 46706373.393\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [30000] loss: 10.317\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [30000] loss: 41.722\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [30000] loss: 38.340\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [30000] loss: 10.232\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [30000] loss: 36.402\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [30000] loss: 13.561\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [30000] loss: 9.854\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [30000] loss: 38.947\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [30000] loss: 37.757\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [35000] loss: 35.919\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [35000] loss: 26035534.696\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [35000] loss: 38.018\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [35000] loss: 10.472\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [35000] loss: 33.599\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [35000] loss: 10.055\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [35000] loss: 35.814\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [35000] loss: 12.749\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [35000] loss: 9.859\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [35000] loss: 32.363\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [35000] loss: 37.413\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [40000] loss: 31.585\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [40000] loss: 7112584.691\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [40000] loss: 32.939\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [40000] loss: 9.833\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [40000] loss: 29.821\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [40000] loss: 35.785\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [40000] loss: 10.040\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [40000] loss: 11.988\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [40000] loss: 9.803\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [40000] loss: 27.346\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [45000] loss: 28.451\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [40000] loss: 38.173\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [45000] loss: 3064550.433\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [45000] loss: 29.297\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [45000] loss: 9.697\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [45000] loss: 28.275\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [45000] loss: 36.597\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [45000] loss: 9.624\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [45000] loss: 11.852\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [45000] loss: 9.566\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [45000] loss: 25.037\n",
            "Result for train_771eb_00024:\n",
            "  date: 2020-10-18_18-26-20\n",
            "  done: false\n",
            "  experiment_id: 59cdfc94c19640e0a23cd8aaf1f7cdfb\n",
            "  experiment_tag: 24_batch_size=10,h1=8,h2=128,lr=1.7431e-05,momentum=0.60581\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 25.976458893179892\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22356\n",
            "  time_since_restore: 373.14296889305115\n",
            "  time_this_iter_s: 373.14296889305115\n",
            "  time_total_s: 373.14296889305115\n",
            "  timestamp: 1603032980\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00024\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m [50000] loss: 25.976\n",
            "\u001b[2m\u001b[36m(pid=22356)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-2.9%): {RUNNING: 4, TERMINATED: 11} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 26, RUNNING: 8} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (64 PENDING, 12 RUNNING, 24 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00036 | PENDING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00037 | PENDING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | PENDING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | PENDING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00040 | PENDING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | PENDING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00042 | PENDING    |                   |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |           |\n",
            "| train_771eb_00024 | RUNNING    | 192.168.1.4:22356 |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |  25.9765  |\n",
            "| train_771eb_00025 | RUNNING    |                   |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |           |\n",
            "| train_771eb_00026 | RUNNING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00027 | RUNNING    |                   |         1000 |    8 |   64 | 0.00290627  |   0.821822 |           |\n",
            "| train_771eb_00028 | RUNNING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00029 | RUNNING    |                   |         1000 |   32 |   64 | 0.0851164   |   0.540514 |           |\n",
            "| train_771eb_00030 | RUNNING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (57 PENDING, 5 RUNNING, 17 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [45000] loss: 38.274\n",
            "Result for train_771eb_00027:\n",
            "  date: 2020-10-18_18-26-23\n",
            "  done: false\n",
            "  experiment_id: 3500f451f6804eac99af6ce2d9be1dcc\n",
            "  experiment_tag: 27_batch_size=1000,h1=8,h2=64,lr=0.0029063,momentum=0.82182\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1281171.317959375\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22381\n",
            "  time_since_restore: 367.7535824775696\n",
            "  time_this_iter_s: 367.7535824775696\n",
            "  time_total_s: 367.7535824775696\n",
            "  timestamp: 1603032983\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00027\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m [50000] loss: 1281171.318\n",
            "\u001b[2m\u001b[36m(pid=22381)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00025:\n",
            "  date: 2020-10-18_18-26-28\n",
            "  done: false\n",
            "  experiment_id: 69233588de514772973626c4d44ed478\n",
            "  experiment_tag: 25_batch_size=1000,h1=64,h2=64,lr=1.5553e-05,momentum=0.62077\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 27.822446392130853\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22384\n",
            "  time_since_restore: 372.6886034011841\n",
            "  time_this_iter_s: 372.6886034011841\n",
            "  time_total_s: 372.6886034011841\n",
            "  timestamp: 1603032988\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00025\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-3.4%): {RUNNING: 2, TERMINATED: 13} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=0.0%): {PENDING: 24, RUNNING: 10} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (62 PENDING, 12 RUNNING, 26 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00038 | PENDING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | PENDING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00040 | PENDING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | PENDING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00042 | PENDING    |                   |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |           |\n",
            "| train_771eb_00043 | PENDING    |                   |           10 |   32 |   32 | 0.000552758 |   0.929839 |           |\n",
            "| train_771eb_00044 | PENDING    |                   |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |           |\n",
            "| train_771eb_00025 | RUNNING    | 192.168.1.4:22384 |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |  27.8224  |\n",
            "| train_771eb_00026 | RUNNING    |                   |           10 |   16 |   64 | 0.000225445 |   0.720695 |           |\n",
            "| train_771eb_00028 | RUNNING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00029 | RUNNING    |                   |         1000 |   32 |   64 | 0.0851164   |   0.540514 |           |\n",
            "| train_771eb_00030 | RUNNING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00031 | RUNNING    |                   |           10 |    8 |   32 | 1.81342e-05 |   0.564515 |           |\n",
            "| train_771eb_00032 | RUNNING    |                   |            1 |   16 |   64 | 6.98617e-05 |   0.898306 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (55 PENDING, 5 RUNNING, 19 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m [50000] loss: 27.822\n",
            "\u001b[2m\u001b[36m(pid=22384)\u001b[0m Finished Training\n",
            "Result for train_771eb_00026:\n",
            "  date: 2020-10-18_18-26-29\n",
            "  done: false\n",
            "  experiment_id: fb6e09389682459eaddcb0bf1fafbe5d\n",
            "  experiment_tag: 26_batch_size=10,h1=16,h2=64,lr=0.00022545,momentum=0.72069\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.787166454911231\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22379\n",
            "  time_since_restore: 374.1168382167816\n",
            "  time_this_iter_s: 374.1168382167816\n",
            "  time_total_s: 374.1168382167816\n",
            "  timestamp: 1603032989\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00026\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m [50000] loss: 9.787\n",
            "\u001b[2m\u001b[36m(pid=22379)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00031:\n",
            "  date: 2020-10-18_18-26-33\n",
            "  done: false\n",
            "  experiment_id: f650b66a9db0464d8afd8800e9694004\n",
            "  experiment_tag: 31_batch_size=10,h1=8,h2=32,lr=1.8134e-05,momentum=0.56452\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 26.768173248100283\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22395\n",
            "  time_since_restore: 371.4429922103882\n",
            "  time_this_iter_s: 371.4429922103882\n",
            "  time_total_s: 371.4429922103882\n",
            "  timestamp: 1603032993\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00031\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m [50000] loss: 26.768\n",
            "\u001b[2m\u001b[36m(pid=22395)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-0.2%): {PENDING: 22, RUNNING: 12} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (60 PENDING, 12 RUNNING, 28 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00040 | PENDING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | PENDING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00042 | PENDING    |                   |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |           |\n",
            "| train_771eb_00043 | PENDING    |                   |           10 |   32 |   32 | 0.000552758 |   0.929839 |           |\n",
            "| train_771eb_00044 | PENDING    |                   |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |           |\n",
            "| train_771eb_00045 | PENDING    |                   |         1000 |   64 |   64 | 0.0770321   |   0.819817 |           |\n",
            "| train_771eb_00046 | PENDING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00028 | RUNNING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00029 | RUNNING    |                   |         1000 |   32 |   64 | 0.0851164   |   0.540514 |           |\n",
            "| train_771eb_00030 | RUNNING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00031 | RUNNING    | 192.168.1.4:22395 |           10 |    8 |   32 | 1.81342e-05 |   0.564515 |  26.7682  |\n",
            "| train_771eb_00032 | RUNNING    |                   |            1 |   16 |   64 | 6.98617e-05 |   0.898306 |           |\n",
            "| train_771eb_00033 | RUNNING    |                   |           10 |   16 |  128 | 0.00161962  |   0.898606 |           |\n",
            "| train_771eb_00034 | RUNNING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (53 PENDING, 5 RUNNING, 21 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:26:34,649\tWARNING worker.py:1072 -- The actor or task with ID ffffffffffffffff157a6ba901000000 is pending and cannot currently be scheduled. It requires {CPU: 1.000000} for execution and {CPU: 1.000000} for placement, but this node only has remaining {CPU: 1.000000}, {node:192.168.1.4: 1.000000}, {memory: 6.884766 GiB}, {accelerator_type:GTX: 1.000000}, {GPU: 1.000000}, {object_store_memory: 2.343750 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m 2020-10-18 18:26:34,943\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.20197979000113264 seconds2020-10-18 18:26:34,985\tINFO (unknown file):0 -- gc.collect() freed 230 refs in 0.24594235099903017 seconds\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m 2020-10-18 18:26:34,924\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.18432736999966437 seconds\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m 2020-10-18 18:26:34,957\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.20081672300148057 seconds\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m 2020-10-18 18:26:34,939\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.17821849599931738 seconds\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m 2020-10-18 18:26:34,935\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.1735190250001324 seconds\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m 2020-10-18 18:26:34,929\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.18848709499980032 seconds\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m 2020-10-18 18:26:34,920\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.17569687299874204 seconds\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m 2020-10-18 18:26:34,951\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.19701776699912443 seconds\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m 2020-10-18 18:26:34,967\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.2192475480005669 seconds\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m 2020-10-18 18:26:34,968\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.20865542300089146 seconds\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m 2020-10-18 18:26:34,965\tINFO (unknown file):0 -- gc.collect() freed 6 refs in 0.21318385799895623 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00029:\n",
            "  date: 2020-10-18_18-26-35\n",
            "  done: false\n",
            "  experiment_id: 8f9d941d0cec44b9bed7e2a38e2f1358\n",
            "  experiment_tag: 29_batch_size=1000,h1=32,h2=64,lr=0.085116,momentum=0.54051\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22419\n",
            "  time_since_restore: 377.92875957489014\n",
            "  time_this_iter_s: 377.92875957489014\n",
            "  time_total_s: 377.92875957489014\n",
            "  timestamp: 1603032995\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00029\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22419)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00033:\n",
            "  date: 2020-10-18_18-26-42\n",
            "  done: false\n",
            "  experiment_id: e5933c6208074a83b96c59bc4ac74d13\n",
            "  experiment_tag: 33_batch_size=10,h1=16,h2=128,lr=0.0016196,momentum=0.89861\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.626549176454546\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22402\n",
            "  time_since_restore: 376.5364260673523\n",
            "  time_this_iter_s: 376.5364260673523\n",
            "  time_total_s: 376.5364260673523\n",
            "  timestamp: 1603033002\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00033\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-0.6%): {PENDING: 20, RUNNING: 12, TERMINATED: 2} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (58 PENDING, 12 RUNNING, 30 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00042 | PENDING    |                   |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |           |\n",
            "| train_771eb_00043 | PENDING    |                   |           10 |   32 |   32 | 0.000552758 |   0.929839 |           |\n",
            "| train_771eb_00044 | PENDING    |                   |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |           |\n",
            "| train_771eb_00045 | PENDING    |                   |         1000 |   64 |   64 | 0.0770321   |   0.819817 |           |\n",
            "| train_771eb_00046 | PENDING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00047 | PENDING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | PENDING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00028 | RUNNING    |                   |            1 |   16 |   32 | 0.000401921 |   0.610701 |           |\n",
            "| train_771eb_00030 | RUNNING    |                   |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |           |\n",
            "| train_771eb_00032 | RUNNING    |                   |            1 |   16 |   64 | 6.98617e-05 |   0.898306 |           |\n",
            "| train_771eb_00033 | RUNNING    | 192.168.1.4:22402 |           10 |   16 |  128 | 0.00161962  |   0.898606 |  35.6265  |\n",
            "| train_771eb_00034 | RUNNING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00035 | RUNNING    |                   |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |           |\n",
            "| train_771eb_00036 | RUNNING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (51 PENDING, 5 RUNNING, 23 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m [50000] loss: 35.627\n",
            "\u001b[2m\u001b[36m(pid=22402)\u001b[0m Finished Training\n",
            "Result for train_771eb_00028:\n",
            "  date: 2020-10-18_18-26-45\n",
            "  done: false\n",
            "  experiment_id: 6beb6738e90e40af82486d4da0c733ac\n",
            "  experiment_tag: 28_batch_size=1,h1=16,h2=32,lr=0.00040192,momentum=0.6107\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.591908756160736\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22434\n",
            "  time_since_restore: 387.96408224105835\n",
            "  time_this_iter_s: 387.96408224105835\n",
            "  time_total_s: 387.96408224105835\n",
            "  timestamp: 1603033005\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00028\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m [50000] loss: 9.592\n",
            "\u001b[2m\u001b[36m(pid=22434)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00030:\n",
            "  date: 2020-10-18_18-26-46\n",
            "  done: false\n",
            "  experiment_id: 5bddbfccd51a4e7486758a5bca2985f7\n",
            "  experiment_tag: 30_batch_size=1,h1=32,h2=16,lr=8.2318e-05,momentum=0.60819\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.559686305820941\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22426\n",
            "  time_since_restore: 386.1969983577728\n",
            "  time_this_iter_s: 386.1969983577728\n",
            "  time_total_s: 386.1969983577728\n",
            "  timestamp: 1603033006\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00030\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m [50000] loss: 11.560\n",
            "\u001b[2m\u001b[36m(pid=22426)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00032:\n",
            "  date: 2020-10-18_18-26-48\n",
            "  done: false\n",
            "  experiment_id: e4ee944a77c544d08552a0205048b7e2\n",
            "  experiment_tag: 32_batch_size=1,h1=16,h2=64,lr=6.9862e-05,momentum=0.89831\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.238753966468572\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22398\n",
            "  time_since_restore: 384.9023199081421\n",
            "  time_this_iter_s: 384.9023199081421\n",
            "  time_total_s: 384.9023199081421\n",
            "  timestamp: 1603033008\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00032\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-1.3%): {PENDING: 17, RUNNING: 12, TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (55 PENDING, 12 RUNNING, 33 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00045 | PENDING    |                   |         1000 |   64 |   64 | 0.0770321   |   0.819817 |           |\n",
            "| train_771eb_00046 | PENDING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00047 | PENDING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | PENDING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | PENDING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | PENDING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | PENDING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00032 | RUNNING    | 192.168.1.4:22398 |            1 |   16 |   64 | 6.98617e-05 |   0.898306 |   9.23875 |\n",
            "| train_771eb_00034 | RUNNING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00035 | RUNNING    |                   |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |           |\n",
            "| train_771eb_00036 | RUNNING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00037 | RUNNING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | RUNNING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | RUNNING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (48 PENDING, 5 RUNNING, 26 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m [50000] loss: 9.239\n",
            "\u001b[2m\u001b[36m(pid=22398)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00035:\n",
            "  date: 2020-10-18_18-26-55\n",
            "  done: false\n",
            "  experiment_id: 453071bdbc604d8981bdd47afa9259a5\n",
            "  experiment_tag: 35_batch_size=1000,h1=64,h2=16,lr=1.9496e-05,momentum=0.65127\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 23.019699252510073\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22400\n",
            "  time_since_restore: 374.01564145088196\n",
            "  time_this_iter_s: 374.01564145088196\n",
            "  time_total_s: 374.01564145088196\n",
            "  timestamp: 1603033015\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00035\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m [50000] loss: 23.020\n",
            "\u001b[2m\u001b[36m(pid=22400)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-1.5%): {PENDING: 16, RUNNING: 12, TERMINATED: 6} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (54 PENDING, 12 RUNNING, 34 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00046 | PENDING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00047 | PENDING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | PENDING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | PENDING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | PENDING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | PENDING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | PENDING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00034 | RUNNING    |                   |            1 |   32 |    8 | 0.0497771   |   0.758362 |           |\n",
            "| train_771eb_00035 | RUNNING    | 192.168.1.4:22400 |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |  23.0197  |\n",
            "| train_771eb_00036 | RUNNING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00037 | RUNNING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | RUNNING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | RUNNING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00040 | RUNNING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (47 PENDING, 5 RUNNING, 27 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00034:\n",
            "  date: 2020-10-18_18-27-01\n",
            "  done: false\n",
            "  experiment_id: 1456f5d2039f41cb824a24003602f296\n",
            "  experiment_tag: 34_batch_size=1,h1=32,h2=8,lr=0.049777,momentum=0.75836\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 37.8230400891304\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22399\n",
            "  time_since_restore: 382.13332653045654\n",
            "  time_this_iter_s: 382.13332653045654\n",
            "  time_total_s: 382.13332653045654\n",
            "  timestamp: 1603033021\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00034\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m [50000] loss: 37.823\n",
            "== Status ==\n",
            "Memory usage on this node: 6.7/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-1.7%): {PENDING: 15, RUNNING: 12, TERMINATED: 7} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (53 PENDING, 12 RUNNING, 35 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00047 | PENDING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | PENDING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | PENDING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | PENDING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | PENDING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | PENDING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | PENDING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00034 | RUNNING    | 192.168.1.4:22399 |            1 |   32 |    8 | 0.0497771   |   0.758362 |  37.823   |\n",
            "| train_771eb_00036 | RUNNING    |                   |          100 |   32 |   64 | 0.0201081   |   0.514602 |           |\n",
            "| train_771eb_00037 | RUNNING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | RUNNING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | RUNNING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00040 | RUNNING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | RUNNING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (46 PENDING, 5 RUNNING, 28 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22399)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [ 5000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [ 5000] loss: 48.171\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [ 5000] loss: 36.255\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [ 5000] loss: 46.956\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [ 5000] loss: 71.447\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [ 5000] loss: 28.090\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [ 5000] loss: 140.832\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [ 5000] loss: 29.810\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [ 5000] loss: 46.325\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [ 5000] loss: 37.739\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [ 5000] loss: 49.645\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [10000] loss: 36.881\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [10000] loss: 36.316\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [10000] loss: 36.877\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [10000] loss: 37.135\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [10000] loss: 13.650\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [10000] loss: 70.419\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [10000] loss: 20.754\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [10000] loss: 19.595\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [10000] loss: 36.128\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [10000] loss: 28.852\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [15000] loss: 37.936\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [15000] loss: 36.123\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [15000] loss: 36.872\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [15000] loss: 27.299\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [15000] loss: 55.052\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [15000] loss: 11.466\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [15000] loss: 16.732\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [15000] loss: 14.168\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [15000] loss: 36.427\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [15000] loss: 35.962\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [20000] loss: 36.270\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [20000] loss: 36.116\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [20000] loss: 37.472\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [20000] loss: 22.591\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [20000] loss: 46.086\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [20000] loss: 10.621\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [20000] loss: 14.524\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [20000] loss: 13.295\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [20000] loss: 36.125\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [20000] loss: 36.322\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [25000] loss: 36.500\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [25000] loss: 37.826\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [25000] loss: 35.245\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [25000] loss: 18.671\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [25000] loss: 42.792\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [25000] loss: 9.973\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [25000] loss: 13.452\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [25000] loss: 13.189\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [25000] loss: 35.436\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [30000] loss: 37.395\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [25000] loss: 35.839\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [30000] loss: 35.553\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [30000] loss: 36.608\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [30000] loss: 16.553\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [30000] loss: 41.962\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [30000] loss: 12.630\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [30000] loss: 9.810\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [30000] loss: 14.633\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [30000] loss: 35.916\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [35000] loss: 37.016\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [30000] loss: 35.683\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [35000] loss: 35.815\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [35000] loss: 36.743\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [35000] loss: 15.410\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [35000] loss: 41.274\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [35000] loss: 12.478\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [35000] loss: 9.641\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [35000] loss: 14.344\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [35000] loss: 36.244\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [40000] loss: 38.410\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [35000] loss: 36.364\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [40000] loss: 36.981\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [40000] loss: 35.459\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [40000] loss: 39.529\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [40000] loss: 14.198\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [40000] loss: 11.607\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [40000] loss: 13.801\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [40000] loss: 9.382\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [40000] loss: 36.841\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [40000] loss: 36.341\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [45000] loss: 38.540\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [45000] loss: 36.607\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [45000] loss: 35.679\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [45000] loss: 35.511\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [45000] loss: 12.900\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [45000] loss: 10.929\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [45000] loss: 13.943\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [45000] loss: 9.257\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [45000] loss: 35.820\n",
            "Result for train_771eb_00036:\n",
            "  date: 2020-10-18_18-32-43\n",
            "  done: false\n",
            "  experiment_id: a342dc2cc2ab438c9bf26db7d3f26d33\n",
            "  experiment_tag: 36_batch_size=100,h1=32,h2=64,lr=0.020108,momentum=0.5146\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22383\n",
            "  time_since_restore: 380.72439789772034\n",
            "  time_this_iter_s: 380.72439789772034\n",
            "  time_total_s: 380.72439789772034\n",
            "  timestamp: 1603033363\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00036\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22383)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-1.9%): {PENDING: 14, RUNNING: 12, TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (52 PENDING, 12 RUNNING, 36 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00048 | PENDING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | PENDING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | PENDING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | PENDING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | PENDING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | PENDING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | PENDING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00036 | RUNNING    | 192.168.1.4:22383 |          100 |   32 |   64 | 0.0201081   |   0.514602 | nan       |\n",
            "| train_771eb_00037 | RUNNING    |                   |           10 |   64 |   32 | 0.00366981  |   0.978938 |           |\n",
            "| train_771eb_00038 | RUNNING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | RUNNING    |                   |          100 |    8 |   32 | 0.00868283  |   0.92879  |           |\n",
            "| train_771eb_00040 | RUNNING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | RUNNING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00042 | RUNNING    |                   |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (45 PENDING, 5 RUNNING, 29 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [45000] loss: 36.250\n",
            "Result for train_771eb_00037:\n",
            "  date: 2020-10-18_18-32-48\n",
            "  done: false\n",
            "  experiment_id: 16a5d3defaf54b958d0960d39329a16c\n",
            "  experiment_tag: 37_batch_size=10,h1=64,h2=32,lr=0.0036698,momentum=0.97894\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 37.88257375485897\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22731\n",
            "  time_since_restore: 382.8009808063507\n",
            "  time_this_iter_s: 382.8009808063507\n",
            "  time_total_s: 382.8009808063507\n",
            "  timestamp: 1603033368\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00037\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m [50000] loss: 37.883\n",
            "\u001b[2m\u001b[36m(pid=22731)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00039:\n",
            "  date: 2020-10-18_18-32-50\n",
            "  done: false\n",
            "  experiment_id: ddb7a26fd1724085a87d57c23f674ca8\n",
            "  experiment_tag: 39_batch_size=100,h1=8,h2=32,lr=0.0086828,momentum=0.92879\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 38.8085621830225\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22774\n",
            "  time_since_restore: 379.31863021850586\n",
            "  time_this_iter_s: 379.31863021850586\n",
            "  time_total_s: 379.31863021850586\n",
            "  timestamp: 1603033370\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00039\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-2.3%): {PENDING: 12, RUNNING: 12, TERMINATED: 10} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (50 PENDING, 12 RUNNING, 38 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00050 | PENDING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | PENDING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | PENDING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | PENDING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | PENDING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00055 | PENDING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | PENDING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00038 | RUNNING    |                   |           10 |  128 |    8 | 0.00380114  |   0.728068 |           |\n",
            "| train_771eb_00039 | RUNNING    | 192.168.1.4:22774 |          100 |    8 |   32 | 0.00868283  |   0.92879  |  38.8086  |\n",
            "| train_771eb_00040 | RUNNING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | RUNNING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00042 | RUNNING    |                   |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |           |\n",
            "| train_771eb_00043 | RUNNING    |                   |           10 |   32 |   32 | 0.000552758 |   0.929839 |           |\n",
            "| train_771eb_00044 | RUNNING    |                   |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (43 PENDING, 5 RUNNING, 31 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m [50000] loss: 38.809\n",
            "\u001b[2m\u001b[36m(pid=22774)\u001b[0m Finished Training\n",
            "Result for train_771eb_00038:\n",
            "  date: 2020-10-18_18-32-51\n",
            "  done: false\n",
            "  experiment_id: c7f6de6cf8a0496b8513c0c65db37364\n",
            "  experiment_tag: 38_batch_size=10,h1=128,h2=8,lr=0.0038011,momentum=0.72807\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.86886550261974\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22753\n",
            "  time_since_restore: 381.22011852264404\n",
            "  time_this_iter_s: 381.22011852264404\n",
            "  time_total_s: 381.22011852264404\n",
            "  timestamp: 1603033371\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00038\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m [50000] loss: 35.869\n",
            "\u001b[2m\u001b[36m(pid=22753)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00042:\n",
            "  date: 2020-10-18_18-32-57\n",
            "  done: false\n",
            "  experiment_id: ff7ae8d957c04015a0b3934ac645f9e5\n",
            "  experiment_tag: 42_batch_size=1000,h1=16,h2=8,lr=1.2666e-05,momentum=0.71975\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 31.00576037552357\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22862\n",
            "  time_since_restore: 372.32084488868713\n",
            "  time_this_iter_s: 372.32084488868713\n",
            "  time_total_s: 372.32084488868713\n",
            "  timestamp: 1603033377\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00042\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m [50000] loss: 31.006\n",
            "\u001b[2m\u001b[36m(pid=22862)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-2.7%): {PENDING: 10, RUNNING: 12, TERMINATED: 12} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (48 PENDING, 12 RUNNING, 40 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00052 | PENDING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | PENDING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | PENDING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00055 | PENDING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | PENDING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | PENDING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00058 | PENDING    |                   |         1000 |    8 |    8 | 0.000478096 |   0.842333 |           |\n",
            "| train_771eb_00040 | RUNNING    |                   |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |           |\n",
            "| train_771eb_00041 | RUNNING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00042 | RUNNING    | 192.168.1.4:22862 |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |  31.0058  |\n",
            "| train_771eb_00043 | RUNNING    |                   |           10 |   32 |   32 | 0.000552758 |   0.929839 |           |\n",
            "| train_771eb_00044 | RUNNING    |                   |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |           |\n",
            "| train_771eb_00045 | RUNNING    |                   |         1000 |   64 |   64 | 0.0770321   |   0.819817 |           |\n",
            "| train_771eb_00046 | RUNNING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (41 PENDING, 5 RUNNING, 33 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_771eb_00040:\n",
            "  date: 2020-10-18_18-32-59\n",
            "  done: false\n",
            "  experiment_id: 55b8c239c3914bfc8f98b0a8ad12ac58\n",
            "  experiment_tag: 40_batch_size=100,h1=16,h2=32,lr=3.0997e-05,momentum=0.96812\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 12.956507226848602\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22809\n",
            "  time_since_restore: 382.6851716041565\n",
            "  time_this_iter_s: 382.6851716041565\n",
            "  time_total_s: 382.6851716041565\n",
            "  timestamp: 1603033379\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00040\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m [50000] loss: 12.957\n",
            "\u001b[2m\u001b[36m(pid=22809)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00044:\n",
            "  date: 2020-10-18_18-33-06\n",
            "  done: false\n",
            "  experiment_id: 992b8b93e9484376b126d1796484a777\n",
            "  experiment_tag: 44_batch_size=10,h1=8,h2=128,lr=7.2533e-05,momentum=0.86029\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.92189860674143\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22906\n",
            "  time_since_restore: 377.2119879722595\n",
            "  time_this_iter_s: 377.2119879722595\n",
            "  time_total_s: 377.2119879722595\n",
            "  timestamp: 1603033386\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00044\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m [50000] loss: 10.922\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-3.2%): {PENDING: 8, RUNNING: 12, TERMINATED: 14} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (46 PENDING, 12 RUNNING, 42 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00054 | PENDING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00055 | PENDING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | PENDING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | PENDING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00058 | PENDING    |                   |         1000 |    8 |    8 | 0.000478096 |   0.842333 |           |\n",
            "| train_771eb_00059 | PENDING    |                   |           10 |    8 |  128 | 0.000838305 |   0.789075 |           |\n",
            "| train_771eb_00060 | PENDING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00041 | RUNNING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00043 | RUNNING    |                   |           10 |   32 |   32 | 0.000552758 |   0.929839 |           |\n",
            "| train_771eb_00044 | RUNNING    | 192.168.1.4:22906 |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |  10.9219  |\n",
            "| train_771eb_00045 | RUNNING    |                   |         1000 |   64 |   64 | 0.0770321   |   0.819817 |           |\n",
            "| train_771eb_00046 | RUNNING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00047 | RUNNING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | RUNNING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (39 PENDING, 5 RUNNING, 35 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22906)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00043:\n",
            "  date: 2020-10-18_18-33-11\n",
            "  done: false\n",
            "  experiment_id: 625fa8ec48ea4e50a46bd09cb6c79b33\n",
            "  experiment_tag: 43_batch_size=10,h1=32,h2=32,lr=0.00055276,momentum=0.92984\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.733546620666981\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22885\n",
            "  time_since_restore: 383.9922149181366\n",
            "  time_this_iter_s: 383.9922149181366\n",
            "  time_total_s: 383.9922149181366\n",
            "  timestamp: 1603033391\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00043\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m [50000] loss: 13.734\n",
            "\u001b[2m\u001b[36m(pid=22885)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-3.4%): {PENDING: 7, RUNNING: 12, TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (45 PENDING, 12 RUNNING, 43 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00055 | PENDING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | PENDING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | PENDING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00058 | PENDING    |                   |         1000 |    8 |    8 | 0.000478096 |   0.842333 |           |\n",
            "| train_771eb_00059 | PENDING    |                   |           10 |    8 |  128 | 0.000838305 |   0.789075 |           |\n",
            "| train_771eb_00060 | PENDING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | PENDING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00041 | RUNNING    |                   |            1 |   16 |  128 | 0.000243597 |   0.823279 |           |\n",
            "| train_771eb_00043 | RUNNING    | 192.168.1.4:22885 |           10 |   32 |   32 | 0.000552758 |   0.929839 |  13.7335  |\n",
            "| train_771eb_00045 | RUNNING    |                   |         1000 |   64 |   64 | 0.0770321   |   0.819817 |           |\n",
            "| train_771eb_00046 | RUNNING    |                   |           10 |  128 |    8 | 0.00125046  |   0.909294 |           |\n",
            "| train_771eb_00047 | RUNNING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | RUNNING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | RUNNING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (38 PENDING, 5 RUNNING, 36 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00045:\n",
            "  date: 2020-10-18_18-33-14\n",
            "  done: false\n",
            "  experiment_id: af756a0ac40c47718e7eadc3090c6893\n",
            "  experiment_tag: 45_batch_size=1000,h1=64,h2=64,lr=0.077032,momentum=0.81982\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22929\n",
            "  time_since_restore: 384.1583547592163\n",
            "  time_this_iter_s: 384.1583547592163\n",
            "  time_total_s: 384.1583547592163\n",
            "  timestamp: 1603033394\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00045\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=22929)\u001b[0m Finished Training\n",
            "Result for train_771eb_00041:\n",
            "  date: 2020-10-18_18-33-15\n",
            "  done: false\n",
            "  experiment_id: 2f50e39e862345769c6cf8f5925defb6\n",
            "  experiment_tag: 41_batch_size=1,h1=16,h2=128,lr=0.0002436,momentum=0.82328\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.169814102506638\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22833\n",
            "  time_since_restore: 397.2469997406006\n",
            "  time_this_iter_s: 397.2469997406006\n",
            "  time_total_s: 397.2469997406006\n",
            "  timestamp: 1603033395\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00041\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m [50000] loss: 9.170\n",
            "\u001b[2m\u001b[36m(pid=22833)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00046:\n",
            "  date: 2020-10-18_18-33-17\n",
            "  done: false\n",
            "  experiment_id: 6a1ce8112e1540c7a117af7240d272c4\n",
            "  experiment_tag: 46_batch_size=10,h1=128,h2=8,lr=0.0012505,momentum=0.90929\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.18870419602394\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22933\n",
            "  time_since_restore: 379.42959904670715\n",
            "  time_this_iter_s: 379.42959904670715\n",
            "  time_total_s: 379.42959904670715\n",
            "  timestamp: 1603033397\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00046\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m [50000] loss: 36.189\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-4.0%): {PENDING: 4, RUNNING: 12, TERMINATED: 18} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (42 PENDING, 12 RUNNING, 46 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00058 | PENDING    |                   |         1000 |    8 |    8 | 0.000478096 |   0.842333 |           |\n",
            "| train_771eb_00059 | PENDING    |                   |           10 |    8 |  128 | 0.000838305 |   0.789075 |           |\n",
            "| train_771eb_00060 | PENDING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | PENDING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | PENDING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | PENDING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | PENDING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00046 | RUNNING    | 192.168.1.4:22933 |           10 |  128 |    8 | 0.00125046  |   0.909294 |  36.1887  |\n",
            "| train_771eb_00047 | RUNNING    |                   |          100 |   16 |    8 | 0.0004038   |   0.760716 |           |\n",
            "| train_771eb_00048 | RUNNING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | RUNNING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | RUNNING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | RUNNING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | RUNNING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (35 PENDING, 5 RUNNING, 39 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=22933)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00047:\n",
            "  date: 2020-10-18_18-33-25\n",
            "  done: false\n",
            "  experiment_id: be48d4ba3e4d4cc587748c3a1801b2c4\n",
            "  experiment_tag: 47_batch_size=100,h1=16,h2=8,lr=0.0004038,momentum=0.76072\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.11016845636368\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 22979\n",
            "  time_since_restore: 381.2604286670685\n",
            "  time_this_iter_s: 381.2604286670685\n",
            "  time_total_s: 381.2604286670685\n",
            "  timestamp: 1603033405\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00047\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m [50000] loss: 36.110\n",
            "\u001b[2m\u001b[36m(pid=22979)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-4.2%): {PENDING: 3, RUNNING: 12, TERMINATED: 19} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (41 PENDING, 12 RUNNING, 47 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00059 | PENDING    |                   |           10 |    8 |  128 | 0.000838305 |   0.789075 |           |\n",
            "| train_771eb_00060 | PENDING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | PENDING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | PENDING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | PENDING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | PENDING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | PENDING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00047 | RUNNING    | 192.168.1.4:22979 |          100 |   16 |    8 | 0.0004038   |   0.760716 |  36.1102  |\n",
            "| train_771eb_00048 | RUNNING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | RUNNING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | RUNNING    |                   |          100 |   64 |   16 | 0.0011488   |   0.937267 |           |\n",
            "| train_771eb_00051 | RUNNING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | RUNNING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | RUNNING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (34 PENDING, 5 RUNNING, 40 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [ 5000] loss: 68.827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [ 5000] loss: 53.507\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [ 5000] loss: 60.903\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [ 5000] loss: 49.737\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [ 5000] loss: 36.664\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [ 5000] loss: 62.955\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [ 5000] loss: 58.817\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [ 5000] loss: 40.881\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [ 5000] loss: 57.054\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [ 5000] loss: 205.897\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [10000] loss: 39.253\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [ 5000] loss: 27.326\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [10000] loss: 36.602\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [10000] loss: 59.854\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [10000] loss: 24.092\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [10000] loss: 36.139\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [10000] loss: 31.914\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [10000] loss: 26.802\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [10000] loss: 19.645\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [10000] loss: 81.270\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [10000] loss: 29.190\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [15000] loss: 35.857\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [15000] loss: 29.055\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [10000] loss: 19.397\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [15000] loss: 61.426\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [15000] loss: 36.293\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [15000] loss: 18.877\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [15000] loss: 24.365\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [15000] loss: 21.636\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [15000] loss: 56.014\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [15000] loss: 15.859\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [15000] loss: 22.879\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [15000] loss: 15.835\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [20000] loss: 24.012\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [20000] loss: 35.453\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [20000] loss: 36.284\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [20000] loss: 15.136\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [20000] loss: 61.672\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [20000] loss: 20.197\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [20000] loss: 19.428\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [20000] loss: 45.018\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [20000] loss: 13.717\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [20000] loss: 18.728\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [25000] loss: 36.218\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [20000] loss: 13.106\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [25000] loss: 21.267\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [25000] loss: 36.317\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [25000] loss: 12.954\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [25000] loss: 57.870\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [25000] loss: 17.944\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [25000] loss: 17.241\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [25000] loss: 39.545\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [25000] loss: 12.376\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [25000] loss: 17.098\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [30000] loss: 36.218\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [30000] loss: 18.944\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [25000] loss: 12.858\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [30000] loss: 35.817\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [30000] loss: 12.109\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [30000] loss: 60.855\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [30000] loss: 15.718\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [30000] loss: 16.175\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [30000] loss: 37.446\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [30000] loss: 11.664\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [35000] loss: 36.242\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [30000] loss: 15.416\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [30000] loss: 12.999\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [35000] loss: 16.854\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [35000] loss: 36.952\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [35000] loss: 11.193\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [35000] loss: 64.002\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [35000] loss: 14.632\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [35000] loss: 15.448\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [35000] loss: 36.160\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [35000] loss: 11.264\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [40000] loss: 36.094\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [35000] loss: 11.030\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [35000] loss: 14.966\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [40000] loss: 15.227\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [40000] loss: 35.935\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [40000] loss: 10.854\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [40000] loss: 61.824\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [40000] loss: 13.153\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [40000] loss: 14.737\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [40000] loss: 35.971\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [40000] loss: 10.872\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [45000] loss: 36.449\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [40000] loss: 11.071\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [45000] loss: 13.850\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [40000] loss: 14.664\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [45000] loss: 36.050\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [45000] loss: 59.037\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [45000] loss: 10.516\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [45000] loss: 12.222\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [45000] loss: 13.923\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [45000] loss: 35.961\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [45000] loss: 10.680\n",
            "Result for train_771eb_00050:\n",
            "  date: 2020-10-18_18-39-05\n",
            "  done: false\n",
            "  experiment_id: 1008107edab74c61a25b74f95865069f\n",
            "  experiment_tag: 50_batch_size=100,h1=64,h2=16,lr=0.0011488,momentum=0.93727\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.90958592488766\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23146\n",
            "  time_since_restore: 372.21738266944885\n",
            "  time_this_iter_s: 372.21738266944885\n",
            "  time_total_s: 372.21738266944885\n",
            "  timestamp: 1603033745\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00050\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m [50000] loss: 35.910\n",
            "\u001b[2m\u001b[36m(pid=23146)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-4.4%): {PENDING: 2, RUNNING: 12, TERMINATED: 20} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (40 PENDING, 12 RUNNING, 48 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00060 | PENDING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | PENDING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | PENDING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | PENDING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | PENDING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | PENDING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | PENDING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00048 | RUNNING    |                   |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |           |\n",
            "| train_771eb_00049 | RUNNING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00050 | RUNNING    | 192.168.1.4:23146 |          100 |   64 |   16 | 0.0011488   |   0.937267 |  35.9096  |\n",
            "| train_771eb_00051 | RUNNING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | RUNNING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | RUNNING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | RUNNING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (33 PENDING, 5 RUNNING, 41 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [45000] loss: 10.294\n",
            "Result for train_771eb_00048:\n",
            "  date: 2020-10-18_18-39-12\n",
            "  done: false\n",
            "  experiment_id: 8a05aceb35274d21bbd11035f0e3c4ef\n",
            "  experiment_tag: 48_batch_size=10,h1=64,h2=64,lr=3.4511e-05,momentum=0.70613\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.093030592131615\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23097\n",
            "  time_since_restore: 387.196861743927\n",
            "  time_this_iter_s: 387.196861743927\n",
            "  time_total_s: 387.196861743927\n",
            "  timestamp: 1603033752\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00048\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-4.6%): {PENDING: 1, RUNNING: 12, TERMINATED: 21} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 38} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (39 PENDING, 12 RUNNING, 49 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00061 | PENDING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | PENDING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | PENDING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | PENDING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | PENDING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | PENDING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00067 | PENDING    |                   |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00048 | RUNNING    | 192.168.1.4:23097 |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |  13.093   |\n",
            "| train_771eb_00049 | RUNNING    |                   |          100 |   16 |  128 | 0.0167206   |   0.769885 |           |\n",
            "| train_771eb_00051 | RUNNING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | RUNNING    |                   |           10 |   16 |   32 | 0.00159151  |   0.853648 |           |\n",
            "| train_771eb_00053 | RUNNING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | RUNNING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00055 | RUNNING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (32 PENDING, 5 RUNNING, 42 TERMINATED)\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m [50000] loss: 13.093\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23097)\u001b[0m Finished Training\n",
            "Result for train_771eb_00049:\n",
            "  date: 2020-10-18_18-39-13\n",
            "  done: false\n",
            "  experiment_id: ce9449c40b81496985016504f9d4c2d2\n",
            "  experiment_tag: 49_batch_size=100,h1=16,h2=128,lr=0.016721,momentum=0.76988\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23120\n",
            "  time_since_restore: 383.4698865413666\n",
            "  time_this_iter_s: 383.4698865413666\n",
            "  time_total_s: 383.4698865413666\n",
            "  timestamp: 1603033753\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00049\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23120)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [45000] loss: 13.548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00052:\n",
            "  date: 2020-10-18_18-39-18\n",
            "  done: false\n",
            "  experiment_id: e1814a6a9cea46af8036abe73ab97e63\n",
            "  experiment_tag: 52_batch_size=10,h1=16,h2=32,lr=0.0015915,momentum=0.85365\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.95758439803124\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23154\n",
            "  time_since_restore: 379.34147119522095\n",
            "  time_this_iter_s: 379.34147119522095\n",
            "  time_total_s: 379.34147119522095\n",
            "  timestamp: 1603033758\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00052\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m [50000] loss: 35.958\n",
            "\u001b[2m\u001b[36m(pid=23154)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-5.1%): {RUNNING: 11, TERMINATED: 23} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 37, RUNNING: 1} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (37 PENDING, 12 RUNNING, 51 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00063 | PENDING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | PENDING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | PENDING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | PENDING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00067 | PENDING    |                   |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00068 | PENDING    |                   |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00069 | PENDING    |                   |         1000 |  128 |    8 | 0.000156659 |   0.780344 |           |\n",
            "| train_771eb_00051 | RUNNING    |                   |            1 |  128 |   16 | 0.0991417   |   0.95929  |           |\n",
            "| train_771eb_00052 | RUNNING    | 192.168.1.4:23154 |           10 |   16 |   32 | 0.00159151  |   0.853648 |  35.9576  |\n",
            "| train_771eb_00053 | RUNNING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | RUNNING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00055 | RUNNING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | RUNNING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | RUNNING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (30 PENDING, 5 RUNNING, 44 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00051:\n",
            "  date: 2020-10-18_18-39-29\n",
            "  done: false\n",
            "  experiment_id: c8f60eabcdd745abaa43a1c94345e175\n",
            "  experiment_tag: 51_batch_size=1,h1=128,h2=16,lr=0.099142,momentum=0.95929\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 62.9079971945107\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23151\n",
            "  time_since_restore: 395.7982394695282\n",
            "  time_this_iter_s: 395.7982394695282\n",
            "  time_total_s: 395.7982394695282\n",
            "  timestamp: 1603033769\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00051\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m [50000] loss: 62.908\n",
            "\u001b[2m\u001b[36m(pid=23151)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-5.3%): {RUNNING: 10, TERMINATED: 24} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 36, RUNNING: 2} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (36 PENDING, 12 RUNNING, 52 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00064 | PENDING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | PENDING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | PENDING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00067 | PENDING    |                   |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00068 | PENDING    |                   |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00069 | PENDING    |                   |         1000 |  128 |    8 | 0.000156659 |   0.780344 |           |\n",
            "| train_771eb_00070 | PENDING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |           |\n",
            "| train_771eb_00051 | RUNNING    | 192.168.1.4:23151 |            1 |  128 |   16 | 0.0991417   |   0.95929  |  62.908   |\n",
            "| train_771eb_00053 | RUNNING    |                   |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |           |\n",
            "| train_771eb_00054 | RUNNING    |                   |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |           |\n",
            "| train_771eb_00055 | RUNNING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | RUNNING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | RUNNING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00058 | RUNNING    |                   |         1000 |    8 |    8 | 0.000478096 |   0.842333 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (29 PENDING, 5 RUNNING, 45 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00053:\n",
            "  date: 2020-10-18_18-39-33\n",
            "  done: false\n",
            "  experiment_id: ed5f178c57374354b6cd5bbe03b29187\n",
            "  experiment_tag: 53_batch_size=1,h1=64,h2=8,lr=7.7024e-05,momentum=0.72219\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.487573445922136\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23165\n",
            "  time_since_restore: 392.9422285556793\n",
            "  time_this_iter_s: 392.9422285556793\n",
            "  time_total_s: 392.9422285556793\n",
            "  timestamp: 1603033773\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00053\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m [50000] loss: 10.488\n",
            "\u001b[2m\u001b[36m(pid=23165)\u001b[0m Finished Training\n",
            "Result for train_771eb_00054:\n",
            "  date: 2020-10-18_18-39-35\n",
            "  done: false\n",
            "  experiment_id: 078979c26bd74770b7ae1298c8337bba\n",
            "  experiment_tag: 54_batch_size=10,h1=128,h2=128,lr=3.1276e-05,momentum=0.82022\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.313369509589672\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23153\n",
            "  time_since_restore: 387.399343252182\n",
            "  time_this_iter_s: 387.399343252182\n",
            "  time_total_s: 387.399343252182\n",
            "  timestamp: 1603033775\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00054\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.3/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-5.7%): {RUNNING: 8, TERMINATED: 26} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 34, RUNNING: 4} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (34 PENDING, 12 RUNNING, 54 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00066 | PENDING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00067 | PENDING    |                   |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00068 | PENDING    |                   |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00069 | PENDING    |                   |         1000 |  128 |    8 | 0.000156659 |   0.780344 |           |\n",
            "| train_771eb_00070 | PENDING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |           |\n",
            "| train_771eb_00071 | PENDING    |                   |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |           |\n",
            "| train_771eb_00072 | PENDING    |                   |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |           |\n",
            "| train_771eb_00054 | RUNNING    | 192.168.1.4:23153 |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |  11.3134  |\n",
            "| train_771eb_00055 | RUNNING    |                   |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |           |\n",
            "| train_771eb_00056 | RUNNING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | RUNNING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00058 | RUNNING    |                   |         1000 |    8 |    8 | 0.000478096 |   0.842333 |           |\n",
            "| train_771eb_00059 | RUNNING    |                   |           10 |    8 |  128 | 0.000838305 |   0.789075 |           |\n",
            "| train_771eb_00060 | RUNNING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (27 PENDING, 5 RUNNING, 47 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m [50000] loss: 11.313\n",
            "\u001b[2m\u001b[36m(pid=23153)\u001b[0m Finished Training\n",
            "Result for train_771eb_00055:\n",
            "  date: 2020-10-18_18-39-35\n",
            "  done: false\n",
            "  experiment_id: 0ef2c683da574f92a57a4fb18b03dd49\n",
            "  experiment_tag: 55_batch_size=10,h1=8,h2=64,lr=4.0157e-05,momentum=0.83479\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.601313618278503\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23271\n",
            "  time_since_restore: 381.6303656101227\n",
            "  time_this_iter_s: 381.6303656101227\n",
            "  time_total_s: 381.6303656101227\n",
            "  timestamp: 1603033775\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00055\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m [50000] loss: 13.601\n",
            "\u001b[2m\u001b[36m(pid=23271)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00058:\n",
            "  date: 2020-10-18_18-39-41\n",
            "  done: false\n",
            "  experiment_id: 3d075519cc874762b4cbde8316f61d18\n",
            "  experiment_tag: 58_batch_size=1000,h1=8,h2=8,lr=0.0004781,momentum=0.84233\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.64502507107258\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23299\n",
            "  time_since_restore: 382.12809109687805\n",
            "  time_this_iter_s: 382.12809109687805\n",
            "  time_total_s: 382.12809109687805\n",
            "  timestamp: 1603033781\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00058\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m [50000] loss: 35.645\n",
            "\u001b[2m\u001b[36m(pid=23299)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-6.1%): {RUNNING: 6, TERMINATED: 28} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 32, RUNNING: 6} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (32 PENDING, 12 RUNNING, 56 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00068 | PENDING    |                   |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00069 | PENDING    |                   |         1000 |  128 |    8 | 0.000156659 |   0.780344 |           |\n",
            "| train_771eb_00070 | PENDING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |           |\n",
            "| train_771eb_00071 | PENDING    |                   |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |           |\n",
            "| train_771eb_00072 | PENDING    |                   |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |           |\n",
            "| train_771eb_00073 | PENDING    |                   |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |           |\n",
            "| train_771eb_00074 | PENDING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 |           |\n",
            "| train_771eb_00056 | RUNNING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00057 | RUNNING    |                   |            1 |    8 |  128 | 0.000145862 |   0.71493  |           |\n",
            "| train_771eb_00058 | RUNNING    | 192.168.1.4:23299 |         1000 |    8 |    8 | 0.000478096 |   0.842333 |  35.645   |\n",
            "| train_771eb_00059 | RUNNING    |                   |           10 |    8 |  128 | 0.000838305 |   0.789075 |           |\n",
            "| train_771eb_00060 | RUNNING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | RUNNING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | RUNNING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (25 PENDING, 5 RUNNING, 49 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_771eb_00057:\n",
            "  date: 2020-10-18_18-39-42\n",
            "  done: false\n",
            "  experiment_id: 1f5276734bc24bb8a2a2993aac2ec261\n",
            "  experiment_tag: 57_batch_size=1,h1=8,h2=128,lr=0.00014586,momentum=0.71493\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.433691724008321\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23309\n",
            "  time_since_restore: 384.7118854522705\n",
            "  time_this_iter_s: 384.7118854522705\n",
            "  time_total_s: 384.7118854522705\n",
            "  timestamp: 1603033782\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00057\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m [50000] loss: 10.434\n",
            "\u001b[2m\u001b[36m(pid=23309)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [ 5000] loss: 48.232\n",
            "Result for train_771eb_00059:\n",
            "  date: 2020-10-18_18-39-48\n",
            "  done: false\n",
            "  experiment_id: a0cbc97c1a9c4159a8de39a7865eefc2\n",
            "  experiment_tag: 59_batch_size=10,h1=8,h2=128,lr=0.0008383,momentum=0.78908\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.23162809214592\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23305\n",
            "  time_since_restore: 380.78198623657227\n",
            "  time_this_iter_s: 380.78198623657227\n",
            "  time_total_s: 380.78198623657227\n",
            "  timestamp: 1603033788\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00059\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-6.5%): {RUNNING: 4, TERMINATED: 30} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 30, RUNNING: 8} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (30 PENDING, 12 RUNNING, 58 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00070 | PENDING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |           |\n",
            "| train_771eb_00071 | PENDING    |                   |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |           |\n",
            "| train_771eb_00072 | PENDING    |                   |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |           |\n",
            "| train_771eb_00073 | PENDING    |                   |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |           |\n",
            "| train_771eb_00074 | PENDING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 |           |\n",
            "| train_771eb_00075 | PENDING    |                   |           10 |   32 |  128 | 0.000563108 |   0.810928 |           |\n",
            "| train_771eb_00076 | PENDING    |                   |         1000 |   64 |  128 | 0.0172635   |   0.539725 |           |\n",
            "| train_771eb_00056 | RUNNING    |                   |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |           |\n",
            "| train_771eb_00059 | RUNNING    | 192.168.1.4:23305 |           10 |    8 |  128 | 0.000838305 |   0.789075 |  11.2316  |\n",
            "| train_771eb_00060 | RUNNING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | RUNNING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | RUNNING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | RUNNING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | RUNNING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (23 PENDING, 5 RUNNING, 51 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m [50000] loss: 11.232\n",
            "\u001b[2m\u001b[36m(pid=23305)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [ 5000] loss: 84282542493968.406\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [ 5000] loss: 90183997.295\n",
            "Result for train_771eb_00056:\n",
            "  date: 2020-10-18_18-39-55\n",
            "  done: false\n",
            "  experiment_id: 551ca6c208f747fdb5f330864b14ebab\n",
            "  experiment_tag: 56_batch_size=1,h1=8,h2=64,lr=7.9182e-05,momentum=0.63702\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.397397040486336\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23294\n",
            "  time_since_restore: 398.8474826812744\n",
            "  time_this_iter_s: 398.8474826812744\n",
            "  time_total_s: 398.8474826812744\n",
            "  timestamp: 1603033795\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00056\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m [50000] loss: 13.397\n",
            "\u001b[2m\u001b[36m(pid=23294)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-6.8%): {RUNNING: 3, TERMINATED: 31} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 29, RUNNING: 9} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (29 PENDING, 12 RUNNING, 59 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00071 | PENDING    |                   |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |           |\n",
            "| train_771eb_00072 | PENDING    |                   |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |           |\n",
            "| train_771eb_00073 | PENDING    |                   |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |           |\n",
            "| train_771eb_00074 | PENDING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 |           |\n",
            "| train_771eb_00075 | PENDING    |                   |           10 |   32 |  128 | 0.000563108 |   0.810928 |           |\n",
            "| train_771eb_00076 | PENDING    |                   |         1000 |   64 |  128 | 0.0172635   |   0.539725 |           |\n",
            "| train_771eb_00077 | PENDING    |                   |            1 |    8 |  128 | 0.00299448  |   0.802929 |           |\n",
            "| train_771eb_00056 | RUNNING    | 192.168.1.4:23294 |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |  13.3974  |\n",
            "| train_771eb_00060 | RUNNING    |                   |           10 |   32 |   32 | 0.000134219 |   0.611783 |           |\n",
            "| train_771eb_00061 | RUNNING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | RUNNING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | RUNNING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | RUNNING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | RUNNING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (22 PENDING, 5 RUNNING, 52 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [ 5000] loss: 44.752\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [ 5000] loss: 37.628\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [ 5000] loss: 76.867\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [ 5000] loss: 49.724\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [ 5000] loss: 29.910\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [10000] loss: 23.726\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [ 5000] loss: 102.862\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [ 5000] loss: 45.907\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [10000] loss: 113945821261045891596288.000\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [ 5000] loss: 43.797\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [10000] loss: 36.479\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [10000] loss: 36.553\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [10000] loss: 20.105\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [10000] loss: 38.247\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [10000] loss: 21.333\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [10000] loss: 59.799\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [15000] loss: 17.373\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [15000] loss: 154046048385730834316804027842560.000\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [10000] loss: 22.275\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [15000] loss: 35.841\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [10000] loss: 17.840\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [15000] loss: 36.461\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [15000] loss: 39.528\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [15000] loss: 36.217\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [15000] loss: 16.474\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [20000] loss: 14.279\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [15000] loss: 35.916\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [20000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [15000] loss: 14.775\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [20000] loss: 35.288\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [15000] loss: 15.844\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [20000] loss: 36.537\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [20000] loss: 36.796\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [20000] loss: 36.252\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [20000] loss: 16.361\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [25000] loss: 12.243\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [20000] loss: 35.801\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [25000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [20000] loss: 11.429\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [25000] loss: 35.569\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [20000] loss: 13.256\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [25000] loss: 35.287\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [25000] loss: 35.619\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [25000] loss: 35.603\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [25000] loss: 15.983\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [30000] loss: 11.554\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [25000] loss: 36.192\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [30000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [30000] loss: 35.968\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [25000] loss: 10.680\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [25000] loss: 11.587\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [30000] loss: 35.554\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [30000] loss: 36.735\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [30000] loss: 35.471\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [30000] loss: 13.808\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [35000] loss: 10.885\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [30000] loss: 35.640\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [35000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [30000] loss: 10.992\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [35000] loss: 36.201\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [30000] loss: 10.974\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [35000] loss: 36.086\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [35000] loss: 36.442\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [35000] loss: 35.670\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [35000] loss: 13.875\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [40000] loss: 10.713\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [35000] loss: 36.334\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [35000] loss: 10.032\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [40000] loss: 36.240\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [35000] loss: 10.582\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [40000] loss: 35.958\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [40000] loss: 35.609\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [40000] loss: 35.813\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [40000] loss: 12.373\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [45000] loss: 10.229\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [40000] loss: 35.463\n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [40000] loss: 9.686\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [45000] loss: 35.948\n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [40000] loss: 10.203\n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [45000] loss: 36.365\n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [45000] loss: 36.294\n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [45000] loss: 35.838\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [45000] loss: 13.327\n",
            "Result for train_771eb_00060:\n",
            "  date: 2020-10-18_18-45-33\n",
            "  done: false\n",
            "  experiment_id: e5b6033d52af4560b9090717cefe9098\n",
            "  experiment_tag: 60_batch_size=10,h1=32,h2=32,lr=0.00013422,momentum=0.61178\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.190934310209752\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23307\n",
            "  time_since_restore: 386.4396381378174\n",
            "  time_this_iter_s: 386.4396381378174\n",
            "  time_total_s: 386.4396381378174\n",
            "  timestamp: 1603034133\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00060\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m [50000] loss: 10.191\n",
            "\u001b[2m\u001b[36m(pid=23307)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [45000] loss: nan\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-7.0%): {RUNNING: 2, TERMINATED: 32} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=0.0%): {PENDING: 28, RUNNING: 10} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (28 PENDING, 12 RUNNING, 60 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00072 | PENDING    |                   |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |           |\n",
            "| train_771eb_00073 | PENDING    |                   |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |           |\n",
            "| train_771eb_00074 | PENDING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 |           |\n",
            "| train_771eb_00075 | PENDING    |                   |           10 |   32 |  128 | 0.000563108 |   0.810928 |           |\n",
            "| train_771eb_00076 | PENDING    |                   |         1000 |   64 |  128 | 0.0172635   |   0.539725 |           |\n",
            "| train_771eb_00077 | PENDING    |                   |            1 |    8 |  128 | 0.00299448  |   0.802929 |           |\n",
            "| train_771eb_00078 | PENDING    |                   |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |           |\n",
            "| train_771eb_00060 | RUNNING    | 192.168.1.4:23307 |           10 |   32 |   32 | 0.000134219 |   0.611783 |  10.1909  |\n",
            "| train_771eb_00061 | RUNNING    |                   |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00062 | RUNNING    |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 |           |\n",
            "| train_771eb_00063 | RUNNING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | RUNNING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | RUNNING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | RUNNING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (21 PENDING, 5 RUNNING, 53 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [45000] loss: 35.266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:45:45,849\tINFO hyperband.py:211 -- PAUSE for train_771eb_00062 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00062:\n",
            "  date: 2020-10-18_18-45-45\n",
            "  done: false\n",
            "  experiment_id: 02881589c06c437c89f0d8ec877aec39\n",
            "  experiment_tag: 62_batch_size=1000,h1=8,h2=16,lr=0.014808,momentum=0.61072\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23497\n",
            "  time_since_restore: 389.482652425766\n",
            "  time_this_iter_s: 389.482652425766\n",
            "  time_total_s: 389.482652425766\n",
            "  timestamp: 1603034145\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00062\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23497)\u001b[0m [50000] loss: nan\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-7.0%): {RUNNING: 1, TERMINATED: 33} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-0.2%): {PAUSED: 1, PENDING: 27, RUNNING: 10} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (1 PAUSED, 27 PENDING, 11 RUNNING, 61 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00073 | PENDING    |       |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |           |\n",
            "| train_771eb_00074 | PENDING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |           |\n",
            "| train_771eb_00075 | PENDING    |       |           10 |   32 |  128 | 0.000563108 |   0.810928 |           |\n",
            "| train_771eb_00076 | PENDING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |           |\n",
            "| train_771eb_00077 | PENDING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |           |\n",
            "| train_771eb_00078 | PENDING    |       |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |           |\n",
            "| train_771eb_00079 | PENDING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |           |\n",
            "| train_771eb_00061 | RUNNING    |       |         1000 |  128 |  128 | 0.000370386 |   0.762688 |           |\n",
            "| train_771eb_00063 | RUNNING    |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | RUNNING    |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | RUNNING    |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | RUNNING    |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00067 | RUNNING    |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00068 | RUNNING    |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (20 PENDING, 4 RUNNING, 54 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [45000] loss: 10.025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00061:\n",
            "  date: 2020-10-18_18-45-51\n",
            "  done: false\n",
            "  experiment_id: 2c0f692e385645b59987327e25d95dab\n",
            "  experiment_tag: 61_batch_size=1000,h1=128,h2=128,lr=0.00037039,momentum=0.76269\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23476\n",
            "  time_since_restore: 396.06416416168213\n",
            "  time_this_iter_s: 396.06416416168213\n",
            "  time_total_s: 396.06416416168213\n",
            "  timestamp: 1603034151\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00061\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=34, Milestone (r)=3, completed=-7.2%): {RUNNING: 1, TERMINATED: 33} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-0.2%): {PAUSED: 1, PENDING: 26, RUNNING: 11} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (1 PAUSED, 26 PENDING, 12 RUNNING, 61 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |                   |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00074 | PENDING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 |           |\n",
            "| train_771eb_00075 | PENDING    |                   |           10 |   32 |  128 | 0.000563108 |   0.810928 |           |\n",
            "| train_771eb_00076 | PENDING    |                   |         1000 |   64 |  128 | 0.0172635   |   0.539725 |           |\n",
            "| train_771eb_00077 | PENDING    |                   |            1 |    8 |  128 | 0.00299448  |   0.802929 |           |\n",
            "| train_771eb_00078 | PENDING    |                   |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |           |\n",
            "| train_771eb_00079 | PENDING    |                   |            1 |   16 |  128 | 0.00387142  |   0.570771 |           |\n",
            "| train_771eb_00080 | PENDING    |                   |         1000 |   64 |   16 | 0.00205382  |   0.632732 |           |\n",
            "| train_771eb_00061 | RUNNING    | 192.168.1.4:23476 |         1000 |  128 |  128 | 0.000370386 |   0.762688 | nan       |\n",
            "| train_771eb_00063 | RUNNING    |                   |          100 |   64 |    8 | 0.00112387  |   0.597223 |           |\n",
            "| train_771eb_00064 | RUNNING    |                   |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | RUNNING    |                   |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00066 | RUNNING    |                   |         1000 |   32 |    8 | 0.000819632 |   0.665984 |           |\n",
            "| train_771eb_00067 | RUNNING    |                   |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00068 | RUNNING    |                   |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (19 PENDING, 5 RUNNING, 54 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23476)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:45:51,435\tINFO hyperband.py:211 -- PAUSE for train_771eb_00063 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00063:\n",
            "  date: 2020-10-18_18-45-51\n",
            "  done: false\n",
            "  experiment_id: 95ef8516b919421590be86ef183c17f1\n",
            "  experiment_tag: 63_batch_size=100,h1=64,h2=8,lr=0.0011239,momentum=0.59722\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.264235120391845\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23525\n",
            "  time_since_restore: 389.84832739830017\n",
            "  time_this_iter_s: 389.84832739830017\n",
            "  time_total_s: 389.84832739830017\n",
            "  timestamp: 1603034151\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00063\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23525)\u001b[0m [50000] loss: 36.264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:46:01,607\tINFO hyperband.py:211 -- PAUSE for train_771eb_00066 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00066:\n",
            "  date: 2020-10-18_18-46-01\n",
            "  done: false\n",
            "  experiment_id: 735e53816fc5487b90d8743bb22c1b46\n",
            "  experiment_tag: 66_batch_size=1000,h1=32,h2=8,lr=0.00081963,momentum=0.66598\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.77966511955261\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23599\n",
            "  time_since_restore: 383.88595509529114\n",
            "  time_this_iter_s: 383.88595509529114\n",
            "  time_total_s: 383.88595509529114\n",
            "  timestamp: 1603034161\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00066\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23599)\u001b[0m [50000] loss: 35.780\n",
            "== Status ==\n",
            "Memory usage on this node: 7.0/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-0.7%): {PAUSED: 3, PENDING: 24, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (3 PAUSED, 24 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00076 | PENDING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |           |\n",
            "| train_771eb_00077 | PENDING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |           |\n",
            "| train_771eb_00078 | PENDING    |       |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |           |\n",
            "| train_771eb_00079 | PENDING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |           |\n",
            "| train_771eb_00080 | PENDING    |       |         1000 |   64 |   16 | 0.00205382  |   0.632732 |           |\n",
            "| train_771eb_00081 | PENDING    |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |           |\n",
            "| train_771eb_00064 | RUNNING    |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |           |\n",
            "| train_771eb_00065 | RUNNING    |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |           |\n",
            "| train_771eb_00067 | RUNNING    |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |           |\n",
            "| train_771eb_00068 | RUNNING    |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 |           |\n",
            "| train_771eb_00069 | RUNNING    |       |         1000 |  128 |    8 | 0.000156659 |   0.780344 |           |\n",
            "| train_771eb_00070 | RUNNING    |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (18 PENDING, 5 RUNNING, 56 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:46:03,224\tINFO hyperband.py:211 -- PAUSE for train_771eb_00065 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00065:\n",
            "  date: 2020-10-18_18-46-03\n",
            "  done: false\n",
            "  experiment_id: 3fb9368ec4284a5e825f04fdeba52058\n",
            "  experiment_tag: 65_batch_size=100,h1=16,h2=32,lr=0.00017108,momentum=0.8337\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.113847293782236\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23578\n",
            "  time_since_restore: 386.6401963233948\n",
            "  time_this_iter_s: 386.6401963233948\n",
            "  time_total_s: 386.6401963233948\n",
            "  timestamp: 1603034163\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00065\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23578)\u001b[0m [50000] loss: 35.114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:46:04,320\tINFO hyperband.py:211 -- PAUSE for train_771eb_00064 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00064:\n",
            "  date: 2020-10-18_18-46-04\n",
            "  done: false\n",
            "  experiment_id: 6f46681884f3407fa306d390be9a7d07\n",
            "  experiment_tag: 64_batch_size=10,h1=64,h2=16,lr=0.0053707,momentum=0.57448\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.71646088113785\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23555\n",
            "  time_since_restore: 391.8070385456085\n",
            "  time_this_iter_s: 391.8070385456085\n",
            "  time_total_s: 391.8070385456085\n",
            "  timestamp: 1603034164\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00064\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23555)\u001b[0m [50000] loss: 35.716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [45000] loss: 9.949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:46:07,630\tINFO hyperband.py:211 -- PAUSE for train_771eb_00067 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00067:\n",
            "  date: 2020-10-18_18-46-07\n",
            "  done: false\n",
            "  experiment_id: 8aca43a434da49078e51071cc7e3cef9\n",
            "  experiment_tag: 67_batch_size=10,h1=8,h2=64,lr=0.0014643,momentum=0.76008\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.187707028079032\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23607\n",
            "  time_since_restore: 389.6709129810333\n",
            "  time_this_iter_s: 389.6709129810333\n",
            "  time_total_s: 389.6709129810333\n",
            "  timestamp: 1603034167\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00067\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-1.5%): {PAUSED: 6, PENDING: 21, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (6 PAUSED, 21 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00079 | PENDING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |          |\n",
            "| train_771eb_00080 | PENDING    |       |         1000 |   64 |   16 | 0.00205382  |   0.632732 |          |\n",
            "| train_771eb_00081 | PENDING    |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |          |\n",
            "| train_771eb_00082 | PENDING    |       |         1000 |  128 |   16 | 0.000311907 |   0.875645 |          |\n",
            "| train_771eb_00083 | PENDING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |          |\n",
            "| train_771eb_00068 | RUNNING    |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 |          |\n",
            "| train_771eb_00069 | RUNNING    |       |         1000 |  128 |    8 | 0.000156659 |   0.780344 |          |\n",
            "| train_771eb_00070 | RUNNING    |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |          |\n",
            "| train_771eb_00071 | RUNNING    |       |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |          |\n",
            "| train_771eb_00072 | RUNNING    |       |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (1 PAUSED, 16 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=23607)\u001b[0m [50000] loss: 13.188\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:46:10,664\tINFO hyperband.py:211 -- PAUSE for train_771eb_00068 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00068:\n",
            "  date: 2020-10-18_18-46-10\n",
            "  done: false\n",
            "  experiment_id: 659b59e8d5eb4fbfbedd797c7dce58ac\n",
            "  experiment_tag: 68_batch_size=1000,h1=32,h2=64,lr=0.064762,momentum=0.71047\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23620\n",
            "  time_since_restore: 387.95159125328064\n",
            "  time_this_iter_s: 387.95159125328064\n",
            "  time_total_s: 387.95159125328064\n",
            "  timestamp: 1603034170\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00068\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23620)\u001b[0m [50000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [ 5000] loss: 43.429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:46:19,570\tINFO hyperband.py:211 -- PAUSE for train_771eb_00069 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00069:\n",
            "  date: 2020-10-18_18-46-19\n",
            "  done: false\n",
            "  experiment_id: f28524cf52ab4276a070d1019e8ffecd\n",
            "  experiment_tag: 69_batch_size=1000,h1=128,h2=8,lr=0.00015666,momentum=0.78034\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.972114915919306\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23605\n",
            "  time_since_restore: 395.5348641872406\n",
            "  time_this_iter_s: 395.5348641872406\n",
            "  time_total_s: 395.5348641872406\n",
            "  timestamp: 1603034179\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00069\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23605)\u001b[0m [50000] loss: 35.972\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-2.0%): {PAUSED: 8, PENDING: 19, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (8 PAUSED, 19 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00081 | PENDING    |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |          |\n",
            "| train_771eb_00082 | PENDING    |       |         1000 |  128 |   16 | 0.000311907 |   0.875645 |          |\n",
            "| train_771eb_00083 | PENDING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |          |\n",
            "| train_771eb_00084 | PENDING    |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 |          |\n",
            "| train_771eb_00085 | PENDING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |          |\n",
            "| train_771eb_00070 | RUNNING    |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |          |\n",
            "| train_771eb_00071 | RUNNING    |       |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |          |\n",
            "| train_771eb_00072 | RUNNING    |       |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |          |\n",
            "| train_771eb_00073 | RUNNING    |       |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |          |\n",
            "| train_771eb_00074 | RUNNING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (3 PAUSED, 14 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:46:24,563\tINFO hyperband.py:211 -- PAUSE for train_771eb_00071 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00071:\n",
            "  date: 2020-10-18_18-46-24\n",
            "  done: false\n",
            "  experiment_id: 4e00af705af542e2bee3eb5cc82b2676\n",
            "  experiment_tag: 71_batch_size=10,h1=16,h2=64,lr=2.6836e-05,momentum=0.98034\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 8.988415633827447\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23728\n",
            "  time_since_restore: 386.4121971130371\n",
            "  time_this_iter_s: 386.4121971130371\n",
            "  time_total_s: 386.4121971130371\n",
            "  timestamp: 1603034184\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00071\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23728)\u001b[0m [50000] loss: 8.988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [ 5000] loss: 60.617\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [ 5000] loss: 25.296\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [ 5000] loss: 27.395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:46:44,742\tINFO hyperband.py:211 -- PAUSE for train_771eb_00070 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00070:\n",
            "  date: 2020-10-18_18-46-44\n",
            "  done: false\n",
            "  experiment_id: 54f0cfb2b7ef44759afc3455f9f36f24\n",
            "  experiment_tag: 70_batch_size=1,h1=128,h2=64,lr=0.00014775,momentum=0.58938\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.931376569879054\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23604\n",
            "  time_since_restore: 414.68525648117065\n",
            "  time_this_iter_s: 414.68525648117065\n",
            "  time_total_s: 414.68525648117065\n",
            "  timestamp: 1603034204\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00070\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23604)\u001b[0m [50000] loss: 9.931\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-2.5%): {PAUSED: 10, PENDING: 17, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (10 PAUSED, 17 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00083 | PENDING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |          |\n",
            "| train_771eb_00084 | PENDING    |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 |          |\n",
            "| train_771eb_00085 | PENDING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |          |\n",
            "| train_771eb_00086 | PENDING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |          |\n",
            "| train_771eb_00087 | PENDING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |          |\n",
            "| train_771eb_00072 | RUNNING    |       |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |          |\n",
            "| train_771eb_00073 | RUNNING    |       |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |          |\n",
            "| train_771eb_00074 | RUNNING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |          |\n",
            "| train_771eb_00075 | RUNNING    |       |           10 |   32 |  128 | 0.000563108 |   0.810928 |          |\n",
            "| train_771eb_00076 | RUNNING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (5 PAUSED, 12 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [ 5000] loss: 80.608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [ 5000] loss: 22.640\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [ 5000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [10000] loss: 19.366\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [ 5000] loss: 54.097\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [10000] loss: 46.269\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [ 5000] loss: 38798647446450.711\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [10000] loss: 13.497\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [10000] loss: 41.832\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [10000] loss: 21.085\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [ 5000] loss: 37.108\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [10000] loss: 14.966\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [15000] loss: 14.668\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [10000] loss: 24.439\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [15000] loss: 52.725\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [15000] loss: 11.949\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [15000] loss: 31.438\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [10000] loss: 35.941\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [15000] loss: 18.068\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [15000] loss: 13.347\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [20000] loss: 12.155\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [15000] loss: 19.583\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [20000] loss: 46.725\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [20000] loss: 11.339\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [20000] loss: 23.837\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [15000] loss: 36.605\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [20000] loss: 18.252\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [20000] loss: 12.550\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [25000] loss: 11.329\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [25000] loss: 39.941\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [20000] loss: 22.829\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [25000] loss: 10.466\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [25000] loss: 21.651\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [20000] loss: 36.573\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [25000] loss: 12.438\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [25000] loss: 17.341\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [30000] loss: 10.861\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [30000] loss: 37.480\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [25000] loss: 17.669\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [30000] loss: 10.608\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [25000] loss: 35.771\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [30000] loss: 19.580\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [30000] loss: 17.089\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [35000] loss: 10.472\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [30000] loss: 12.066\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [35000] loss: 36.977\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [30000] loss: 24.870\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [35000] loss: 9.837\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [30000] loss: 35.303\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [35000] loss: 18.530\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [35000] loss: 16.693\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [40000] loss: 9.779\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [35000] loss: 11.540\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [40000] loss: 37.024\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [35000] loss: 18.882\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [40000] loss: 10.402\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [35000] loss: 35.836\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [40000] loss: 17.127\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [45000] loss: 9.573\n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [40000] loss: 16.609\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [40000] loss: 11.391\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [45000] loss: 36.668\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [40000] loss: 19.587\n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [45000] loss: 10.185\n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [40000] loss: 36.012\n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [45000] loss: 16.441\n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [45000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:03,799\tINFO hyperband.py:211 -- PAUSE for train_771eb_00072 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00072:\n",
            "  date: 2020-10-18_18-52-03\n",
            "  done: false\n",
            "  experiment_id: fb4a658c3b8c46a78d9f0a0996e83097\n",
            "  experiment_tag: 72_batch_size=10,h1=32,h2=128,lr=6.1146e-05,momentum=0.87704\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.592284817445279\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 23999\n",
            "  time_since_restore: 387.5869200229645\n",
            "  time_this_iter_s: 387.5869200229645\n",
            "  time_total_s: 387.5869200229645\n",
            "  timestamp: 1603034523\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00072\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=23999)\u001b[0m [50000] loss: 9.592\n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-2.7%): {PAUSED: 11, PENDING: 16, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (11 PAUSED, 16 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00084 | PENDING    |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 |          |\n",
            "| train_771eb_00085 | PENDING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |          |\n",
            "| train_771eb_00086 | PENDING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |          |\n",
            "| train_771eb_00087 | PENDING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |          |\n",
            "| train_771eb_00088 | PENDING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |          |\n",
            "| train_771eb_00073 | RUNNING    |       |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |          |\n",
            "| train_771eb_00074 | RUNNING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |          |\n",
            "| train_771eb_00075 | RUNNING    |       |           10 |   32 |  128 | 0.000563108 |   0.810928 |          |\n",
            "| train_771eb_00076 | RUNNING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |          |\n",
            "| train_771eb_00077 | RUNNING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (6 PAUSED, 11 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [45000] loss: 16.347\n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [45000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:10,339\tINFO hyperband.py:211 -- PAUSE for train_771eb_00073 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00073:\n",
            "  date: 2020-10-18_18-52-10\n",
            "  done: false\n",
            "  experiment_id: 72da1844ad704e1ebd00d30d6775403f\n",
            "  experiment_tag: 73_batch_size=100,h1=16,h2=8,lr=9.7334e-05,momentum=0.9862\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.984940979218486\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24026\n",
            "  time_since_restore: 381.8105869293213\n",
            "  time_this_iter_s: 381.8105869293213\n",
            "  time_total_s: 381.8105869293213\n",
            "  timestamp: 1603034530\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00073\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-3.0%): {PAUSED: 12, PENDING: 15, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (12 PAUSED, 15 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00085 | PENDING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |          |\n",
            "| train_771eb_00086 | PENDING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |          |\n",
            "| train_771eb_00087 | PENDING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |          |\n",
            "| train_771eb_00088 | PENDING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |          |\n",
            "| train_771eb_00089 | PENDING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |          |\n",
            "| train_771eb_00074 | RUNNING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |          |\n",
            "| train_771eb_00075 | RUNNING    |       |           10 |   32 |  128 | 0.000563108 |   0.810928 |          |\n",
            "| train_771eb_00076 | RUNNING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |          |\n",
            "| train_771eb_00077 | RUNNING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |          |\n",
            "| train_771eb_00078 | RUNNING    |       |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (7 PAUSED, 10 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24026)\u001b[0m [50000] loss: 35.985\n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [45000] loss: 11.291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [45000] loss: 22.513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:15,813\tINFO hyperband.py:211 -- PAUSE for train_771eb_00075 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00075:\n",
            "  date: 2020-10-18_18-52-15\n",
            "  done: false\n",
            "  experiment_id: e68b57a28f8b449b9c28a42483348517\n",
            "  experiment_tag: 75_batch_size=10,h1=32,h2=128,lr=0.00056311,momentum=0.81093\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.580831172350049\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24058\n",
            "  time_since_restore: 381.93481826782227\n",
            "  time_this_iter_s: 381.93481826782227\n",
            "  time_total_s: 381.93481826782227\n",
            "  timestamp: 1603034535\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00075\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24058)\u001b[0m [50000] loss: 9.581\n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-3.2%): {PAUSED: 13, PENDING: 14, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (13 PAUSED, 14 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00086 | PENDING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |          |\n",
            "| train_771eb_00087 | PENDING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |          |\n",
            "| train_771eb_00088 | PENDING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |          |\n",
            "| train_771eb_00089 | PENDING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |          |\n",
            "| train_771eb_00090 | PENDING    |       |            1 |    8 |   16 | 0.00046237  |   0.964451 |          |\n",
            "| train_771eb_00074 | RUNNING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |          |\n",
            "| train_771eb_00076 | RUNNING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |          |\n",
            "| train_771eb_00077 | RUNNING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |          |\n",
            "| train_771eb_00078 | RUNNING    |       |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |          |\n",
            "| train_771eb_00079 | RUNNING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (8 PAUSED, 9 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:52:20,091\tINFO hyperband.py:211 -- PAUSE for train_771eb_00074 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00074:\n",
            "  date: 2020-10-18_18-52-20\n",
            "  done: false\n",
            "  experiment_id: 9b2374c5c12c4a2ca5ce3070f2c2c81c\n",
            "  experiment_tag: 74_batch_size=100,h1=16,h2=128,lr=0.026067,momentum=0.73786\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24051\n",
            "  time_since_restore: 386.37821865081787\n",
            "  time_this_iter_s: 386.37821865081787\n",
            "  time_total_s: 386.37821865081787\n",
            "  timestamp: 1603034540\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00074\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24051)\u001b[0m [50000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [45000] loss: 36.330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:33,397\tINFO hyperband.py:211 -- PAUSE for train_771eb_00078 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00078:\n",
            "  date: 2020-10-18_18-52-33\n",
            "  done: false\n",
            "  experiment_id: 90ccbcc836774a16939d0a0019f0bb67\n",
            "  experiment_tag: 78_batch_size=100,h1=8,h2=16,lr=2.9735e-05,momentum=0.76234\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 15.70928892865181\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24059\n",
            "  time_since_restore: 387.55615639686584\n",
            "  time_this_iter_s: 387.55615639686584\n",
            "  time_total_s: 387.55615639686584\n",
            "  timestamp: 1603034553\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00078\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24059)\u001b[0m [50000] loss: 15.709\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-3.7%): {PAUSED: 15, PENDING: 12, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (15 PAUSED, 12 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00088 | PENDING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |          |\n",
            "| train_771eb_00089 | PENDING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |          |\n",
            "| train_771eb_00090 | PENDING    |       |            1 |    8 |   16 | 0.00046237  |   0.964451 |          |\n",
            "| train_771eb_00091 | PENDING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |          |\n",
            "| train_771eb_00092 | PENDING    |       |         1000 |   64 |   32 | 0.0827984   |   0.821088 |          |\n",
            "| train_771eb_00076 | RUNNING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |          |\n",
            "| train_771eb_00077 | RUNNING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |          |\n",
            "| train_771eb_00079 | RUNNING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |          |\n",
            "| train_771eb_00080 | RUNNING    |       |         1000 |   64 |   16 | 0.00205382  |   0.632732 |          |\n",
            "| train_771eb_00081 | RUNNING    |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (10 PAUSED, 7 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:35,105\tINFO hyperband.py:211 -- PAUSE for train_771eb_00076 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00076:\n",
            "  date: 2020-10-18_18-52-35\n",
            "  done: false\n",
            "  experiment_id: d6164920db734ec08e8ff2163cf21d65\n",
            "  experiment_tag: 76_batch_size=1000,h1=64,h2=128,lr=0.017264,momentum=0.53973\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24073\n",
            "  time_since_restore: 391.40719532966614\n",
            "  time_this_iter_s: 391.40719532966614\n",
            "  time_total_s: 391.40719532966614\n",
            "  timestamp: 1603034555\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00076\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24073)\u001b[0m [50000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:52:42,121\tINFO hyperband.py:211 -- PAUSE for train_771eb_00080 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00080:\n",
            "  date: 2020-10-18_18-52-42\n",
            "  done: false\n",
            "  experiment_id: 9c0db88e947742c0a61f1005661420c9\n",
            "  experiment_tag: 80_batch_size=1000,h1=64,h2=16,lr=0.0020538,momentum=0.63273\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24193\n",
            "  time_since_restore: 389.17931056022644\n",
            "  time_this_iter_s: 389.17931056022644\n",
            "  time_total_s: 389.17931056022644\n",
            "  timestamp: 1603034562\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00080\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-4.2%): {PAUSED: 17, PENDING: 10, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (17 PAUSED, 10 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00090 | PENDING    |       |            1 |    8 |   16 | 0.00046237  |   0.964451 |          |\n",
            "| train_771eb_00091 | PENDING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |          |\n",
            "| train_771eb_00092 | PENDING    |       |         1000 |   64 |   32 | 0.0827984   |   0.821088 |          |\n",
            "| train_771eb_00093 | PENDING    |       |            1 |    8 |   64 | 0.0407744   |   0.934975 |          |\n",
            "| train_771eb_00094 | PENDING    |       |           10 |   16 |   32 | 0.00154639  |   0.563597 |          |\n",
            "| train_771eb_00077 | RUNNING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |          |\n",
            "| train_771eb_00079 | RUNNING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |          |\n",
            "| train_771eb_00081 | RUNNING    |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |          |\n",
            "| train_771eb_00082 | RUNNING    |       |         1000 |  128 |   16 | 0.000311907 |   0.875645 |          |\n",
            "| train_771eb_00083 | RUNNING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (12 PAUSED, 5 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24193)\u001b[0m [50000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [ 5000] loss: 5891.219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:48,225\tINFO hyperband.py:211 -- PAUSE for train_771eb_00082 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00082:\n",
            "  date: 2020-10-18_18-52-48\n",
            "  done: false\n",
            "  experiment_id: 66eb99fa5fb443dda6ce9b914a8326e8\n",
            "  experiment_tag: 82_batch_size=1000,h1=128,h2=16,lr=0.00031191,momentum=0.87564\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24239\n",
            "  time_since_restore: 381.50642490386963\n",
            "  time_this_iter_s: 381.50642490386963\n",
            "  time_total_s: 381.50642490386963\n",
            "  timestamp: 1603034568\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00082\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24239)\u001b[0m [50000] loss: nan\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-4.5%): {PAUSED: 18, PENDING: 9, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (18 PAUSED, 9 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00091 | PENDING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |          |\n",
            "| train_771eb_00092 | PENDING    |       |         1000 |   64 |   32 | 0.0827984   |   0.821088 |          |\n",
            "| train_771eb_00093 | PENDING    |       |            1 |    8 |   64 | 0.0407744   |   0.934975 |          |\n",
            "| train_771eb_00094 | PENDING    |       |           10 |   16 |   32 | 0.00154639  |   0.563597 |          |\n",
            "| train_771eb_00095 | PENDING    |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |          |\n",
            "| train_771eb_00077 | RUNNING    |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |          |\n",
            "| train_771eb_00079 | RUNNING    |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |          |\n",
            "| train_771eb_00081 | RUNNING    |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |          |\n",
            "| train_771eb_00083 | RUNNING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |          |\n",
            "| train_771eb_00084 | RUNNING    |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (13 PAUSED, 4 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:50,033\tINFO hyperband.py:211 -- PAUSE for train_771eb_00077 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00077:\n",
            "  date: 2020-10-18_18-52-50\n",
            "  done: false\n",
            "  experiment_id: 44670882cc114bd78920053236ef73fd\n",
            "  experiment_tag: 77_batch_size=1,h1=8,h2=128,lr=0.0029945,momentum=0.80293\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 16.770007921123504\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24056\n",
            "  time_since_restore: 405.0367920398712\n",
            "  time_this_iter_s: 405.0367920398712\n",
            "  time_total_s: 405.0367920398712\n",
            "  timestamp: 1603034570\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00077\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24056)\u001b[0m [50000] loss: 16.770\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [ 5000] loss: 44.693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:52:52,695\tINFO hyperband.py:211 -- PAUSE for train_771eb_00079 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00079:\n",
            "  date: 2020-10-18_18-52-52\n",
            "  done: false\n",
            "  experiment_id: d37c21a80be74c2cadd92e26114822be\n",
            "  experiment_tag: 79_batch_size=1,h1=16,h2=128,lr=0.0038714,momentum=0.57077\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.230787442272902\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24170\n",
            "  time_since_restore: 402.45701456069946\n",
            "  time_this_iter_s: 402.45701456069946\n",
            "  time_total_s: 402.45701456069946\n",
            "  timestamp: 1603034572\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00079\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24170)\u001b[0m [50000] loss: 11.231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:52:53,954\tINFO hyperband.py:211 -- PAUSE for train_771eb_00081 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00081:\n",
            "  date: 2020-10-18_18-52-53\n",
            "  done: false\n",
            "  experiment_id: 63a6b3a024f94eec9499cccdca320e17\n",
            "  experiment_tag: 81_batch_size=100,h1=32,h2=64,lr=0.00014924,momentum=0.56983\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 14.586233361917735\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24217\n",
            "  time_since_restore: 391.8171031475067\n",
            "  time_this_iter_s: 391.8171031475067\n",
            "  time_total_s: 391.8171031475067\n",
            "  timestamp: 1603034573\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00081\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24217)\u001b[0m [50000] loss: 14.586\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-5.2%): {PAUSED: 21, PENDING: 6, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (21 PAUSED, 6 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00094 | PENDING    |       |           10 |   16 |   32 | 0.00154639  |   0.563597 |          |\n",
            "| train_771eb_00095 | PENDING    |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |          |\n",
            "| train_771eb_00096 | PENDING    |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |          |\n",
            "| train_771eb_00097 | PENDING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |          |\n",
            "| train_771eb_00098 | PENDING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |          |\n",
            "| train_771eb_00083 | RUNNING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |          |\n",
            "| train_771eb_00084 | RUNNING    |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 |          |\n",
            "| train_771eb_00085 | RUNNING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |          |\n",
            "| train_771eb_00086 | RUNNING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |          |\n",
            "| train_771eb_00087 | RUNNING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (16 PAUSED, 1 PENDING, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [ 5000] loss: 49.489\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [ 5000] loss: 56.639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:53:10,277\tINFO hyperband.py:211 -- PAUSE for train_771eb_00083 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00083:\n",
            "  date: 2020-10-18_18-53-10\n",
            "  done: false\n",
            "  experiment_id: 36c76a39c86c4e9f85c92bbece4166af\n",
            "  experiment_tag: 83_batch_size=10,h1=8,h2=32,lr=0.0050882,momentum=0.73076\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.60011154551506\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24265\n",
            "  time_since_restore: 382.8301782608032\n",
            "  time_this_iter_s: 382.8301782608032\n",
            "  time_total_s: 382.8301782608032\n",
            "  timestamp: 1603034590\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00083\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24265)\u001b[0m [50000] loss: 35.600\n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-5.4%): {PAUSED: 22, PENDING: 5, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (22 PAUSED, 5 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan      |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642 |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165 |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138 |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797 |\n",
            "| train_771eb_00095 | PENDING    |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |          |\n",
            "| train_771eb_00096 | PENDING    |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |          |\n",
            "| train_771eb_00097 | PENDING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |          |\n",
            "| train_771eb_00098 | PENDING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |          |\n",
            "| train_771eb_00099 | PENDING    |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |          |\n",
            "| train_771eb_00084 | RUNNING    |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 |          |\n",
            "| train_771eb_00085 | RUNNING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |          |\n",
            "| train_771eb_00086 | RUNNING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |          |\n",
            "| train_771eb_00087 | RUNNING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |          |\n",
            "| train_771eb_00088 | RUNNING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |          |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714 |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202 |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan      |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236 |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "... 80 more trials not shown (17 PAUSED, 6 RUNNING, 57 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [ 5000] loss: 40.871\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [ 5000] loss: 22.159\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [ 5000] loss: 35.798\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [10000] loss: 10342.513\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [10000] loss: 20.848\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [ 5000] loss: 55.384\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [ 5000] loss: 37.426\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [10000] loss: 21.492\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [ 5000] loss: 43.175\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [10000] loss: 23.830\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [ 5000] loss: 79.588\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [10000] loss: 41.021\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [10000] loss: 12.363\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [15000] loss: 1254727.595\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [10000] loss: 37.010\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [15000] loss: 16.422\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [10000] loss: 28.549\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [10000] loss: 35.739\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [15000] loss: 16.467\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [10000] loss: 41.824\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [15000] loss: 19.471\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [10000] loss: 52.488\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [15000] loss: 40.092\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [15000] loss: 11.144\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [20000] loss: 124249.387\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [15000] loss: 35.833\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [20000] loss: 13.804\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [15000] loss: 35.965\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [15000] loss: 21.446\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [20000] loss: 16.202\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [20000] loss: 14.353\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [15000] loss: 43.058\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [15000] loss: 40.611\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [20000] loss: 41.904\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [20000] loss: 10.574\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [25000] loss: 175916.598\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [25000] loss: 12.834\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [20000] loss: 35.672\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [20000] loss: 35.379\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [25000] loss: 15.934\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [25000] loss: 12.806\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [20000] loss: 17.979\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [20000] loss: 41.718\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [20000] loss: 32.722\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [25000] loss: 41.889\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [30000] loss: 72407.578\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [30000] loss: 12.017\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [25000] loss: 10.284\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [25000] loss: 36.411\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [25000] loss: 36.283\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [30000] loss: 12.451\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [30000] loss: 13.730\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [25000] loss: 15.629\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [25000] loss: 42.202\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [25000] loss: 28.402\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [35000] loss: 33549.762\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [30000] loss: 40.948\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [35000] loss: 11.185\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [30000] loss: 36.172\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [30000] loss: 10.152\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [30000] loss: 36.237\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [35000] loss: 11.809\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [35000] loss: 13.705\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [30000] loss: 13.814\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [30000] loss: 42.336\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [40000] loss: 44844.379\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [30000] loss: 25.629\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [40000] loss: 10.837\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [35000] loss: 40.769\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [35000] loss: 36.252\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [35000] loss: 9.984\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [35000] loss: 35.817\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [40000] loss: 11.596\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [40000] loss: 11.963\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [35000] loss: 12.438\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [35000] loss: 42.520\n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [45000] loss: 16698.220\n",
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [45000] loss: 10.670\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [35000] loss: 23.510\n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [40000] loss: 35.642\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [40000] loss: 40.327\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [40000] loss: 36.642\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [40000] loss: 9.731\n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [45000] loss: 11.099\n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [45000] loss: 12.133\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [40000] loss: 11.852\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [40000] loss: 43.144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:58:30,677\tINFO hyperband.py:211 -- PAUSE for train_771eb_00084 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00084:\n",
            "  date: 2020-10-18_18-58-30\n",
            "  done: false\n",
            "  experiment_id: b15762e06b814209936d4bb72b6b8049\n",
            "  experiment_tag: 84_batch_size=1000,h1=32,h2=32,lr=0.00024412,momentum=0.9119\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9120.687044794306\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24416\n",
            "  time_since_restore: 384.338725566864\n",
            "  time_this_iter_s: 384.338725566864\n",
            "  time_total_s: 384.338725566864\n",
            "  timestamp: 1603034910\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00084\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24416)\u001b[0m [50000] loss: 9120.687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:58:30,989\tINFO hyperband.py:211 -- PAUSE for train_771eb_00085 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24438)\u001b[0m [50000] loss: 10.410\n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-5.7%): {PAUSED: 23, PENDING: 4, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (23 PAUSED, 4 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00096 | PENDING    |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |           |\n",
            "| train_771eb_00097 | PENDING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |           |\n",
            "| train_771eb_00098 | PENDING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00099 | PENDING    |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |           |\n",
            "| train_771eb_00085 | RUNNING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |           |\n",
            "| train_771eb_00086 | RUNNING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |           |\n",
            "| train_771eb_00087 | RUNNING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |           |\n",
            "| train_771eb_00088 | RUNNING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |           |\n",
            "| train_771eb_00089 | RUNNING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |           |\n",
            "| train_771eb_00090 | RUNNING    |       |            1 |    8 |   16 | 0.00046237  |   0.964451 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (17 PAUSED, 5 RUNNING, 56 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_771eb_00085:\n",
            "  date: 2020-10-18_18-58-30\n",
            "  done: false\n",
            "  experiment_id: f9de4e6d8f2c41e5b1461d65f285277c\n",
            "  experiment_tag: 85_batch_size=10,h1=16,h2=64,lr=0.00011522,momentum=0.75249\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.409620081055165\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24438\n",
            "  time_since_restore: 378.10272884368896\n",
            "  time_this_iter_s: 378.10272884368896\n",
            "  time_total_s: 378.10272884368896\n",
            "  timestamp: 1603034910\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00085\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [45000] loss: 35.580\n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [45000] loss: 40.853\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [40000] loss: 21.684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:58:47,449\tINFO hyperband.py:211 -- PAUSE for train_771eb_00086 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00086:\n",
            "  date: 2020-10-18_18-58-47\n",
            "  done: false\n",
            "  experiment_id: c612bad30b424869bca4d1c5dc2b10c6\n",
            "  experiment_tag: 86_batch_size=10,h1=32,h2=8,lr=7.7355e-05,momentum=0.81063\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.213238483822346\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24463\n",
            "  time_since_restore: 388.71959161758423\n",
            "  time_this_iter_s: 388.71959161758423\n",
            "  time_total_s: 388.71959161758423\n",
            "  timestamp: 1603034927\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00086\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24463)\u001b[0m [50000] loss: 11.213\n",
            "== Status ==\n",
            "Memory usage on this node: 7.1/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-6.2%): {PAUSED: 25, PENDING: 2, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (25 PAUSED, 2 PENDING, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00098 | PENDING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00099 | PENDING    |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |           |\n",
            "| train_771eb_00087 | RUNNING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |           |\n",
            "| train_771eb_00088 | RUNNING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |           |\n",
            "| train_771eb_00089 | RUNNING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |           |\n",
            "| train_771eb_00090 | RUNNING    |       |            1 |    8 |   16 | 0.00046237  |   0.964451 |           |\n",
            "| train_771eb_00091 | RUNNING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |           |\n",
            "| train_771eb_00092 | RUNNING    |       |         1000 |   64 |   32 | 0.0827984   |   0.821088 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (19 PAUSED, 5 RUNNING, 56 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [45000] loss: 35.599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 18:58:51,672\tINFO hyperband.py:211 -- PAUSE for train_771eb_00087 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00087:\n",
            "  date: 2020-10-18_18-58-51\n",
            "  done: false\n",
            "  experiment_id: 456427b4eeef40d7bd5b051703a0e505\n",
            "  experiment_tag: 87_batch_size=100,h1=64,h2=32,lr=9.0561e-05,momentum=0.7764\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.702781301218272\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24493\n",
            "  time_since_restore: 389.14332485198975\n",
            "  time_this_iter_s: 389.14332485198975\n",
            "  time_total_s: 389.14332485198975\n",
            "  timestamp: 1603034931\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00087\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24493)\u001b[0m [50000] loss: 10.703\n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [45000] loss: 9.328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [45000] loss: 41.293\n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [45000] loss: 11.052\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [ 5000] loss: 48.616\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [ 5000] loss: 320.992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:16,773\tINFO hyperband.py:211 -- PAUSE for train_771eb_00090 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00090:\n",
            "  date: 2020-10-18_18-59-16\n",
            "  done: false\n",
            "  experiment_id: f0e86ea330e44d1c890e5d5f00480b53\n",
            "  experiment_tag: 90_batch_size=1,h1=8,h2=16,lr=0.00046237,momentum=0.96445\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.90537017354965\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24565\n",
            "  time_since_restore: 392.32406997680664\n",
            "  time_this_iter_s: 392.32406997680664\n",
            "  time_total_s: 392.32406997680664\n",
            "  timestamp: 1603034956\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00090\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24565)\u001b[0m [50000] loss: 35.905\n",
            "== Status ==\n",
            "Memory usage on this node: 7.0/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-6.7%): {PAUSED: 27, RUNNING: 11} \n",
            "Resources requested: 11/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (27 PAUSED, 11 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | PAUSED     |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00088 | RUNNING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |           |\n",
            "| train_771eb_00089 | RUNNING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |           |\n",
            "| train_771eb_00091 | RUNNING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |           |\n",
            "| train_771eb_00092 | RUNNING    |       |         1000 |   64 |   32 | 0.0827984   |   0.821088 |           |\n",
            "| train_771eb_00093 | RUNNING    |       |            1 |    8 |   64 | 0.0407744   |   0.934975 |           |\n",
            "| train_771eb_00094 | RUNNING    |       |           10 |   16 |   32 | 0.00154639  |   0.563597 |           |\n",
            "| train_771eb_00095 | RUNNING    |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (20 PAUSED, 4 RUNNING, 55 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:18,052\tINFO hyperband.py:211 -- PAUSE for train_771eb_00092 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00092:\n",
            "  date: 2020-10-18_18-59-18\n",
            "  done: false\n",
            "  experiment_id: a9be3fbfd03540bbb6a2264d8877c5e3\n",
            "  experiment_tag: 92_batch_size=1000,h1=64,h2=32,lr=0.082798,momentum=0.82109\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24611\n",
            "  time_since_restore: 385.5827491283417\n",
            "  time_this_iter_s: 385.5827491283417\n",
            "  time_total_s: 385.5827491283417\n",
            "  timestamp: 1603034958\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00092\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24611)\u001b[0m [50000] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:19,267\tINFO hyperband.py:211 -- PAUSE for train_771eb_00088 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00088:\n",
            "  date: 2020-10-18_18-59-19\n",
            "  done: false\n",
            "  experiment_id: b5fe300cf57246e69c760cdeab8ea3c8\n",
            "  experiment_tag: 88_batch_size=1,h1=8,h2=32,lr=0.059191,momentum=0.88212\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 40.31581004095077\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24520\n",
            "  time_since_restore: 403.03511476516724\n",
            "  time_this_iter_s: 403.03511476516724\n",
            "  time_total_s: 403.03511476516724\n",
            "  timestamp: 1603034959\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00088\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24520)\u001b[0m [50000] loss: 40.316\n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [45000] loss: 20.543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:25,391\tINFO hyperband.py:211 -- PAUSE for train_771eb_00094 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00094:\n",
            "  date: 2020-10-18_18-59-25\n",
            "  done: false\n",
            "  experiment_id: 1b4d9d2f8a254bd0898578c5fddd8228\n",
            "  experiment_tag: 94_batch_size=10,h1=16,h2=32,lr=0.0015464,momentum=0.5636\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.30232249302864\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24657\n",
            "  time_since_restore: 388.97230553627014\n",
            "  time_this_iter_s: 388.97230553627014\n",
            "  time_total_s: 388.97230553627014\n",
            "  timestamp: 1603034965\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00094\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-7.4%): {PAUSED: 30, RUNNING: 8} \n",
            "Resources requested: 8/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (30 PAUSED, 8 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | PAUSED     |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00089 | RUNNING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |           |\n",
            "| train_771eb_00091 | RUNNING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |           |\n",
            "| train_771eb_00093 | RUNNING    |       |            1 |    8 |   64 | 0.0407744   |   0.934975 |           |\n",
            "| train_771eb_00095 | RUNNING    |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |           |\n",
            "| train_771eb_00096 | RUNNING    |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |           |\n",
            "| train_771eb_00097 | RUNNING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |           |\n",
            "| train_771eb_00098 | RUNNING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (23 PAUSED, 1 RUNNING, 55 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24657)\u001b[0m [50000] loss: 36.302\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [ 5000] loss: 24.976\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [ 5000] loss: 41.779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:29,809\tINFO hyperband.py:211 -- PAUSE for train_771eb_00089 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00089:\n",
            "  date: 2020-10-18_18-59-29\n",
            "  done: false\n",
            "  experiment_id: 8df118e2a6584e48af3616fc43813584\n",
            "  experiment_tag: 89_batch_size=1,h1=64,h2=128,lr=0.00080253,momentum=0.71856\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.23932134282887\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24540\n",
            "  time_since_restore: 412.5476644039154\n",
            "  time_this_iter_s: 412.5476644039154\n",
            "  time_total_s: 412.5476644039154\n",
            "  timestamp: 1603034969\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00089\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24540)\u001b[0m [50000] loss: 9.239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:35,400\tINFO hyperband.py:211 -- PAUSE for train_771eb_00093 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00093:\n",
            "  date: 2020-10-18_18-59-35\n",
            "  done: false\n",
            "  experiment_id: 79e092570c794147b81851eda39cc79b\n",
            "  experiment_tag: 93_batch_size=1,h1=8,h2=64,lr=0.040774,momentum=0.93498\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 42.40719588000774\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24636\n",
            "  time_since_restore: 399.9582176208496\n",
            "  time_this_iter_s: 399.9582176208496\n",
            "  time_total_s: 399.9582176208496\n",
            "  timestamp: 1603034975\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00093\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-7.9%): {PAUSED: 32, RUNNING: 6} \n",
            "Resources requested: 6/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (32 PAUSED, 6 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | PAUSED     |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00091 | RUNNING    |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |           |\n",
            "| train_771eb_00095 | RUNNING    |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |           |\n",
            "| train_771eb_00096 | RUNNING    |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |           |\n",
            "| train_771eb_00097 | RUNNING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |           |\n",
            "| train_771eb_00098 | RUNNING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00099 | RUNNING    |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (25 PAUSED, 55 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24636)\u001b[0m [50000] loss: 42.407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:36,066\tINFO hyperband.py:211 -- PAUSE for train_771eb_00091 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00091:\n",
            "  date: 2020-10-18_18-59-36\n",
            "  done: false\n",
            "  experiment_id: eba302a68d3a406e83be31749b39dff7\n",
            "  experiment_tag: 91_batch_size=1,h1=32,h2=64,lr=6.7777e-05,momentum=0.68317\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.811381756108998\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24591\n",
            "  time_since_restore: 404.98742938041687\n",
            "  time_this_iter_s: 404.98742938041687\n",
            "  time_total_s: 404.98742938041687\n",
            "  timestamp: 1603034976\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00091\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24591)\u001b[0m [50000] loss: 10.811\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [10000] loss: 32.164\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [10000] loss: 547.463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 18:59:45,904\tINFO hyperband.py:211 -- PAUSE for train_771eb_00095 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00095:\n",
            "  date: 2020-10-18_18-59-45\n",
            "  done: false\n",
            "  experiment_id: ac6004bf550e4fe8a5ee7026c17aa4df\n",
            "  experiment_tag: 95_batch_size=1,h1=64,h2=64,lr=2.8635e-05,momentum=0.55605\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 19.38373364365101\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24685\n",
            "  time_since_restore: 393.3619511127472\n",
            "  time_this_iter_s: 393.3619511127472\n",
            "  time_total_s: 393.3619511127472\n",
            "  timestamp: 1603034985\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00095\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24685)\u001b[0m [50000] loss: 19.384\n",
            "== Status ==\n",
            "Memory usage on this node: 6.1/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-8.4%): {PAUSED: 34, RUNNING: 4} \n",
            "Resources requested: 4/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (34 PAUSED, 4 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | PAUSED     |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00069 | PAUSED     |       |         1000 |  128 |    8 | 0.000156659 |   0.780344 |  35.9721  |\n",
            "| train_771eb_00096 | RUNNING    |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |           |\n",
            "| train_771eb_00097 | RUNNING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |           |\n",
            "| train_771eb_00098 | RUNNING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00099 | RUNNING    |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |       |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (26 PAUSED, 54 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [10000] loss: 17.195\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [10000] loss: 40.523\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [15000] loss: 36.023\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [15000] loss: 458.932\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [15000] loss: 15.007\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [15000] loss: 42.298\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [20000] loss: 36.440\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [20000] loss: 336.818\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [20000] loss: 41.202\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [20000] loss: 14.007\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [25000] loss: 36.006\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [25000] loss: 251.668\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [25000] loss: 40.511\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [25000] loss: 13.889\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [30000] loss: 35.701\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [30000] loss: 185.855\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [30000] loss: 41.920\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [30000] loss: 14.052\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [35000] loss: 35.753\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [35000] loss: 156.757\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [35000] loss: 42.388\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [35000] loss: 13.858\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [40000] loss: 36.438\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [40000] loss: 144.765\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [40000] loss: 41.448\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [40000] loss: 13.820\n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [45000] loss: 35.847\n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [45000] loss: 128.937\n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [45000] loss: 41.600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:02:10,449\tINFO hyperband.py:211 -- PAUSE for train_771eb_00096 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00096:\n",
            "  date: 2020-10-18_19-02-10\n",
            "  done: false\n",
            "  experiment_id: 22ea35809ce3468f8403a5ff2619f8b9\n",
            "  experiment_tag: 96_batch_size=100,h1=128,h2=32,lr=0.00057708,momentum=0.67433\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.831832187128065\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24771\n",
            "  time_since_restore: 217.06533241271973\n",
            "  time_this_iter_s: 217.06533241271973\n",
            "  time_total_s: 217.06533241271973\n",
            "  timestamp: 1603035130\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00096\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24771)\u001b[0m [50000] loss: 35.832\n",
            "== Status ==\n",
            "Memory usage on this node: 6.0/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-8.7%): {PAUSED: 35, RUNNING: 3} \n",
            "Resources requested: 3/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (35 PAUSED, 3 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | PAUSED     |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00069 | PAUSED     |       |         1000 |  128 |    8 | 0.000156659 |   0.780344 |  35.9721  |\n",
            "| train_771eb_00070 | PAUSED     |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |   9.93138 |\n",
            "| train_771eb_00097 | RUNNING    |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |           |\n",
            "| train_771eb_00098 | RUNNING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00099 | RUNNING    |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |       |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |       |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (26 PAUSED, 53 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [45000] loss: 13.405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:02:11,715\tINFO hyperband.py:211 -- PAUSE for train_771eb_00097 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00097:\n",
            "  date: 2020-10-18_19-02-11\n",
            "  done: false\n",
            "  experiment_id: 77dc8978240845e09dcdcb965166d158\n",
            "  experiment_tag: 97_batch_size=1000,h1=16,h2=32,lr=0.00073615,momentum=0.95066\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 107.28057315009535\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24767\n",
            "  time_since_restore: 218.1278326511383\n",
            "  time_this_iter_s: 218.1278326511383\n",
            "  time_total_s: 218.1278326511383\n",
            "  timestamp: 1603035131\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00097\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24767)\u001b[0m [50000] loss: 107.281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:02:26,194\tINFO hyperband.py:211 -- PAUSE for train_771eb_00099 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00099:\n",
            "  date: 2020-10-18_19-02-26\n",
            "  done: false\n",
            "  experiment_id: 2b2ca74d16154866af10e9a803eefd4c\n",
            "  experiment_tag: 99_batch_size=1,h1=64,h2=32,lr=0.010643,momentum=0.97906\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 40.81035001286566\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24769\n",
            "  time_since_restore: 212.80365133285522\n",
            "  time_this_iter_s: 212.80365133285522\n",
            "  time_total_s: 212.80365133285522\n",
            "  timestamp: 1603035146\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00099\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24769)\u001b[0m [50000] loss: 40.810\n",
            "== Status ==\n",
            "Memory usage on this node: 5.7/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=81, Milestone (r)=1, completed=-9.2%): {PAUSED: 37, RUNNING: 1} \n",
            "Resources requested: 1/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (37 PAUSED, 1 RUNNING, 62 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00062 | PAUSED     |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 | nan       |\n",
            "| train_771eb_00063 | PAUSED     |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |  36.2642  |\n",
            "| train_771eb_00064 | PAUSED     |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |  35.7165  |\n",
            "| train_771eb_00065 | PAUSED     |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |  35.1138  |\n",
            "| train_771eb_00066 | PAUSED     |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |  35.7797  |\n",
            "| train_771eb_00067 | PAUSED     |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | PAUSED     |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00069 | PAUSED     |       |         1000 |  128 |    8 | 0.000156659 |   0.780344 |  35.9721  |\n",
            "| train_771eb_00070 | PAUSED     |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |   9.93138 |\n",
            "| train_771eb_00071 | PAUSED     |       |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |   8.98842 |\n",
            "| train_771eb_00098 | RUNNING    |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |           |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |       |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |       |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "| train_771eb_00009 | TERMINATED |       |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (27 PAUSED, 52 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:02:28,976\tINFO hyperband.py:211 -- CONTINUE for train_771eb_00098 on training_iteration=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00098:\n",
            "  date: 2020-10-18_19-02-28\n",
            "  done: false\n",
            "  experiment_id: 97c636cd76a847e993001de8f3bbe4f7\n",
            "  experiment_tag: 98_batch_size=1,h1=128,h2=128,lr=0.00485,momentum=0.73257\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.228290637862683\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24787\n",
            "  time_since_restore: 219.51380825042725\n",
            "  time_this_iter_s: 219.51380825042725\n",
            "  time_total_s: 219.51380825042725\n",
            "  timestamp: 1603035148\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00098\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m [50000] loss: 13.228\n",
            "\u001b[2m\u001b[36m(pid=24787)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m 2020-10-18 19:02:31,006\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00065_65_batch_size=100,h1=16,h2=32,lr=0.00017108,momentum=0.8337_2020-10-18_18-39-33/checkpoint_tmp09ef59/./\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m 2020-10-18 19:02:31,006\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 386.6401963233948, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m 2020-10-18 19:02:31,482\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00068_68_batch_size=1000,h1=32,h2=64,lr=0.064762,momentum=0.71047_2020-10-18_18-39-41/checkpoint_tmp7affa5/./\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m 2020-10-18 19:02:31,483\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 387.95159125328064, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m 2020-10-18 19:02:31,476\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00070_70_batch_size=1,h1=128,h2=64,lr=0.00014775,momentum=0.58938_2020-10-18_18-39-48/checkpoint_tmp736f51/./\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m 2020-10-18 19:02:31,477\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 414.68525648117065, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m 2020-10-18 19:02:31,678\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00067_67_batch_size=10,h1=8,h2=64,lr=0.0014643,momentum=0.76008_2020-10-18_18-39-35/checkpoint_tmp1a3691/./\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m 2020-10-18 19:02:31,679\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 389.6709129810333, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m 2020-10-18 19:02:31,641\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00075_75_batch_size=10,h1=32,h2=128,lr=0.00056311,momentum=0.81093_2020-10-18_18-45-51/checkpoint_tmp135a1f/./\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m 2020-10-18 19:02:31,641\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 381.93481826782227, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m 2020-10-18 19:02:31,651\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00079_79_batch_size=1,h1=16,h2=128,lr=0.0038714,momentum=0.57077_2020-10-18_18-46-07/checkpoint_tmp093fb1/./\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m 2020-10-18 19:02:31,651\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 402.45701456069946, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m 2020-10-18 19:02:31,785\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00072_72_batch_size=10,h1=32,h2=128,lr=6.1146e-05,momentum=0.87704_2020-10-18_18-45-34/checkpoint_tmpb7d187/./\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m 2020-10-18 19:02:31,786\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 387.5869200229645, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m 2020-10-18 19:02:31,750\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00071_71_batch_size=10,h1=16,h2=64,lr=2.6836e-05,momentum=0.98034_2020-10-18_18-39-56/checkpoint_tmp31b8f6/./\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m 2020-10-18 19:02:31,750\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 386.4121971130371, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m 2020-10-18 19:02:31,798\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00076_76_batch_size=1000,h1=64,h2=128,lr=0.017264,momentum=0.53973_2020-10-18_18-46-02/checkpoint_tmp772385/./\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m 2020-10-18 19:02:31,798\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 391.40719532966614, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m 2020-10-18 19:02:31,823\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00077_77_batch_size=1,h1=8,h2=128,lr=0.0029945,momentum=0.80293_2020-10-18_18-46-03/checkpoint_tmp03dad1/./\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m 2020-10-18 19:02:31,823\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 405.0367920398712, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m 2020-10-18 19:02:31,872\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00078_78_batch_size=100,h1=8,h2=16,lr=2.9735e-05,momentum=0.76234_2020-10-18_18-46-04/checkpoint_tmp9e6dd1/./\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m 2020-10-18 19:02:31,873\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 387.55615639686584, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m 2020-10-18 19:02:31,969\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00074_74_batch_size=100,h1=16,h2=128,lr=0.026067,momentum=0.73786_2020-10-18_18-45-51/checkpoint_tmp434c6a/./\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m 2020-10-18 19:02:31,970\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 386.37821865081787, '_episodes_total': 0}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [ 5000] loss: 48.851\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [ 5000] loss: 28.489\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [ 5000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [ 5000] loss: 81.203\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [ 5000] loss: 492155185904941212368896.000\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [ 5000] loss: 43.866\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [ 5000] loss: 22.635\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [ 5000] loss: 25.147\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [ 5000] loss: 45.777\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [ 5000] loss: 24.727\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [ 5000] loss: 45.010\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [10000] loss: 19.199\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [10000] loss: 21.707\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [10000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [10000] loss: 358100264768675136.000\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [10000] loss: 19.923\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [10000] loss: 44.409\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [10000] loss: 13.558\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [10000] loss: 14.350\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [10000] loss: 17.925\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [10000] loss: 16.695\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [10000] loss: 21.269\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [15000] loss: 16.543\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [15000] loss: 26.862\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [15000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [15000] loss: 33.115\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [15000] loss: 89686955054.260\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [15000] loss: 11.905\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [15000] loss: 13.779\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [15000] loss: 15.265\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [15000] loss: 13.496\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [15000] loss: 16.624\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [15000] loss: 15.493\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [20000] loss: 40.677\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [20000] loss: 16.367\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [20000] loss: 24.768\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [20000] loss: 11.989\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [20000] loss: 11.187\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [20000] loss: 22516.624\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [20000] loss: 12.716\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [20000] loss: 12.555\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [20000] loss: 14.835\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [20000] loss: 13.378\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [25000] loss: 34.688\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [25000] loss: 14.649\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [25000] loss: 21.668\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [25000] loss: 11.004\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [25000] loss: 11.899\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [25000] loss: 11.393\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [25000] loss: 12.289\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [25000] loss: 36.722\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [25000] loss: 11.731\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [25000] loss: 14.010\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [30000] loss: 33.954\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [30000] loss: 15.565\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [30000] loss: 10.192\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [30000] loss: 19.081\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [30000] loss: 9.993\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [30000] loss: 10.638\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [30000] loss: 37.329\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [30000] loss: 12.039\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [30000] loss: 10.986\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [30000] loss: 13.569\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [35000] loss: 33.533\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [35000] loss: 14.986\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [35000] loss: 18.096\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [35000] loss: 10.165\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [35000] loss: 9.808\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [35000] loss: 10.202\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [35000] loss: 39.076\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [35000] loss: 11.840\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [35000] loss: 10.459\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [35000] loss: 13.424\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [40000] loss: 31.290\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [40000] loss: 13.173\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [40000] loss: 17.021\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [40000] loss: 10.066\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [40000] loss: 9.827\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [40000] loss: 9.914\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [40000] loss: 37.843\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [40000] loss: 11.281\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [40000] loss: 10.207\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [40000] loss: 13.158\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [45000] loss: 12.423\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [45000] loss: 31.145\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [45000] loss: 9.464\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [45000] loss: 10.386\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [45000] loss: 15.677\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [45000] loss: 9.692\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [45000] loss: 38.632\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [45000] loss: 11.004\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [45000] loss: 12.865\n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [45000] loss: 10.041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:09:02,549\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00065:\n",
            "  date: 2020-10-18_19-09-02\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 3fb9368ec4284a5e825f04fdeba52058\n",
            "  experiment_tag: 65_batch_size=100,h1=16,h2=32,lr=0.00017108,momentum=0.8337\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 31.622673449897768\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24772\n",
            "  time_since_restore: 391.541508436203\n",
            "  time_this_iter_s: 391.541508436203\n",
            "  time_total_s: 778.1817047595978\n",
            "  timestamp: 1603035542\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00065\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m [50000] loss: 31.623\n",
            "\u001b[2m\u001b[36m(pid=24772)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m [50000] loss: 13.012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:09:02,803\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 7.3/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {PENDING: 14, RUNNING: 12, TERMINATED: 12} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (14 PENDING, 12 RUNNING, 74 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00080 | PENDING    |                   |         1000 |   64 |   16 | 0.00205382  |   0.632732 | nan       |\n",
            "| train_771eb_00081 | PENDING    |                   |          100 |   32 |   64 | 0.000149239 |   0.569827 |  14.5862  |\n",
            "| train_771eb_00082 | PENDING    |                   |         1000 |  128 |   16 | 0.000311907 |   0.875645 | nan       |\n",
            "| train_771eb_00083 | PENDING    |                   |           10 |    8 |   32 | 0.00508818  |   0.730759 |  35.6001  |\n",
            "| train_771eb_00085 | PENDING    |                   |           10 |   16 |   64 | 0.000115223 |   0.752489 |  10.4096  |\n",
            "| train_771eb_00086 | PENDING    |                   |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |  11.2132  |\n",
            "| train_771eb_00087 | PENDING    |                   |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  10.7028  |\n",
            "| train_771eb_00065 | RUNNING    | 192.168.1.4:24772 |          100 |   16 |   32 | 0.000171083 |   0.833695 |  31.6227  |\n",
            "| train_771eb_00067 | RUNNING    |                   |           10 |    8 |   64 | 0.00146429  |   0.760084 |  13.1877  |\n",
            "| train_771eb_00068 | RUNNING    |                   |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00070 | RUNNING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |   9.93138 |\n",
            "| train_771eb_00071 | RUNNING    |                   |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |   8.98842 |\n",
            "| train_771eb_00072 | RUNNING    |                   |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |   9.59228 |\n",
            "| train_771eb_00074 | RUNNING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 | nan       |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (7 PENDING, 5 RUNNING, 67 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_771eb_00067:\n",
            "  date: 2020-10-18_19-09-02\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 8aca43a434da49078e51071cc7e3cef9\n",
            "  experiment_tag: 67_batch_size=10,h1=8,h2=64,lr=0.0014643,momentum=0.76008\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 13.012050639575719\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24941\n",
            "  time_since_restore: 390.9738292694092\n",
            "  time_this_iter_s: 390.9738292694092\n",
            "  time_total_s: 780.6447422504425\n",
            "  timestamp: 1603035542\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00067\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24941)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m 2020-10-18 19:09:04,214\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00081_81_batch_size=100,h1=32,h2=64,lr=0.00014924,momentum=0.56983_2020-10-18_18-46-19/checkpoint_tmpdbec79/./\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m 2020-10-18 19:09:04,214\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 391.8171031475067, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m 2020-10-18 19:09:04,357\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00080_80_batch_size=1000,h1=64,h2=16,lr=0.0020538,momentum=0.63273_2020-10-18_18-46-10/checkpoint_tmp272aa6/./\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m 2020-10-18 19:09:04,357\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 389.17931056022644, '_episodes_total': 0}\n",
            "2020-10-18 19:09:08,103\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n",
            "2020-10-18 19:09:08,161\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00078:\n",
            "  date: 2020-10-18_19-09-08\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 90ccbcc836774a16939d0a0019f0bb67\n",
            "  experiment_tag: 78_batch_size=100,h1=8,h2=16,lr=2.9735e-05,momentum=0.76234\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 15.0334247736454\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24954\n",
            "  time_since_restore: 396.2289755344391\n",
            "  time_this_iter_s: 396.2289755344391\n",
            "  time_total_s: 783.7851319313049\n",
            "  timestamp: 1603035548\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00078\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 7.2/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {PENDING: 12, RUNNING: 12, TERMINATED: 14} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (12 PENDING, 12 RUNNING, 76 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00082 | PENDING    |       |         1000 |  128 |   16 | 0.000311907 |   0.875645 | nan       |\n",
            "| train_771eb_00083 | PENDING    |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |  35.6001  |\n",
            "| train_771eb_00085 | PENDING    |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |  10.4096  |\n",
            "| train_771eb_00086 | PENDING    |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |  11.2132  |\n",
            "| train_771eb_00087 | PENDING    |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  10.7028  |\n",
            "| train_771eb_00088 | PENDING    |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |  40.3158  |\n",
            "| train_771eb_00089 | PENDING    |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932 |\n",
            "| train_771eb_00068 | RUNNING    |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 | nan       |\n",
            "| train_771eb_00070 | RUNNING    |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |   9.93138 |\n",
            "| train_771eb_00071 | RUNNING    |       |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |   8.98842 |\n",
            "| train_771eb_00072 | RUNNING    |       |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |   9.59228 |\n",
            "| train_771eb_00074 | RUNNING    |       |          100 |   16 |  128 | 0.0260674   |   0.737861 | nan       |\n",
            "| train_771eb_00075 | RUNNING    |       |           10 |   32 |  128 | 0.000563108 |   0.810928 |   9.58083 |\n",
            "| train_771eb_00076 | RUNNING    |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 | nan       |\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (5 PENDING, 5 RUNNING, 69 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m [50000] loss: 15.033\n",
            "\u001b[2m\u001b[36m(pid=24954)\u001b[0m Finished Training\n",
            "Result for train_771eb_00075:\n",
            "  date: 2020-10-18_19-09-08\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: e68b57a28f8b449b9c28a42483348517\n",
            "  experiment_tag: 75_batch_size=10,h1=32,h2=128,lr=0.00056311,momentum=0.81093\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.598040112021565\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24947\n",
            "  time_since_restore: 396.5182731151581\n",
            "  time_this_iter_s: 396.5182731151581\n",
            "  time_total_s: 778.4530913829803\n",
            "  timestamp: 1603035548\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00075\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m [50000] loss: 9.598\n",
            "\u001b[2m\u001b[36m(pid=24947)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:09:08,971\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00068:\n",
            "  date: 2020-10-18_19-09-08\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 659b59e8d5eb4fbfbedd797c7dce58ac\n",
            "  experiment_tag: 68_batch_size=1000,h1=32,h2=64,lr=0.064762,momentum=0.71047\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24939\n",
            "  time_since_restore: 397.4870626926422\n",
            "  time_this_iter_s: 397.4870626926422\n",
            "  time_total_s: 785.4386539459229\n",
            "  timestamp: 1603035548\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00068\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24939)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:09:09,199\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00071:\n",
            "  date: 2020-10-18_19-09-09\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 4e00af705af542e2bee3eb5cc82b2676\n",
            "  experiment_tag: 71_batch_size=10,h1=16,h2=64,lr=2.6836e-05,momentum=0.98034\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.365231740731002\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24942\n",
            "  time_since_restore: 397.44797229766846\n",
            "  time_this_iter_s: 397.44797229766846\n",
            "  time_total_s: 783.8601694107056\n",
            "  timestamp: 1603035549\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00071\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m [50000] loss: 9.365\n",
            "\u001b[2m\u001b[36m(pid=24942)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m 2020-10-18 19:09:09,942\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00082_82_batch_size=1000,h1=128,h2=16,lr=0.00031191,momentum=0.87564_2020-10-18_18-46-24/checkpoint_tmpf8950b/./\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m 2020-10-18 19:09:09,942\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 381.50642490386963, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m 2020-10-18 19:09:09,953\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00083_83_batch_size=10,h1=8,h2=32,lr=0.0050882,momentum=0.73076_2020-10-18_18-46-45/checkpoint_tmpd6d46a/./\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m 2020-10-18 19:09:09,953\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 382.8301782608032, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m 2020-10-18 19:09:10,600\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00085_85_batch_size=10,h1=16,h2=64,lr=0.00011522,momentum=0.75249_2020-10-18_18-52-10/checkpoint_tmpa0f7ba/./\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m 2020-10-18 19:09:10,600\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 378.10272884368896, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m 2020-10-18 19:09:10,818\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00086_86_batch_size=10,h1=32,h2=8,lr=7.7355e-05,momentum=0.81063_2020-10-18_18-52-16/checkpoint_tmp1fd796/./\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m 2020-10-18 19:09:10,818\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 388.71959161758423, '_episodes_total': 0}\n",
            "2020-10-18 19:09:16,017\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00072:\n",
            "  date: 2020-10-18_19-09-16\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: fb4a658c3b8c46a78d9f0a0996e83097\n",
            "  experiment_tag: 72_batch_size=10,h1=32,h2=128,lr=6.1146e-05,momentum=0.87704\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.711487126326562\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24943\n",
            "  time_since_restore: 404.2298390865326\n",
            "  time_this_iter_s: 404.2298390865326\n",
            "  time_total_s: 791.8167591094971\n",
            "  timestamp: 1603035556\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00072\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m [50000] loss: 9.711\n",
            "\u001b[2m\u001b[36m(pid=24943)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 7.1/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {PENDING: 8, RUNNING: 12, TERMINATED: 18} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (8 PENDING, 12 RUNNING, 80 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00087 | PENDING    |                   |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  10.7028  |\n",
            "| train_771eb_00088 | PENDING    |                   |            1 |    8 |   32 | 0.0591907   |   0.882117 |  40.3158  |\n",
            "| train_771eb_00089 | PENDING    |                   |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932 |\n",
            "| train_771eb_00090 | PENDING    |                   |            1 |    8 |   16 | 0.00046237  |   0.964451 |  35.9054  |\n",
            "| train_771eb_00091 | PENDING    |                   |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.8114  |\n",
            "| train_771eb_00092 | PENDING    |                   |         1000 |   64 |   32 | 0.0827984   |   0.821088 | nan       |\n",
            "| train_771eb_00095 | PENDING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00070 | RUNNING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |   9.93138 |\n",
            "| train_771eb_00072 | RUNNING    | 192.168.1.4:24943 |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |   9.71149 |\n",
            "| train_771eb_00074 | RUNNING    |                   |          100 |   16 |  128 | 0.0260674   |   0.737861 | nan       |\n",
            "| train_771eb_00076 | RUNNING    |                   |         1000 |   64 |  128 | 0.0172635   |   0.539725 | nan       |\n",
            "| train_771eb_00077 | RUNNING    |                   |            1 |    8 |  128 | 0.00299448  |   0.802929 |  16.77    |\n",
            "| train_771eb_00079 | RUNNING    |                   |            1 |   16 |  128 | 0.00387142  |   0.570771 |  11.2308  |\n",
            "| train_771eb_00080 | RUNNING    |                   |         1000 |   64 |   16 | 0.00205382  |   0.632732 | nan       |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (1 PENDING, 5 RUNNING, 73 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:09:17,079\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n",
            "2020-10-18 19:09:17,131\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00076:\n",
            "  date: 2020-10-18_19-09-17\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: d6164920db734ec08e8ff2163cf21d65\n",
            "  experiment_tag: 76_batch_size=1000,h1=64,h2=128,lr=0.017264,momentum=0.53973\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24944\n",
            "  time_since_restore: 405.27994537353516\n",
            "  time_this_iter_s: 405.27994537353516\n",
            "  time_total_s: 796.6871407032013\n",
            "  timestamp: 1603035557\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00076\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24944)\u001b[0m Finished Training\n",
            "Result for train_771eb_00074:\n",
            "  date: 2020-10-18_19-09-17\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 9b2374c5c12c4a2ca5ce3070f2c2c81c\n",
            "  experiment_tag: 74_batch_size=100,h1=16,h2=128,lr=0.026067,momentum=0.73786\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 37.795279202485084\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24945\n",
            "  time_since_restore: 405.1600661277771\n",
            "  time_this_iter_s: 405.1600661277771\n",
            "  time_total_s: 791.538284778595\n",
            "  timestamp: 1603035557\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00074\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m [50000] loss: 37.795\n",
            "\u001b[2m\u001b[36m(pid=24945)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m 2020-10-18 19:09:18,020\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00087_87_batch_size=100,h1=64,h2=32,lr=9.0561e-05,momentum=0.7764_2020-10-18_18-52-20/checkpoint_tmp4ab450/./\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m 2020-10-18 19:09:18,020\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 389.14332485198975, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m 2020-10-18 19:09:18,757\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00088_88_batch_size=1,h1=8,h2=32,lr=0.059191,momentum=0.88212_2020-10-18_18-52-33/checkpoint_tmp85084a/./\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m 2020-10-18 19:09:18,757\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 403.03511476516724, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m 2020-10-18 19:09:18,824\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00089_89_batch_size=1,h1=64,h2=128,lr=0.00080253,momentum=0.71856_2020-10-18_18-52-35/checkpoint_tmpf3b608/./\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m 2020-10-18 19:09:18,824\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 412.5476644039154, '_episodes_total': 0}\n",
            "2020-10-18 19:09:22,251\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00079:\n",
            "  date: 2020-10-18_19-09-22\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: d37c21a80be74c2cadd92e26114822be\n",
            "  experiment_tag: 79_batch_size=1,h1=16,h2=128,lr=0.0038714,momentum=0.57077\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.11228988341689\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24961\n",
            "  time_since_restore: 410.5985059738159\n",
            "  time_this_iter_s: 410.5985059738159\n",
            "  time_total_s: 813.0555205345154\n",
            "  timestamp: 1603035562\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00079\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 7.0/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {PENDING: 5, RUNNING: 12, TERMINATED: 21} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (5 PENDING, 12 RUNNING, 83 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00090 | PENDING    |                   |            1 |    8 |   16 | 0.00046237  |   0.964451 |  35.9054  |\n",
            "| train_771eb_00091 | PENDING    |                   |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.8114  |\n",
            "| train_771eb_00092 | PENDING    |                   |         1000 |   64 |   32 | 0.0827984   |   0.821088 | nan       |\n",
            "| train_771eb_00095 | PENDING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00096 | PENDING    |                   |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.8318  |\n",
            "| train_771eb_00070 | RUNNING    |                   |            1 |  128 |   64 | 0.000147746 |   0.58938  |   9.93138 |\n",
            "| train_771eb_00077 | RUNNING    |                   |            1 |    8 |  128 | 0.00299448  |   0.802929 |  16.77    |\n",
            "| train_771eb_00079 | RUNNING    | 192.168.1.4:24961 |            1 |   16 |  128 | 0.00387142  |   0.570771 |  11.1123  |\n",
            "| train_771eb_00080 | RUNNING    |                   |         1000 |   64 |   16 | 0.00205382  |   0.632732 | nan       |\n",
            "| train_771eb_00081 | RUNNING    |                   |          100 |   32 |   64 | 0.000149239 |   0.569827 |  14.5862  |\n",
            "| train_771eb_00082 | RUNNING    |                   |         1000 |  128 |   16 | 0.000311907 |   0.875645 | nan       |\n",
            "| train_771eb_00083 | RUNNING    |                   |           10 |    8 |   32 | 0.00508818  |   0.730759 |  35.6001  |\n",
            "| train_771eb_00085 | RUNNING    |                   |           10 |   16 |   64 | 0.000115223 |   0.752489 |  10.4096  |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (4 RUNNING, 75 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m [50000] loss: 11.112\n",
            "\u001b[2m\u001b[36m(pid=24961)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m 2020-10-18 19:09:23,845\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00090_90_batch_size=1,h1=8,h2=16,lr=0.00046237,momentum=0.96445_2020-10-18_18-52-42/checkpoint_tmp30d89e/./\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m 2020-10-18 19:09:23,845\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 392.32406997680664, '_episodes_total': 0}\n",
            "2020-10-18 19:09:26,816\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00077:\n",
            "  date: 2020-10-18_19-09-26\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 44670882cc114bd78920053236ef73fd\n",
            "  experiment_tag: 77_batch_size=1,h1=8,h2=128,lr=0.0029945,momentum=0.80293\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 12.79760287887454\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24946\n",
            "  time_since_restore: 414.9913709163666\n",
            "  time_this_iter_s: 414.9913709163666\n",
            "  time_total_s: 820.0281629562378\n",
            "  timestamp: 1603035566\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00077\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m [50000] loss: 12.798\n",
            "\u001b[2m\u001b[36m(pid=24946)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:09:27,069\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m [50000] loss: 9.898\n",
            "Result for train_771eb_00070:\n",
            "  date: 2020-10-18_19-09-27\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 54f0cfb2b7ef44759afc3455f9f36f24\n",
            "  experiment_tag: 70_batch_size=1,h1=128,h2=64,lr=0.00014775,momentum=0.58938\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.898391321349145\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24940\n",
            "  time_since_restore: 415.5658190250397\n",
            "  time_this_iter_s: 415.5658190250397\n",
            "  time_total_s: 830.2510755062103\n",
            "  timestamp: 1603035567\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00070\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=24940)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m 2020-10-18 19:09:28,770\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00091_91_batch_size=1,h1=32,h2=64,lr=6.7777e-05,momentum=0.68317_2020-10-18_18-52-48/checkpoint_tmp6d3840/./\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m 2020-10-18 19:09:28,770\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 404.98742938041687, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m 2020-10-18 19:09:29,137\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00092_92_batch_size=1000,h1=64,h2=32,lr=0.082798,momentum=0.82109_2020-10-18_18-52-50/checkpoint_tmp595109/./\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m 2020-10-18 19:09:29,137\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 385.5827491283417, '_episodes_total': 0}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [ 5000] loss: 1521186778675632416090997013872640.000\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [ 5000] loss: 54.960\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [ 5000] loss: 12288013.483\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [ 5000] loss: 37.690\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [ 5000] loss: 44.098\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [ 5000] loss: 43.401\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [ 5000] loss: 57.261\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [ 5000] loss: 41.751\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [ 5000] loss: 21.395\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [ 5000] loss: 28.227\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [ 5000] loss: 1373356082569163181129728.000\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [ 5000] loss: 57.350\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [10000] loss: 23.630\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [10000] loss: 6649404576739155239252799782912.000\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [10000] loss: 36.799\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [10000] loss: 20.300\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [10000] loss: 20.874\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [10000] loss: 24.399\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [10000] loss: 42.312\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [10000] loss: 12.220\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [10000] loss: 22.028\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [10000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [10000] loss: 29.227\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [15000] loss: 20.895\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [15000] loss: 35.914\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [15000] loss: 955678116918598127243124277248.000\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [15000] loss: 15.204\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [15000] loss: 16.364\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [15000] loss: 17.768\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [15000] loss: 41.609\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [15000] loss: 11.278\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [15000] loss: 21.771\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [15000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [15000] loss: 22.313\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [20000] loss: 22.544\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [20000] loss: 12.712\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [20000] loss: 36.111\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [20000] loss: 759879595813127662170477166592.000\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [20000] loss: 12.986\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [20000] loss: 15.002\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [20000] loss: 40.267\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [20000] loss: 10.637\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [20000] loss: 20.807\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [20000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [20000] loss: 18.519\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [25000] loss: 17.137\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [25000] loss: 11.386\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [25000] loss: 35.650\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [25000] loss: 350462971909494268364656214016.000\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [25000] loss: 11.443\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [25000] loss: 14.652\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [25000] loss: 40.218\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [25000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [25000] loss: 19.716\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [25000] loss: 10.540\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [25000] loss: 15.996\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [30000] loss: 21.475\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [30000] loss: 10.999\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [30000] loss: 36.125\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [30000] loss: 109507890428030281853911957504.000\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [30000] loss: 10.916\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [30000] loss: 14.621\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [30000] loss: 41.037\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [30000] loss: 19.984\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [30000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [30000] loss: 10.055\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [30000] loss: 14.219\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [35000] loss: 17.533\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [35000] loss: 10.352\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [35000] loss: 35.093\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [35000] loss: 67313725439870164574234738688.000\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [35000] loss: 10.479\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [35000] loss: 12.156\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [35000] loss: 40.804\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [35000] loss: 19.532\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [35000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [35000] loss: 9.808\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [35000] loss: 13.021\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [40000] loss: 18.598\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [40000] loss: 10.085\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [40000] loss: 36.055\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [40000] loss: 10.275\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [40000] loss: 53423153192191557737612574720.000\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [40000] loss: 13.818\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [40000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [40000] loss: 40.527\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [40000] loss: 19.095\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [40000] loss: 9.526\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [40000] loss: 12.121\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [45000] loss: 17.376\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [45000] loss: 10.294\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [45000] loss: 35.745\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [45000] loss: 24564032801138914399159844864.000\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [45000] loss: 9.943\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [45000] loss: 12.473\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [45000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [45000] loss: 42.304\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [45000] loss: 19.977\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [45000] loss: 9.629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:28,360\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00080:\n",
            "  date: 2020-10-18_19-15-28\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 9c0db88e947742c0a61f1005661420c9\n",
            "  experiment_tag: 80_batch_size=1000,h1=64,h2=16,lr=0.0020538,momentum=0.63273\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25113\n",
            "  time_since_restore: 383.9997889995575\n",
            "  time_this_iter_s: 383.9997889995575\n",
            "  time_total_s: 773.1790995597839\n",
            "  timestamp: 1603035928\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00080\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25113)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 7.1/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {PENDING: 2, RUNNING: 12, TERMINATED: 24} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (2 PENDING, 12 RUNNING, 86 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00095 | PENDING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00096 | PENDING    |                   |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.8318  |\n",
            "| train_771eb_00080 | RUNNING    | 192.168.1.4:25113 |         1000 |   64 |   16 | 0.00205382  |   0.632732 | nan       |\n",
            "| train_771eb_00081 | RUNNING    |                   |          100 |   32 |   64 | 0.000149239 |   0.569827 |  14.5862  |\n",
            "| train_771eb_00082 | RUNNING    |                   |         1000 |  128 |   16 | 0.000311907 |   0.875645 | nan       |\n",
            "| train_771eb_00083 | RUNNING    |                   |           10 |    8 |   32 | 0.00508818  |   0.730759 |  35.6001  |\n",
            "| train_771eb_00085 | RUNNING    |                   |           10 |   16 |   64 | 0.000115223 |   0.752489 |  10.4096  |\n",
            "| train_771eb_00086 | RUNNING    |                   |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |  11.2132  |\n",
            "| train_771eb_00087 | RUNNING    |                   |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  10.7028  |\n",
            "| train_771eb_00088 | RUNNING    |                   |            1 |    8 |   32 | 0.0591907   |   0.882117 |  40.3158  |\n",
            "| train_771eb_00089 | RUNNING    |                   |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932 |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (3 RUNNING, 77 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m 2020-10-18 19:15:30,851\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00095_95_batch_size=1,h1=64,h2=64,lr=2.8635e-05,momentum=0.55605_2020-10-18_18-53-10/checkpoint_tmp355609/./\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m 2020-10-18 19:15:30,851\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 393.3619511127472, '_episodes_total': 0}\n",
            "2020-10-18 19:15:32,894\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00081:\n",
            "  date: 2020-10-18_19-15-32\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 63a6b3a024f94eec9499cccdca320e17\n",
            "  experiment_tag: 81_batch_size=100,h1=32,h2=64,lr=0.00014924,momentum=0.56983\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 14.934414706027507\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25097\n",
            "  time_since_restore: 388.67213702201843\n",
            "  time_this_iter_s: 388.67213702201843\n",
            "  time_total_s: 780.4892401695251\n",
            "  timestamp: 1603035932\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00081\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m [50000] loss: 14.934\n",
            "\u001b[2m\u001b[36m(pid=25097)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:34,036\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00086:\n",
            "  date: 2020-10-18_19-15-34\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: c612bad30b424869bca4d1c5dc2b10c6\n",
            "  experiment_tag: 86_batch_size=10,h1=32,h2=8,lr=7.7355e-05,momentum=0.81063\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.834419462442398\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25041\n",
            "  time_since_restore: 383.21637511253357\n",
            "  time_this_iter_s: 383.21637511253357\n",
            "  time_total_s: 771.9359667301178\n",
            "  timestamp: 1603035934\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00086\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {RUNNING: 12, TERMINATED: 26} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (12 RUNNING, 88 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00082 | RUNNING    |                   |         1000 |  128 |   16 | 0.000311907 |   0.875645 | nan       |\n",
            "| train_771eb_00083 | RUNNING    |                   |           10 |    8 |   32 | 0.00508818  |   0.730759 |  35.6001  |\n",
            "| train_771eb_00085 | RUNNING    |                   |           10 |   16 |   64 | 0.000115223 |   0.752489 |  10.4096  |\n",
            "| train_771eb_00086 | RUNNING    | 192.168.1.4:25041 |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |   9.83442 |\n",
            "| train_771eb_00087 | RUNNING    |                   |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  10.7028  |\n",
            "| train_771eb_00088 | RUNNING    |                   |            1 |    8 |   32 | 0.0591907   |   0.882117 |  40.3158  |\n",
            "| train_771eb_00089 | RUNNING    |                   |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932 |\n",
            "| train_771eb_00090 | RUNNING    |                   |            1 |    8 |   16 | 0.00046237  |   0.964451 |  35.9054  |\n",
            "| train_771eb_00091 | RUNNING    |                   |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.8114  |\n",
            "| train_771eb_00092 | RUNNING    |                   |         1000 |   64 |   32 | 0.0827984   |   0.821088 | nan       |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (2 RUNNING, 78 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m [50000] loss: 9.834\n",
            "\u001b[2m\u001b[36m(pid=25041)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [45000] loss: 11.439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m Using backend: pytorch\n",
            "2020-10-18 19:15:35,123\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m 2020-10-18 19:15:35,190\tINFO trainable.py:482 -- Restored on 192.168.1.4 from checkpoint: /home/mahi/ray_results/train/train_771eb_00096_96_batch_size=100,h1=128,h2=32,lr=0.00057708,momentum=0.67433_2020-10-18_18-58-30/checkpoint_tmpe70c86/./\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m 2020-10-18 19:15:35,191\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 217.06533241271973, '_episodes_total': 0}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00083:\n",
            "  date: 2020-10-18_19-15-35\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 36c76a39c86c4e9f85c92bbece4166af\n",
            "  experiment_tag: 83_batch_size=10,h1=8,h2=32,lr=0.0050882,momentum=0.73076\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.500009551286695\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25135\n",
            "  time_since_restore: 385.1680791378021\n",
            "  time_this_iter_s: 385.1680791378021\n",
            "  time_total_s: 767.9982573986053\n",
            "  timestamp: 1603035935\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00083\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m [50000] loss: 35.500\n",
            "\u001b[2m\u001b[36m(pid=25135)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:37,874\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00085:\n",
            "  date: 2020-10-18_19-15-37\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: f9de4e6d8f2c41e5b1461d65f285277c\n",
            "  experiment_tag: 85_batch_size=10,h1=16,h2=64,lr=0.00011522,momentum=0.75249\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.031535715425015\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25064\n",
            "  time_since_restore: 387.2719359397888\n",
            "  time_this_iter_s: 387.2719359397888\n",
            "  time_total_s: 765.3746647834778\n",
            "  timestamp: 1603035937\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00085\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m [50000] loss: 10.032\n",
            "\u001b[2m\u001b[36m(pid=25064)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:38,963\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00082:\n",
            "  date: 2020-10-18_19-15-38\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 66eb99fa5fb443dda6ce9b914a8326e8\n",
            "  experiment_tag: 82_batch_size=1000,h1=128,h2=16,lr=0.00031191,momentum=0.87564\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 7.677299909601303e+27\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25079\n",
            "  time_since_restore: 389.0192677974701\n",
            "  time_this_iter_s: 389.0192677974701\n",
            "  time_total_s: 770.5256927013397\n",
            "  timestamp: 1603035938\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00082\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m [50000] loss: 7677299909601303008500514816.000\n",
            "\u001b[2m\u001b[36m(pid=25079)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {RUNNING: 9, TERMINATED: 29} \n",
            "Resources requested: 9/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (9 RUNNING, 91 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+--------------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |         loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+--------------|\n",
            "| train_771eb_00082 | RUNNING    | 192.168.1.4:25079 |         1000 |  128 |   16 | 0.000311907 |   0.875645 |   7.6773e+27 |\n",
            "| train_771eb_00087 | RUNNING    |                   |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  10.7028     |\n",
            "| train_771eb_00088 | RUNNING    |                   |            1 |    8 |   32 | 0.0591907   |   0.882117 |  40.3158     |\n",
            "| train_771eb_00089 | RUNNING    |                   |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932    |\n",
            "| train_771eb_00090 | RUNNING    |                   |            1 |    8 |   16 | 0.00046237  |   0.964451 |  35.9054     |\n",
            "| train_771eb_00091 | RUNNING    |                   |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.8114     |\n",
            "| train_771eb_00092 | RUNNING    |                   |         1000 |   64 |   32 | 0.0827984   |   0.821088 | nan          |\n",
            "| train_771eb_00095 | RUNNING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837     |\n",
            "| train_771eb_00096 | RUNNING    |                   |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.8318     |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714     |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202     |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan          |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236     |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043     |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738    |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433     |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245     |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan          |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404     |\n",
            "| train_771eb_00010 | TERMINATED |                   |          100 |  128 |   64 | 0.0728514   |   0.720064 | nan          |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+--------------+\n",
            "... 80 more trials not shown (80 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:46,144\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00087:\n",
            "  date: 2020-10-18_19-15-46\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 456427b4eeef40d7bd5b051703a0e505\n",
            "  experiment_tag: 87_batch_size=100,h1=64,h2=32,lr=9.0561e-05,momentum=0.7764\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.079637528401614\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24993\n",
            "  time_since_restore: 388.12284445762634\n",
            "  time_this_iter_s: 388.12284445762634\n",
            "  time_total_s: 777.2661693096161\n",
            "  timestamp: 1603035946\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00087\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {RUNNING: 8, TERMINATED: 30} \n",
            "Resources requested: 8/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (8 RUNNING, 92 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00087 | RUNNING    | 192.168.1.4:24993 |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |  11.0796  |\n",
            "| train_771eb_00088 | RUNNING    |                   |            1 |    8 |   32 | 0.0591907   |   0.882117 |  40.3158  |\n",
            "| train_771eb_00089 | RUNNING    |                   |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932 |\n",
            "| train_771eb_00090 | RUNNING    |                   |            1 |    8 |   16 | 0.00046237  |   0.964451 |  35.9054  |\n",
            "| train_771eb_00091 | RUNNING    |                   |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.8114  |\n",
            "| train_771eb_00092 | RUNNING    |                   |         1000 |   64 |   32 | 0.0827984   |   0.821088 | nan       |\n",
            "| train_771eb_00095 | RUNNING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00096 | RUNNING    |                   |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.8318  |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404  |\n",
            "| train_771eb_00010 | TERMINATED |                   |          100 |  128 |   64 | 0.0728514   |   0.720064 | nan       |\n",
            "| train_771eb_00011 | TERMINATED |                   |            1 |   64 |   32 | 0.0333067   |   0.924837 |  40.0098  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (80 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m [50000] loss: 11.080\n",
            "\u001b[2m\u001b[36m(pid=24993)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:49,624\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00092:\n",
            "  date: 2020-10-18_19-15-49\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: a9be3fbfd03540bbb6a2264d8877c5e3\n",
            "  experiment_tag: 92_batch_size=1000,h1=64,h2=32,lr=0.082798,momentum=0.82109\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25482\n",
            "  time_since_restore: 380.48552680015564\n",
            "  time_this_iter_s: 380.48552680015564\n",
            "  time_total_s: 766.0682759284973\n",
            "  timestamp: 1603035949\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00092\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m [50000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=25482)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:50,238\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00088:\n",
            "  date: 2020-10-18_19-15-50\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: b5fe300cf57246e69c760cdeab8ea3c8\n",
            "  experiment_tag: 88_batch_size=1,h1=8,h2=32,lr=0.059191,momentum=0.88212\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 40.99227374544144\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25010\n",
            "  time_since_restore: 391.4794125556946\n",
            "  time_this_iter_s: 391.4794125556946\n",
            "  time_total_s: 794.5145273208618\n",
            "  timestamp: 1603035950\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00088\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m [50000] loss: 40.992\n",
            "\u001b[2m\u001b[36m(pid=25010)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:51,181\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00090:\n",
            "  date: 2020-10-18_19-15-51\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: f0e86ea330e44d1c890e5d5f00480b53\n",
            "  experiment_tag: 90_batch_size=1,h1=8,h2=16,lr=0.00046237,momentum=0.96445\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 19.48819387819767\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24987\n",
            "  time_since_restore: 387.33447647094727\n",
            "  time_this_iter_s: 387.33447647094727\n",
            "  time_total_s: 779.6585464477539\n",
            "  timestamp: 1603035951\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00090\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.1/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {RUNNING: 5, TERMINATED: 33} \n",
            "Resources requested: 5/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (5 RUNNING, 95 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00089 | RUNNING    |                   |            1 |   64 |  128 | 0.000802533 |   0.718561 |   9.23932 |\n",
            "| train_771eb_00090 | RUNNING    | 192.168.1.4:24987 |            1 |    8 |   16 | 0.00046237  |   0.964451 |  19.4882  |\n",
            "| train_771eb_00091 | RUNNING    |                   |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.8114  |\n",
            "| train_771eb_00095 | RUNNING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00096 | RUNNING    |                   |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.8318  |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404  |\n",
            "| train_771eb_00010 | TERMINATED |                   |          100 |  128 |   64 | 0.0728514   |   0.720064 | nan       |\n",
            "| train_771eb_00011 | TERMINATED |                   |            1 |   64 |   32 | 0.0333067   |   0.924837 |  40.0098  |\n",
            "| train_771eb_00012 | TERMINATED |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 | nan       |\n",
            "| train_771eb_00013 | TERMINATED |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |  35.4784  |\n",
            "| train_771eb_00014 | TERMINATED |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |  11.0566  |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (80 TERMINATED)\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m [50000] loss: 19.488\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24987)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:54,852\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00089:\n",
            "  date: 2020-10-18_19-15-54\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 8df118e2a6584e48af3616fc43813584\n",
            "  experiment_tag: 89_batch_size=1,h1=64,h2=128,lr=0.00080253,momentum=0.71856\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 9.442377821299434\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25025\n",
            "  time_since_restore: 396.02653765678406\n",
            "  time_this_iter_s: 396.02653765678406\n",
            "  time_total_s: 808.5742020606995\n",
            "  timestamp: 1603035954\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00089\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m [50000] loss: 9.442\n",
            "\u001b[2m\u001b[36m(pid=25025)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [ 5000] loss: 80.106\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [ 5000] loss: 48.760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:15:59,098\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00091:\n",
            "  date: 2020-10-18_19-15-59\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: eba302a68d3a406e83be31749b39dff7\n",
            "  experiment_tag: 91_batch_size=1,h1=32,h2=64,lr=6.7777e-05,momentum=0.68317\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.994484976804257\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 24955\n",
            "  time_since_restore: 390.3268413543701\n",
            "  time_this_iter_s: 390.3268413543701\n",
            "  time_total_s: 795.314270734787\n",
            "  timestamp: 1603035959\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00091\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 5.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {RUNNING: 3, TERMINATED: 35} \n",
            "Resources requested: 3/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (3 RUNNING, 97 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00091 | RUNNING    | 192.168.1.4:24955 |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |  10.9945  |\n",
            "| train_771eb_00095 | RUNNING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00096 | RUNNING    |                   |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.8318  |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404  |\n",
            "| train_771eb_00010 | TERMINATED |                   |          100 |  128 |   64 | 0.0728514   |   0.720064 | nan       |\n",
            "| train_771eb_00011 | TERMINATED |                   |            1 |   64 |   32 | 0.0333067   |   0.924837 |  40.0098  |\n",
            "| train_771eb_00012 | TERMINATED |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 | nan       |\n",
            "| train_771eb_00013 | TERMINATED |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |  35.4784  |\n",
            "| train_771eb_00014 | TERMINATED |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |  11.0566  |\n",
            "| train_771eb_00015 | TERMINATED |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |  26.4723  |\n",
            "| train_771eb_00016 | TERMINATED |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |  24.251   |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (80 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m [50000] loss: 10.994\n",
            "\u001b[2m\u001b[36m(pid=24955)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [10000] loss: 52.674\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [10000] loss: 30.623\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [15000] loss: 41.612\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [15000] loss: 35.861\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [20000] loss: 36.093\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [20000] loss: 34.144\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [25000] loss: 35.968\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [25000] loss: 29.247\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [30000] loss: 36.478\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [30000] loss: 26.809\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [35000] loss: 35.524\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [35000] loss: 23.940\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [40000] loss: 36.322\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [40000] loss: 22.503\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [45000] loss: 35.840\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [45000] loss: 20.613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:18:29,405\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00096:\n",
            "  date: 2020-10-18_19-18-29\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: 22ea35809ce3468f8403a5ff2619f8b9\n",
            "  experiment_tag: 96_batch_size=100,h1=128,h2=32,lr=0.00057708,momentum=0.67433\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.66073397581577\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25587\n",
            "  time_since_restore: 174.21306705474854\n",
            "  time_this_iter_s: 174.21306705474854\n",
            "  time_total_s: 391.27839946746826\n",
            "  timestamp: 1603036109\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00096\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m [50000] loss: 35.661\n",
            "\u001b[2m\u001b[36m(pid=25587)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 5.8/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=27, Milestone (r)=3, completed=-9.4%): {RUNNING: 2, TERMINATED: 36} \n",
            "Resources requested: 2/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (2 RUNNING, 98 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |      loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------|\n",
            "| train_771eb_00095 | RUNNING    |                   |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |  19.3837  |\n",
            "| train_771eb_00096 | RUNNING    | 192.168.1.4:25587 |          100 |  128 |   32 | 0.000577078 |   0.674333 |  35.6607  |\n",
            "| train_771eb_00000 | TERMINATED |                   |            1 |   16 |   64 | 0.00492288  |   0.820453 |  36.4714  |\n",
            "| train_771eb_00001 | TERMINATED |                   |           10 |    8 |    8 | 0.00132672  |   0.535895 |  36.3202  |\n",
            "| train_771eb_00002 | TERMINATED |                   |           10 |  128 |   32 | 0.0241017   |   0.565936 | nan       |\n",
            "| train_771eb_00003 | TERMINATED |                   |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |  20.0236  |\n",
            "| train_771eb_00004 | TERMINATED |                   |           10 |   16 |    8 | 0.000104871 |   0.860637 |  11.1043  |\n",
            "| train_771eb_00005 | TERMINATED |                   |            1 |  128 |   32 | 0.000623547 |   0.595976 |   9.27738 |\n",
            "| train_771eb_00006 | TERMINATED |                   |           10 |    8 |  128 | 0.0247025   |   0.560927 |  36.6433  |\n",
            "| train_771eb_00007 | TERMINATED |                   |           10 |    8 |   16 | 0.000309116 |   0.554296 |  11.5245  |\n",
            "| train_771eb_00008 | TERMINATED |                   |          100 |  128 |  128 | 0.00619614  |   0.860599 | nan       |\n",
            "| train_771eb_00009 | TERMINATED |                   |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |  22.6404  |\n",
            "| train_771eb_00010 | TERMINATED |                   |          100 |  128 |   64 | 0.0728514   |   0.720064 | nan       |\n",
            "| train_771eb_00011 | TERMINATED |                   |            1 |   64 |   32 | 0.0333067   |   0.924837 |  40.0098  |\n",
            "| train_771eb_00012 | TERMINATED |                   |         1000 |    8 |   64 | 0.0178356   |   0.838857 | nan       |\n",
            "| train_771eb_00013 | TERMINATED |                   |          100 |  128 |  128 | 0.00109204  |   0.500525 |  35.4784  |\n",
            "| train_771eb_00014 | TERMINATED |                   |            1 |  128 |    8 | 0.000220337 |   0.565689 |  11.0566  |\n",
            "| train_771eb_00015 | TERMINATED |                   |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |  26.4723  |\n",
            "| train_771eb_00016 | TERMINATED |                   |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |  24.251   |\n",
            "| train_771eb_00017 | TERMINATED |                   |         1000 |   64 |  128 | 0.000423194 |   0.914008 | nan       |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+-----------+\n",
            "... 80 more trials not shown (80 TERMINATED)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 19:18:32,274\tINFO hyperband.py:421 -- Restoring from a previous point in time. Previous=1; Now=1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_771eb_00095:\n",
            "  date: 2020-10-18_19-18-32\n",
            "  done: false\n",
            "  episodes_total: 0\n",
            "  experiment_id: ac6004bf550e4fe8a5ee7026c17aa4df\n",
            "  experiment_tag: 95_batch_size=1,h1=64,h2=64,lr=2.8635e-05,momentum=0.55605\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 19.555500680720804\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 25563\n",
            "  time_since_restore: 181.42224383354187\n",
            "  time_this_iter_s: 181.42224383354187\n",
            "  time_total_s: 574.7841949462891\n",
            "  timestamp: 1603036112\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 771eb_00095\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m [50000] loss: 19.556\n",
            "\u001b[2m\u001b[36m(pid=25563)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 5.7/15.5 GiB\n",
            "Using HyperBand: num_stopped=11 total_brackets=5\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-3.6%): {TERMINATED: 15} \n",
            "  Bracket(Max Size (n)=12, Milestone (r)=9, completed=-7.2%): {TERMINATED: 34} \n",
            "  Bracket(Max Size (n)=9, Milestone (r)=9, completed=-9.4%): {TERMINATED: 38} \n",
            "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 100 (100 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |           loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------------|\n",
            "| train_771eb_00000 | TERMINATED |       |            1 |   16 |   64 | 0.00492288  |   0.820453 |   36.4714      |\n",
            "| train_771eb_00001 | TERMINATED |       |           10 |    8 |    8 | 0.00132672  |   0.535895 |   36.3202      |\n",
            "| train_771eb_00002 | TERMINATED |       |           10 |  128 |   32 | 0.0241017   |   0.565936 |  nan           |\n",
            "| train_771eb_00003 | TERMINATED |       |           10 |   32 |   16 | 1.27708e-05 |   0.833976 |   20.0236      |\n",
            "| train_771eb_00004 | TERMINATED |       |           10 |   16 |    8 | 0.000104871 |   0.860637 |   11.1043      |\n",
            "| train_771eb_00005 | TERMINATED |       |            1 |  128 |   32 | 0.000623547 |   0.595976 |    9.27738     |\n",
            "| train_771eb_00006 | TERMINATED |       |           10 |    8 |  128 | 0.0247025   |   0.560927 |   36.6433      |\n",
            "| train_771eb_00007 | TERMINATED |       |           10 |    8 |   16 | 0.000309116 |   0.554296 |   11.5245      |\n",
            "| train_771eb_00008 | TERMINATED |       |          100 |  128 |  128 | 0.00619614  |   0.860599 |  nan           |\n",
            "| train_771eb_00009 | TERMINATED |       |         1000 |    8 |   64 | 2.1502e-05  |   0.689133 |   22.6404      |\n",
            "| train_771eb_00010 | TERMINATED |       |          100 |  128 |   64 | 0.0728514   |   0.720064 |  nan           |\n",
            "| train_771eb_00011 | TERMINATED |       |            1 |   64 |   32 | 0.0333067   |   0.924837 |   40.0098      |\n",
            "| train_771eb_00012 | TERMINATED |       |         1000 |    8 |   64 | 0.0178356   |   0.838857 |  nan           |\n",
            "| train_771eb_00013 | TERMINATED |       |          100 |  128 |  128 | 0.00109204  |   0.500525 |   35.4784      |\n",
            "| train_771eb_00014 | TERMINATED |       |            1 |  128 |    8 | 0.000220337 |   0.565689 |   11.0566      |\n",
            "| train_771eb_00015 | TERMINATED |       |          100 |    8 |   64 | 1.41627e-05 |   0.7107   |   26.4723      |\n",
            "| train_771eb_00016 | TERMINATED |       |           10 |  128 |   32 | 1.57199e-05 |   0.636361 |   24.251       |\n",
            "| train_771eb_00017 | TERMINATED |       |         1000 |   64 |  128 | 0.000423194 |   0.914008 |  nan           |\n",
            "| train_771eb_00018 | TERMINATED |       |          100 |   32 |   32 | 0.00138404  |   0.911168 |   36.288       |\n",
            "| train_771eb_00019 | TERMINATED |       |         1000 |   32 |   32 | 0.00037243  |   0.885834 |  nan           |\n",
            "| train_771eb_00020 | TERMINATED |       |            1 |   64 |  128 | 0.0628102   |   0.748114 |   38.1694      |\n",
            "| train_771eb_00021 | TERMINATED |       |          100 |   16 |   64 | 1.2933e-05  |   0.749235 |   22.3074      |\n",
            "| train_771eb_00022 | TERMINATED |       |          100 |  128 |   16 | 0.0796555   |   0.920876 |  nan           |\n",
            "| train_771eb_00023 | TERMINATED |       |            1 |   32 |   32 | 4.78669e-05 |   0.973818 |    9.33084     |\n",
            "| train_771eb_00024 | TERMINATED |       |           10 |    8 |  128 | 1.74313e-05 |   0.605809 |   25.9765      |\n",
            "| train_771eb_00025 | TERMINATED |       |         1000 |   64 |   64 | 1.55532e-05 |   0.620771 |   27.8224      |\n",
            "| train_771eb_00026 | TERMINATED |       |           10 |   16 |   64 | 0.000225445 |   0.720695 |    9.78717     |\n",
            "| train_771eb_00027 | TERMINATED |       |         1000 |    8 |   64 | 0.00290627  |   0.821822 |    1.28117e+06 |\n",
            "| train_771eb_00028 | TERMINATED |       |            1 |   16 |   32 | 0.000401921 |   0.610701 |    9.59191     |\n",
            "| train_771eb_00029 | TERMINATED |       |         1000 |   32 |   64 | 0.0851164   |   0.540514 |  nan           |\n",
            "| train_771eb_00030 | TERMINATED |       |            1 |   32 |   16 | 8.23175e-05 |   0.608186 |   11.5597      |\n",
            "| train_771eb_00031 | TERMINATED |       |           10 |    8 |   32 | 1.81342e-05 |   0.564515 |   26.7682      |\n",
            "| train_771eb_00032 | TERMINATED |       |            1 |   16 |   64 | 6.98617e-05 |   0.898306 |    9.23875     |\n",
            "| train_771eb_00033 | TERMINATED |       |           10 |   16 |  128 | 0.00161962  |   0.898606 |   35.6265      |\n",
            "| train_771eb_00034 | TERMINATED |       |            1 |   32 |    8 | 0.0497771   |   0.758362 |   37.823       |\n",
            "| train_771eb_00035 | TERMINATED |       |         1000 |   64 |   16 | 1.94962e-05 |   0.651273 |   23.0197      |\n",
            "| train_771eb_00036 | TERMINATED |       |          100 |   32 |   64 | 0.0201081   |   0.514602 |  nan           |\n",
            "| train_771eb_00037 | TERMINATED |       |           10 |   64 |   32 | 0.00366981  |   0.978938 |   37.8826      |\n",
            "| train_771eb_00038 | TERMINATED |       |           10 |  128 |    8 | 0.00380114  |   0.728068 |   35.8689      |\n",
            "| train_771eb_00039 | TERMINATED |       |          100 |    8 |   32 | 0.00868283  |   0.92879  |   38.8086      |\n",
            "| train_771eb_00040 | TERMINATED |       |          100 |   16 |   32 | 3.09971e-05 |   0.968119 |   12.9565      |\n",
            "| train_771eb_00041 | TERMINATED |       |            1 |   16 |  128 | 0.000243597 |   0.823279 |    9.16981     |\n",
            "| train_771eb_00042 | TERMINATED |       |         1000 |   16 |    8 | 1.26658e-05 |   0.719753 |   31.0058      |\n",
            "| train_771eb_00043 | TERMINATED |       |           10 |   32 |   32 | 0.000552758 |   0.929839 |   13.7335      |\n",
            "| train_771eb_00044 | TERMINATED |       |           10 |    8 |  128 | 7.2533e-05  |   0.86029  |   10.9219      |\n",
            "| train_771eb_00045 | TERMINATED |       |         1000 |   64 |   64 | 0.0770321   |   0.819817 |  nan           |\n",
            "| train_771eb_00046 | TERMINATED |       |           10 |  128 |    8 | 0.00125046  |   0.909294 |   36.1887      |\n",
            "| train_771eb_00047 | TERMINATED |       |          100 |   16 |    8 | 0.0004038   |   0.760716 |   36.1102      |\n",
            "| train_771eb_00048 | TERMINATED |       |           10 |   64 |   64 | 3.45114e-05 |   0.706125 |   13.093       |\n",
            "| train_771eb_00049 | TERMINATED |       |          100 |   16 |  128 | 0.0167206   |   0.769885 |  nan           |\n",
            "| train_771eb_00050 | TERMINATED |       |          100 |   64 |   16 | 0.0011488   |   0.937267 |   35.9096      |\n",
            "| train_771eb_00051 | TERMINATED |       |            1 |  128 |   16 | 0.0991417   |   0.95929  |   62.908       |\n",
            "| train_771eb_00052 | TERMINATED |       |           10 |   16 |   32 | 0.00159151  |   0.853648 |   35.9576      |\n",
            "| train_771eb_00053 | TERMINATED |       |            1 |   64 |    8 | 7.70235e-05 |   0.722191 |   10.4876      |\n",
            "| train_771eb_00054 | TERMINATED |       |           10 |  128 |  128 | 3.12763e-05 |   0.820219 |   11.3134      |\n",
            "| train_771eb_00055 | TERMINATED |       |           10 |    8 |   64 | 4.01575e-05 |   0.834794 |   13.6013      |\n",
            "| train_771eb_00056 | TERMINATED |       |            1 |    8 |   64 | 7.91824e-05 |   0.637022 |   13.3974      |\n",
            "| train_771eb_00057 | TERMINATED |       |            1 |    8 |  128 | 0.000145862 |   0.71493  |   10.4337      |\n",
            "| train_771eb_00058 | TERMINATED |       |         1000 |    8 |    8 | 0.000478096 |   0.842333 |   35.645       |\n",
            "| train_771eb_00059 | TERMINATED |       |           10 |    8 |  128 | 0.000838305 |   0.789075 |   11.2316      |\n",
            "| train_771eb_00060 | TERMINATED |       |           10 |   32 |   32 | 0.000134219 |   0.611783 |   10.1909      |\n",
            "| train_771eb_00061 | TERMINATED |       |         1000 |  128 |  128 | 0.000370386 |   0.762688 |  nan           |\n",
            "| train_771eb_00062 | TERMINATED |       |         1000 |    8 |   16 | 0.0148077   |   0.610719 |  nan           |\n",
            "| train_771eb_00063 | TERMINATED |       |          100 |   64 |    8 | 0.00112387  |   0.597223 |   36.2642      |\n",
            "| train_771eb_00064 | TERMINATED |       |           10 |   64 |   16 | 0.00537073  |   0.574478 |   35.7165      |\n",
            "| train_771eb_00065 | TERMINATED |       |          100 |   16 |   32 | 0.000171083 |   0.833695 |   31.6227      |\n",
            "| train_771eb_00066 | TERMINATED |       |         1000 |   32 |    8 | 0.000819632 |   0.665984 |   35.7797      |\n",
            "| train_771eb_00067 | TERMINATED |       |           10 |    8 |   64 | 0.00146429  |   0.760084 |   13.0121      |\n",
            "| train_771eb_00068 | TERMINATED |       |         1000 |   32 |   64 | 0.0647617   |   0.710473 |  nan           |\n",
            "| train_771eb_00069 | TERMINATED |       |         1000 |  128 |    8 | 0.000156659 |   0.780344 |   35.9721      |\n",
            "| train_771eb_00070 | TERMINATED |       |            1 |  128 |   64 | 0.000147746 |   0.58938  |    9.89839     |\n",
            "| train_771eb_00071 | TERMINATED |       |           10 |   16 |   64 | 2.68361e-05 |   0.980344 |    9.36523     |\n",
            "| train_771eb_00072 | TERMINATED |       |           10 |   32 |  128 | 6.11461e-05 |   0.877038 |    9.71149     |\n",
            "| train_771eb_00073 | TERMINATED |       |          100 |   16 |    8 | 9.73342e-05 |   0.986201 |   35.9849      |\n",
            "| train_771eb_00074 | TERMINATED |       |          100 |   16 |  128 | 0.0260674   |   0.737861 |   37.7953      |\n",
            "| train_771eb_00075 | TERMINATED |       |           10 |   32 |  128 | 0.000563108 |   0.810928 |    9.59804     |\n",
            "| train_771eb_00076 | TERMINATED |       |         1000 |   64 |  128 | 0.0172635   |   0.539725 |  nan           |\n",
            "| train_771eb_00077 | TERMINATED |       |            1 |    8 |  128 | 0.00299448  |   0.802929 |   12.7976      |\n",
            "| train_771eb_00078 | TERMINATED |       |          100 |    8 |   16 | 2.9735e-05  |   0.76234  |   15.0334      |\n",
            "| train_771eb_00079 | TERMINATED |       |            1 |   16 |  128 | 0.00387142  |   0.570771 |   11.1123      |\n",
            "| train_771eb_00080 | TERMINATED |       |         1000 |   64 |   16 | 0.00205382  |   0.632732 |  nan           |\n",
            "| train_771eb_00081 | TERMINATED |       |          100 |   32 |   64 | 0.000149239 |   0.569827 |   14.9344      |\n",
            "| train_771eb_00082 | TERMINATED |       |         1000 |  128 |   16 | 0.000311907 |   0.875645 |    7.6773e+27  |\n",
            "| train_771eb_00083 | TERMINATED |       |           10 |    8 |   32 | 0.00508818  |   0.730759 |   35.5         |\n",
            "| train_771eb_00084 | TERMINATED |       |         1000 |   32 |   32 | 0.000244123 |   0.911902 | 9120.69        |\n",
            "| train_771eb_00085 | TERMINATED |       |           10 |   16 |   64 | 0.000115223 |   0.752489 |   10.0315      |\n",
            "| train_771eb_00086 | TERMINATED |       |           10 |   32 |    8 | 7.73546e-05 |   0.810635 |    9.83442     |\n",
            "| train_771eb_00087 | TERMINATED |       |          100 |   64 |   32 | 9.05614e-05 |   0.776397 |   11.0796      |\n",
            "| train_771eb_00088 | TERMINATED |       |            1 |    8 |   32 | 0.0591907   |   0.882117 |   40.9923      |\n",
            "| train_771eb_00089 | TERMINATED |       |            1 |   64 |  128 | 0.000802533 |   0.718561 |    9.44238     |\n",
            "| train_771eb_00090 | TERMINATED |       |            1 |    8 |   16 | 0.00046237  |   0.964451 |   19.4882      |\n",
            "| train_771eb_00091 | TERMINATED |       |            1 |   32 |   64 | 6.77773e-05 |   0.683171 |   10.9945      |\n",
            "| train_771eb_00092 | TERMINATED |       |         1000 |   64 |   32 | 0.0827984   |   0.821088 |  nan           |\n",
            "| train_771eb_00093 | TERMINATED |       |            1 |    8 |   64 | 0.0407744   |   0.934975 |   42.4072      |\n",
            "| train_771eb_00094 | TERMINATED |       |           10 |   16 |   32 | 0.00154639  |   0.563597 |   36.3023      |\n",
            "| train_771eb_00095 | TERMINATED |       |            1 |   64 |   64 | 2.86347e-05 |   0.55605  |   19.5555      |\n",
            "| train_771eb_00096 | TERMINATED |       |          100 |  128 |   32 | 0.000577078 |   0.674333 |   35.6607      |\n",
            "| train_771eb_00097 | TERMINATED |       |         1000 |   16 |   32 | 0.000736153 |   0.950656 |  107.281       |\n",
            "| train_771eb_00098 | TERMINATED |       |            1 |  128 |  128 | 0.00484998  |   0.732569 |   13.2283      |\n",
            "| train_771eb_00099 | TERMINATED |       |            1 |   64 |   32 | 0.0106433   |   0.979056 |   40.8104      |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLY1ZriB-xFl"
      },
      "source": [
        "### Best Hyperparameter of Ray Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woYpslj28rBo",
        "outputId": "9ba21501-0c0a-4047-a3d7-5503db18ceb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best trial config: {'h1': 16, 'h2': 128, 'lr': 0.00024359708462730486, 'num_batch': 50000, 'momentum': 0.8232790978931446, 'batch_size': 1}\n",
            "Best trial final validation loss: 9.169814102506638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B9pMxez-1fE"
      },
      "source": [
        "### Testing the Best of RayTune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRMTHZQoLzJj"
      },
      "source": [
        "l2 = test(best_trial.config)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOrmjWCG-7P7"
      },
      "source": [
        "### Plot and Comparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCo3utwFLzC3",
        "outputId": "dab7d63f-97be-405a-988a-96dabcbc0e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_me([l,l2])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[13.15940514755249, 9.279495883703232]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}