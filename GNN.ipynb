{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPdvV9rDpJUguIAycXDOqXa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahi97/MahiColabs/blob/master/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD3l-oiQ40pY"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "1. random, numpy -> simple random arrauys and numbers\n",
        "2. torch -> deseing and optimize GNN\n",
        "3. dgl -> Used to create GNN layers and model\n",
        "4. ray -> Just used for tuning hyper parameters\n",
        "5. networkx -> Generate random graphs \n",
        "6. matplotlib -> Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n39El8omMGEK",
        "outputId": "68c52684-315b-47d8-c60e-b26fde080513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "  \n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import HyperBandScheduler\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "\n",
        "from networkx.generators.random_graphs import erdos_renyi_graph\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhMalAvv5s6Q"
      },
      "source": [
        "### Easy Plotter Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruWHfynykkSl"
      },
      "source": [
        "def plot_me(x):\n",
        "  [plt.plot(l) for l in x]\n",
        "  plt.ylabel('Running Loss')\n",
        "  plt.show()\n",
        "  print([l[-1] for l in x])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V4P2jqa_MM_"
      },
      "source": [
        "# Generating Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkpkFbgS5w6B"
      },
      "source": [
        "### Generate Random Graphs\n",
        "\n",
        "For any number of nodes and probability of edge existance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeT-KEyfpi3E"
      },
      "source": [
        "def generate_random_graph(num_nodes, prob):\n",
        "  g = erdos_renyi_graph(num_nodes, prob)\n",
        "  [g.add_edge(i, i) for i in range(num_nodes)] # add self-loop\n",
        "\n",
        "  # Generate Adj. Matrix of Graph\n",
        "  a = torch.zeros(num_nodes, num_nodes)\n",
        "  for n in g.edges:\n",
        "    a[n[0]][n[1]] = 1.0\n",
        "    a[n[1]][n[0]] = 1.0\n",
        "    a[n[0]][n[0]] = 1.0\n",
        "    a[n[1]][n[1]] = 1.0\n",
        "\n",
        "  # Generate dgl object of graph \n",
        "  u = list(map(lambda x : x[0], g.edges))\n",
        "  v = list(map(lambda x : x[1], g.edges))  \n",
        "  g = dgl.graph((torch.tensor(u), torch.tensor(v)))\n",
        "  g = dgl.add_self_loop(g)\n",
        "\n",
        "  return g, a"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3057gzL6tAn"
      },
      "source": [
        "### Data Loader Function\n",
        "\n",
        "## Generate data dictionary for training GNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbEah08FMPUe"
      },
      "source": [
        "def data_loader(num_batch):\n",
        "  w = torch.Tensor([\n",
        "                  [2.7, 0.0, 1.0],\n",
        "                  [1.2, 1.3, 0.2],\n",
        "                  [0.0, 0.5, 0.0],\n",
        "                  [2.1, 0.0, 1.1],\n",
        "                  [0.0, 0.0, 0.7]])\n",
        "  for i in range(num_batch):\n",
        "    p = random.random()\n",
        "    g, a =  generate_random_graph(10, p)\n",
        "    x = torch.rand(10, 5)\n",
        "    \n",
        "    yield {\n",
        "        'feat': x,\n",
        "        'graph': g,\n",
        "        'label': torch.matmul(torch.matmul(a, x), w)\n",
        "        }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urkid7K7CPOg"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuewvoE5CRNS"
      },
      "source": [
        "##1. GNN With GraphConv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-awJmwNOOR7A"
      },
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, hid2_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.GraphConv(in_feats=in_feats, \n",
        "                                    out_feats=hid_feats) \n",
        "                                    # aggregator_type='mean')\n",
        "        self.conv2 = dglnn.GraphConv(in_feats=hid_feats, \n",
        "                                    out_feats=hid2_feats) \n",
        "        self.conv3 = dglnn.GraphConv(in_feats=hid2_feats, \n",
        "                                    out_feats=out_feats) \n",
        "                                    # aggregator_type='mean')\n",
        "                                    \n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(graph, h)\n",
        "        return h"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQmTBci3637G"
      },
      "source": [
        "## Simple Training Procedure\n",
        "#### Test Function for evaluationg hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PosYck1AkLyH"
      },
      "source": [
        "def test(config):\n",
        "  model = GNN(5, config['h1'], config['h2'], 3)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "\n",
        "  losses = []\n",
        "  running_loss = 0\n",
        "  iter = 0\n",
        "  for i, data in enumerate(data_loader(config['num_batch'])):\n",
        "    model.train()\n",
        "    iter += 1\n",
        "    g = data['graph']\n",
        "    x = data['feat']\n",
        "    labels = data['label']\n",
        "    outputs = model(g, x)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    # optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # print statistics\n",
        "    if i % 1000 == 999:\n",
        "        print(\"[%5d] loss: %.3f\" % (i + 1, running_loss / iter))\n",
        "        losses.append(running_loss / iter)\n",
        "        iter = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "    if i % config['batch_size'] == config['batch_size'] - 1:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "  return losses"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xP4-ezRkMui",
        "outputId": "4cb2e2d8-d635-4624-f9db-cea7eada85ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "l = test({\n",
        "    'h1' : 10,\n",
        "    'h2' : 10,\n",
        "    'lr' : 1e-3,\n",
        "    'momentum' : 0.9,\n",
        "    'num_batch': 20000,\n",
        "    'batch_size': 1\n",
        "})"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1000] loss: 36.450\n",
            "[ 2000] loss: 25.412\n",
            "[ 3000] loss: 22.974\n",
            "[ 4000] loss: 20.570\n",
            "[ 5000] loss: 20.422\n",
            "[ 6000] loss: 17.687\n",
            "[ 7000] loss: 17.288\n",
            "[ 8000] loss: 14.989\n",
            "[ 9000] loss: 17.069\n",
            "[10000] loss: 14.812\n",
            "[11000] loss: 14.837\n",
            "[12000] loss: 14.309\n",
            "[13000] loss: 15.224\n",
            "[14000] loss: 14.981\n",
            "[15000] loss: 14.120\n",
            "[16000] loss: 14.608\n",
            "[17000] loss: 13.553\n",
            "[18000] loss: 13.140\n",
            "[19000] loss: 13.260\n",
            "[20000] loss: 14.141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZMdmk6_kwOl",
        "outputId": "46396562-ce45-4d33-a5d4-a06862080797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_me([l])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[14.140532826066018]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9qwSCWkor_7"
      },
      "source": [
        "# Tuning of Hyper-Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQcVuN8L-lXD"
      },
      "source": [
        "## Ray Tune Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLpKviWqLMc"
      },
      "source": [
        "def train(config):\n",
        "  model = GNN(5, config['h1'], config['h2'], 3)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "\n",
        "\n",
        "  running_loss = 0\n",
        "  final = 0\n",
        "  iter = 0\n",
        "  for i, data in enumerate(data_loader(config['num_batch'])):\n",
        "    model.train()\n",
        "    iter += 1\n",
        "    g = data['graph']\n",
        "    x = data['feat']\n",
        "    labels = data['label']\n",
        "    outputs = model(g, x)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    # optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # print statistics\n",
        "    final = running_loss / iter\n",
        "    # print statistics\n",
        "    if i % 1000 == 999:\n",
        "        print(\"[%5d] loss: %.3f\" % (i + 1, running_loss / iter))\n",
        "        iter = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "    if i % config['batch_size'] == config['batch_size'] - 1:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "  tune.report(loss=final)\n",
        "  print(\"Finished Training\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhFUxs3-pEW"
      },
      "source": [
        "## Ray Tune Main Scenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0LwcP4gCadc"
      },
      "source": [
        "#### What we tune:\n",
        "\n",
        "1. Number of neurons in first hidden layer (2^n) [1 < n < 8]\n",
        "2. Number of neurons in second hidden layer (2^n) [1 < n < 8] \n",
        "3. Learning Rate [1e-5 < lr < 1e-1]\n",
        "4. Momentum of SGD [0.5 < m < 1]\n",
        "5. Batch Size 10^n [0 < n < 4]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vHrnQPipvcC",
        "outputId": "5d181f9d-774a-4591-972c-ccee18126478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_batch=20000\n",
        "num_samples = 24 \n",
        "config = {\n",
        "    \"h1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 8)),\n",
        "    \"h2\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 8)),\n",
        "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
        "    \"num_batch\": num_batch,\n",
        "    \"momentum\": tune.uniform(0.5, 0.99),\n",
        "    \"batch_size\": tune.sample_from(lambda _: 10 ** np.random.randint(0, 4))\n",
        "}\n",
        "\n",
        "hyperband = HyperBandScheduler(metric=\"loss\", mode=\"min\")\n",
        "\n",
        "reporter = CLIReporter(metric_columns=[\"loss\"])\n",
        "\n",
        "result = tune.run(\n",
        "    train,\n",
        "    config=config,\n",
        "    num_samples=num_samples,\n",
        "    scheduler=hyperband,\n",
        "    progress_reporter=reporter\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 17:54:29,005\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2020-10-18 17:54:29,246\tWARNING function_runner.py:486 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
            "2020-10-18 17:54:29,331\tWARNING tune.py:396 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 5.0/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=3\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=0.0%): {PENDING: 4, RUNNING: 1} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=0.0%): {PENDING: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 11} \n",
            "Resources requested: 1/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 24 (23 PENDING, 1 RUNNING)\n",
            "+-------------------+----------+-------+--------------+------+------+-------------+------------+\n",
            "| Trial name        | status   | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |\n",
            "|-------------------+----------+-------+--------------+------+------+-------------+------------|\n",
            "| train_a2047_00001 | PENDING  |       |            1 |   64 |    8 | 0.0737988   |   0.678238 |\n",
            "| train_a2047_00002 | PENDING  |       |         1000 |    8 |   16 | 1.07313e-05 |   0.589369 |\n",
            "| train_a2047_00003 | PENDING  |       |         1000 |   64 |   32 | 0.00486594  |   0.528756 |\n",
            "| train_a2047_00004 | PENDING  |       |         1000 |    8 |   16 | 0.000676748 |   0.921247 |\n",
            "| train_a2047_00005 | PENDING  |       |            1 |   32 |  128 | 0.00198688  |   0.776994 |\n",
            "| train_a2047_00006 | PENDING  |       |          100 |   16 |  128 | 0.00337964  |   0.717471 |\n",
            "| train_a2047_00007 | PENDING  |       |         1000 |   64 |  128 | 0.012411    |   0.644994 |\n",
            "| train_a2047_00008 | PENDING  |       |          100 |   64 |   32 | 0.012294    |   0.52366  |\n",
            "| train_a2047_00009 | PENDING  |       |         1000 |  128 |   32 | 0.0158148   |   0.852333 |\n",
            "| train_a2047_00010 | PENDING  |       |           10 |   16 |   16 | 4.4709e-05  |   0.865333 |\n",
            "| train_a2047_00011 | PENDING  |       |           10 |   64 |   32 | 0.0094289   |   0.642795 |\n",
            "| train_a2047_00012 | PENDING  |       |            1 |   16 |   64 | 2.95773e-05 |   0.987101 |\n",
            "| train_a2047_00013 | PENDING  |       |          100 |   64 |   16 | 2.01472e-05 |   0.673017 |\n",
            "| train_a2047_00014 | PENDING  |       |          100 |   32 |   32 | 0.000135655 |   0.721037 |\n",
            "| train_a2047_00015 | PENDING  |       |          100 |  128 |   32 | 0.0177869   |   0.944948 |\n",
            "| train_a2047_00016 | PENDING  |       |          100 |   64 |   16 | 0.0643478   |   0.887535 |\n",
            "| train_a2047_00017 | PENDING  |       |         1000 |  128 |    8 | 0.00029944  |   0.524602 |\n",
            "| train_a2047_00018 | PENDING  |       |          100 |  128 |   32 | 0.0401815   |   0.684186 |\n",
            "| train_a2047_00019 | PENDING  |       |         1000 |   32 |   64 | 0.094647    |   0.612066 |\n",
            "| train_a2047_00000 | RUNNING  |       |           10 |  128 |   32 | 1.13376e-05 |   0.571503 |\n",
            "+-------------------+----------+-------+--------------+------+------+-------------+------------+\n",
            "... 4 more trials not shown (4 PENDING)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 1000] loss: 156.783\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 1000] loss: 98.697\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 1000] loss: 162.448\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 1000] loss: 165.279\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 1000] loss: 52.412\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 1000] loss: 163.739\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 1000] loss: 37.856\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 1000] loss: 154.145\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 1000] loss: 260.395\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 1000] loss: 150.633\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 1000] loss: 132186.567\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 1000] loss: 41.361\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 2000] loss: 41438030.500\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 2000] loss: 13326567706.112\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 2000] loss: 43.817\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 2000] loss: 51.208\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 2000] loss: 39.072\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 2000] loss: 4253317647.616\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 2000] loss: 51.011\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 2000] loss: 154.135\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 2000] loss: 22.073\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 2000] loss: 35.812\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 2000] loss: 146.311\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 2000] loss: 6639.600\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 3000] loss: 8291357859703874912256.000\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 3000] loss: 1981.920\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 3000] loss: 32248382367973403690795008.000\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 3000] loss: 42.521\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 3000] loss: 146.408\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 3000] loss: 35.535\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 3000] loss: 36.619\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 3000] loss: 18707262749024949213593600.000\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 3000] loss: 37.080\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 3000] loss: 19.258\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 3000] loss: 119.743\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 3000] loss: 509.706\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 4000] loss: 5283.437\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 4000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 4000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 4000] loss: 35.544\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 4000] loss: 129.243\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 4000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 4000] loss: 36.409\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 4000] loss: 37.592\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 4000] loss: 84.795\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 4000] loss: 37.588\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 4000] loss: 49.248\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 4000] loss: 18.819\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 5000] loss: 85.384\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 5000] loss: 113.296\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 5000] loss: 29.432\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 5000] loss: 35.499\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 5000] loss: 65.611\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 5000] loss: 34.335\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 5000] loss: 39.964\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 5000] loss: 37.660\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 5000] loss: 16.239\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 6000] loss: 130.550\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 6000] loss: 96.029\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 6000] loss: 24.474\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 6000] loss: 38.170\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 6000] loss: 67.206\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 6000] loss: 36.823\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 6000] loss: 38.025\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 6000] loss: 13.881\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 6000] loss: 36.009\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 7000] loss: 379.912\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 7000] loss: 73.659\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 7000] loss: 23.660\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 7000] loss: 63.228\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 7000] loss: 35.490\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 7000] loss: 37.545\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 7000] loss: 37.949\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 7000] loss: 36.211\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 7000] loss: 13.716\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 8000] loss: 398.117\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 8000] loss: 64.957\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 8000] loss: 21.895\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 8000] loss: 63.641\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 8000] loss: 36.369\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 8000] loss: 35.697\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 8000] loss: 38.127\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 8000] loss: 36.393\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 8000] loss: 14.151\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [ 9000] loss: 160.678\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [ 9000] loss: 69.010\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [ 9000] loss: 21.396\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [ 9000] loss: 63.055\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [ 9000] loss: 36.028\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [ 9000] loss: 35.594\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [ 9000] loss: 36.939\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [ 9000] loss: 34.601\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [ 9000] loss: 14.056\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [10000] loss: 48.112\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [10000] loss: 59.855\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [10000] loss: 21.046\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [10000] loss: 37.289\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [10000] loss: 62.308\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [10000] loss: 37.947\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [10000] loss: 39.605\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [10000] loss: 36.254\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [10000] loss: 14.024\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [11000] loss: 192.272\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [11000] loss: 58.788\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [11000] loss: 19.823\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [11000] loss: 36.045\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [11000] loss: 36.878\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [11000] loss: 38.583\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [11000] loss: 58.708\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [11000] loss: 35.200\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [11000] loss: 12.933\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [12000] loss: 310.073\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [12000] loss: 61.453\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [12000] loss: 20.498\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [12000] loss: 37.990\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [12000] loss: 37.618\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [12000] loss: 39.936\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [12000] loss: 62.619\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [12000] loss: 34.783\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [12000] loss: 13.430\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [13000] loss: 203.406\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [13000] loss: 58.045\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [13000] loss: 18.641\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [13000] loss: 34.882\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [13000] loss: 36.214\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [13000] loss: 39.747\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [13000] loss: 36.562\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [13000] loss: 58.350\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [13000] loss: 13.243\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [14000] loss: 56.393\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [14000] loss: 17.867\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [14000] loss: 57.673\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [14000] loss: 35.556\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [14000] loss: 36.147\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [14000] loss: 37.826\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [14000] loss: 36.285\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [14000] loss: 57.696\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [14000] loss: 12.908\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [15000] loss: 80.871\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [15000] loss: 16.838\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [15000] loss: 36.879\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [15000] loss: 37.493\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [15000] loss: 58.700\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [15000] loss: 38.463\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [15000] loss: 36.794\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [15000] loss: 55.732\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [15000] loss: 12.428\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [16000] loss: 199.645\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [16000] loss: 16.835\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [16000] loss: 35.125\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [16000] loss: 56.402\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [16000] loss: 34.991\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [16000] loss: 39.454\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [16000] loss: 36.510\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [16000] loss: 58.013\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [16000] loss: 12.605\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [17000] loss: 202.662\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [17000] loss: 16.493\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [17000] loss: 35.536\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [17000] loss: 55.956\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [17000] loss: 35.868\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [17000] loss: 36.302\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [17000] loss: 36.999\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [17000] loss: 54.949\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [17000] loss: 12.649\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [18000] loss: 95.173\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [18000] loss: 15.218\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [18000] loss: 35.896\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [18000] loss: 35.991\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [18000] loss: 52.659\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [18000] loss: 35.314\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [18000] loss: 37.745\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [18000] loss: 54.685\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [19000] loss: 40.692\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [18000] loss: 12.304\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [19000] loss: 15.471\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [19000] loss: 35.554\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [19000] loss: 36.997\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [19000] loss: 50.680\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [19000] loss: 35.990\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [19000] loss: 39.339\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [19000] loss: 52.101\n",
            "Result for train_a2047_00004:\n",
            "  date: 2020-10-18_17-56-50\n",
            "  done: false\n",
            "  experiment_id: 9597b02aa25a426f96c464fed06708eb\n",
            "  experiment_tag: 4_batch_size=1000,h1=8,h2=16,lr=0.00067675,momentum=0.92125\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 111.52823372650147\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20336\n",
            "  time_since_restore: 138.59900832176208\n",
            "  time_this_iter_s: 138.59900832176208\n",
            "  time_total_s: 138.59900832176208\n",
            "  timestamp: 1603031210\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00004\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m [20000] loss: 111.528\n",
            "\u001b[2m\u001b[36m(pid=20336)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=3\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=-0.2%): {RUNNING: 5} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=0.0%): {PENDING: 1, RUNNING: 7} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 11} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 24 (12 PENDING, 12 RUNNING)\n",
            "+-------------------+----------+-------------------+--------------+------+------+-------------+------------+---------+\n",
            "| Trial name        | status   | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |    loss |\n",
            "|-------------------+----------+-------------------+--------------+------+------+-------------+------------+---------|\n",
            "| train_a2047_00012 | PENDING  |                   |            1 |   16 |   64 | 2.95773e-05 |   0.987101 |         |\n",
            "| train_a2047_00013 | PENDING  |                   |          100 |   64 |   16 | 2.01472e-05 |   0.673017 |         |\n",
            "| train_a2047_00014 | PENDING  |                   |          100 |   32 |   32 | 0.000135655 |   0.721037 |         |\n",
            "| train_a2047_00015 | PENDING  |                   |          100 |  128 |   32 | 0.0177869   |   0.944948 |         |\n",
            "| train_a2047_00016 | PENDING  |                   |          100 |   64 |   16 | 0.0643478   |   0.887535 |         |\n",
            "| train_a2047_00017 | PENDING  |                   |         1000 |  128 |    8 | 0.00029944  |   0.524602 |         |\n",
            "| train_a2047_00018 | PENDING  |                   |          100 |  128 |   32 | 0.0401815   |   0.684186 |         |\n",
            "| train_a2047_00019 | PENDING  |                   |         1000 |   32 |   64 | 0.094647    |   0.612066 |         |\n",
            "| train_a2047_00020 | PENDING  |                   |           10 |  128 |    8 | 0.0128129   |   0.674578 |         |\n",
            "| train_a2047_00021 | PENDING  |                   |            1 |   32 |   32 | 0.0750197   |   0.673524 |         |\n",
            "| train_a2047_00000 | RUNNING  |                   |           10 |  128 |   32 | 1.13376e-05 |   0.571503 |         |\n",
            "| train_a2047_00001 | RUNNING  |                   |            1 |   64 |    8 | 0.0737988   |   0.678238 |         |\n",
            "| train_a2047_00002 | RUNNING  |                   |         1000 |    8 |   16 | 1.07313e-05 |   0.589369 |         |\n",
            "| train_a2047_00003 | RUNNING  |                   |         1000 |   64 |   32 | 0.00486594  |   0.528756 |         |\n",
            "| train_a2047_00004 | RUNNING  | 192.168.1.4:20336 |         1000 |    8 |   16 | 0.000676748 |   0.921247 | 111.528 |\n",
            "| train_a2047_00005 | RUNNING  |                   |            1 |   32 |  128 | 0.00198688  |   0.776994 |         |\n",
            "| train_a2047_00006 | RUNNING  |                   |          100 |   16 |  128 | 0.00337964  |   0.717471 |         |\n",
            "| train_a2047_00007 | RUNNING  |                   |         1000 |   64 |  128 | 0.012411    |   0.644994 |         |\n",
            "| train_a2047_00008 | RUNNING  |                   |          100 |   64 |   32 | 0.012294    |   0.52366  |         |\n",
            "| train_a2047_00009 | RUNNING  |                   |         1000 |  128 |   32 | 0.0158148   |   0.852333 |         |\n",
            "+-------------------+----------+-------------------+--------------+------+------+-------------+------------+---------+\n",
            "... 4 more trials not shown (2 PENDING, 2 RUNNING)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [19000] loss: 12.939\n",
            "Result for train_a2047_00010:\n",
            "  date: 2020-10-18_17-56-51\n",
            "  done: false\n",
            "  experiment_id: 40d2fc7997474357a82c62eda084e7f5\n",
            "  experiment_tag: 10_batch_size=10,h1=16,h2=16,lr=4.4709e-05,momentum=0.86533\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 14.924950712680817\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20344\n",
            "  time_since_restore: 140.0497739315033\n",
            "  time_this_iter_s: 140.0497739315033\n",
            "  time_total_s: 140.0497739315033\n",
            "  timestamp: 1603031211\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00010\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m [20000] loss: 14.925\n",
            "\u001b[2m\u001b[36m(pid=20344)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_a2047_00003:\n",
            "  date: 2020-10-18_17-56-52\n",
            "  done: false\n",
            "  experiment_id: f0a2afad0be3435db258411835c3fa72\n",
            "  experiment_tag: 3_batch_size=1000,h1=64,h2=32,lr=0.0048659,momentum=0.52876\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20348\n",
            "  time_since_restore: 141.44317388534546\n",
            "  time_this_iter_s: 141.44317388534546\n",
            "  time_total_s: 141.44317388534546\n",
            "  timestamp: 1603031212\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00003\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20348)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_a2047_00006:\n",
            "  date: 2020-10-18_17-56-53\n",
            "  done: false\n",
            "  experiment_id: 224becb30e0942e8b00dd29a30735bdb\n",
            "  experiment_tag: 6_batch_size=100,h1=16,h2=128,lr=0.0033796,momentum=0.71747\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.8514783771038\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20337\n",
            "  time_since_restore: 141.54590582847595\n",
            "  time_this_iter_s: 141.54590582847595\n",
            "  time_total_s: 141.54590582847595\n",
            "  timestamp: 1603031213\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00006\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m [20000] loss: 36.851\n",
            "\u001b[2m\u001b[36m(pid=20337)\u001b[0m Finished Training\n",
            "Result for train_a2047_00008:\n",
            "  date: 2020-10-18_17-56-53\n",
            "  done: false\n",
            "  experiment_id: 50178c6c9d4746b79038d6c4ba5f9ff2\n",
            "  experiment_tag: 8_batch_size=100,h1=64,h2=32,lr=0.012294,momentum=0.52366\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.84711087560654\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20345\n",
            "  time_since_restore: 141.87251806259155\n",
            "  time_this_iter_s: 141.87251806259155\n",
            "  time_total_s: 141.87251806259155\n",
            "  timestamp: 1603031213\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00008\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m [20000] loss: 35.847\n",
            "Result for train_a2047_00002:\n",
            "  date: 2020-10-18_17-56-53\n",
            "  done: false\n",
            "  experiment_id: 69fab7b884f44483867b232e7de5663f\n",
            "  experiment_tag: 2_batch_size=1000,h1=8,h2=16,lr=1.0731e-05,momentum=0.58937\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 52.59307874727249\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20340\n",
            "  time_since_restore: 142.20284581184387\n",
            "  time_this_iter_s: 142.20284581184387\n",
            "  time_total_s: 142.20284581184387\n",
            "  timestamp: 1603031213\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00002\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m [20000] loss: 52.593\n",
            "\u001b[2m\u001b[36m(pid=20340)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=20345)\u001b[0m Finished Training\n",
            "Result for train_a2047_00011:\n",
            "  date: 2020-10-18_17-56-53\n",
            "  done: false\n",
            "  experiment_id: 4c8a59e97e5049e1b330fde47c09dbf3\n",
            "  experiment_tag: 11_batch_size=10,h1=64,h2=32,lr=0.0094289,momentum=0.64279\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 35.99527486014366\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20346\n",
            "  time_since_restore: 141.80535197257996\n",
            "  time_this_iter_s: 141.80535197257996\n",
            "  time_total_s: 141.80535197257996\n",
            "  timestamp: 1603031213\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00011\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m [20000] loss: 35.995\n",
            "\u001b[2m\u001b[36m(pid=20346)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_a2047_00001:\n",
            "  date: 2020-10-18_17-56-54\n",
            "  done: false\n",
            "  experiment_id: b9899752d2304218bddc169393f4c909\n",
            "  experiment_tag: 1_batch_size=1,h1=64,h2=8,lr=0.073799,momentum=0.67824\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 38.45061930382252\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20338\n",
            "  time_since_restore: 143.55269956588745\n",
            "  time_this_iter_s: 143.55269956588745\n",
            "  time_total_s: 143.55269956588745\n",
            "  timestamp: 1603031214\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00001\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m [20000] loss: 38.451\n",
            "\u001b[2m\u001b[36m(pid=20338)\u001b[0m Finished Training\n",
            "Result for train_a2047_00009:\n",
            "  date: 2020-10-18_17-56-54\n",
            "  done: false\n",
            "  experiment_id: 1d9ea3f051ec4086a385b12e472ef1c2\n",
            "  experiment_tag: 9_batch_size=1000,h1=128,h2=32,lr=0.015815,momentum=0.85233\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20339\n",
            "  time_since_restore: 143.51514506340027\n",
            "  time_this_iter_s: 143.51514506340027\n",
            "  time_total_s: 143.51514506340027\n",
            "  timestamp: 1603031214\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00009\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20339)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_a2047_00000:\n",
            "  date: 2020-10-18_17-56-55\n",
            "  done: false\n",
            "  experiment_id: 920709eae8064967bcccafb6461b71f7\n",
            "  experiment_tag: 0_batch_size=10,h1=128,h2=32,lr=1.1338e-05,momentum=0.5715\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 50.97551909852028\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20343\n",
            "  time_since_restore: 143.66589760780334\n",
            "  time_this_iter_s: 143.66589760780334\n",
            "  time_total_s: 143.66589760780334\n",
            "  timestamp: 1603031215\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=3\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=-1.2%): {RUNNING: 1, TERMINATED: 4} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-1.3%): {RUNNING: 3, TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=0.0%): {PENDING: 3, RUNNING: 8} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 24 (3 PENDING, 12 RUNNING, 9 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------|\n",
            "| train_a2047_00021 | PENDING    |                   |            1 |   32 |   32 | 0.0750197   |   0.673524 |          |\n",
            "| train_a2047_00022 | PENDING    |                   |           10 |    8 |  128 | 0.000600559 |   0.754024 |          |\n",
            "| train_a2047_00023 | PENDING    |                   |         1000 |   16 |  128 | 8.38624e-05 |   0.903744 |          |\n",
            "| train_a2047_00000 | RUNNING    | 192.168.1.4:20343 |           10 |  128 |   32 | 1.13376e-05 |   0.571503 |  50.9755 |\n",
            "| train_a2047_00005 | RUNNING    |                   |            1 |   32 |  128 | 0.00198688  |   0.776994 |          |\n",
            "| train_a2047_00007 | RUNNING    |                   |         1000 |   64 |  128 | 0.012411    |   0.644994 |          |\n",
            "| train_a2047_00012 | RUNNING    |                   |            1 |   16 |   64 | 2.95773e-05 |   0.987101 |          |\n",
            "| train_a2047_00013 | RUNNING    |                   |          100 |   64 |   16 | 2.01472e-05 |   0.673017 |          |\n",
            "| train_a2047_00014 | RUNNING    |                   |          100 |   32 |   32 | 0.000135655 |   0.721037 |          |\n",
            "| train_a2047_00015 | RUNNING    |                   |          100 |  128 |   32 | 0.0177869   |   0.944948 |          |\n",
            "| train_a2047_00016 | RUNNING    |                   |          100 |   64 |   16 | 0.0643478   |   0.887535 |          |\n",
            "| train_a2047_00017 | RUNNING    |                   |         1000 |  128 |    8 | 0.00029944  |   0.524602 |          |\n",
            "| train_a2047_00001 | TERMINATED |                   |            1 |   64 |    8 | 0.0737988   |   0.678238 |  38.4506 |\n",
            "| train_a2047_00002 | TERMINATED |                   |         1000 |    8 |   16 | 1.07313e-05 |   0.589369 |  52.5931 |\n",
            "| train_a2047_00003 | TERMINATED |                   |         1000 |   64 |   32 | 0.00486594  |   0.528756 | nan      |\n",
            "| train_a2047_00004 | TERMINATED |                   |         1000 |    8 |   16 | 0.000676748 |   0.921247 | 111.528  |\n",
            "| train_a2047_00006 | TERMINATED |                   |          100 |   16 |  128 | 0.00337964  |   0.717471 |  36.8515 |\n",
            "| train_a2047_00008 | TERMINATED |                   |          100 |   64 |   32 | 0.012294    |   0.52366  |  35.8471 |\n",
            "| train_a2047_00009 | TERMINATED |                   |         1000 |  128 |   32 | 0.0158148   |   0.852333 | nan      |\n",
            "| train_a2047_00010 | TERMINATED |                   |           10 |   16 |   16 | 4.4709e-05  |   0.865333 |  14.925  |\n",
            "| train_a2047_00011 | TERMINATED |                   |           10 |   64 |   32 | 0.0094289   |   0.642795 |  35.9953 |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "... 4 more trials not shown (3 RUNNING)\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m [20000] loss: 50.976\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=20343)\u001b[0m \n",
            "\n",
            "Result for train_a2047_00007:\n",
            "  date: 2020-10-18_17-56-55\n",
            "  done: false\n",
            "  experiment_id: 7b20abda43e74330b5bb5b0507a4b0ea\n",
            "  experiment_tag: 7_batch_size=1000,h1=64,h2=128,lr=0.012411,momentum=0.64499\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20347\n",
            "  time_since_restore: 143.75456857681274\n",
            "  time_this_iter_s: 143.75456857681274\n",
            "  time_total_s: 143.75456857681274\n",
            "  timestamp: 1603031215\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00007\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20347)\u001b[0m Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m Using backend: pytorch\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_a2047_00005:\n",
            "  date: 2020-10-18_17-56-58\n",
            "  done: false\n",
            "  experiment_id: 1d0b348e19054bbc9117e7e1c3733b9a\n",
            "  experiment_tag: 5_batch_size=1,h1=32,h2=128,lr=0.0019869,momentum=0.77699\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 12.658275332868099\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20342\n",
            "  time_since_restore: 146.8584566116333\n",
            "  time_this_iter_s: 146.8584566116333\n",
            "  time_total_s: 146.8584566116333\n",
            "  timestamp: 1603031218\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00005\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m [20000] loss: 12.658\n",
            "\u001b[2m\u001b[36m(pid=20342)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 1000] loss: 52.102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 1000] loss: 150.074\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 1000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 1000] loss: 94.412\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 1000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 1000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 1000] loss: 164.492\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 1000] loss: 41.386\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 1000] loss: 153.053\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 1000] loss: 38.613\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 1000] loss: 52.661\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 2000] loss: 22.829\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 2000] loss: 112.808\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 1000] loss: 157.661\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 2000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 2000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 2000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 2000] loss: 49.749\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 2000] loss: 109.434\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 2000] loss: 36.373\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 2000] loss: 255051953371873.281\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 2000] loss: 23.098\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 2000] loss: 38.663\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 3000] loss: 19.780\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 3000] loss: 66.522\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 2000] loss: 122.310\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 3000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 3000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 3000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 3000] loss: 43.285\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 3000] loss: 1894.757\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 3000] loss: 35.339\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 3000] loss: inf\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 3000] loss: 20.542\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 3000] loss: 39.495\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 4000] loss: 17.819\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 4000] loss: 59.182\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 3000] loss: 321.567\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 4000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 4000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 4000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 4000] loss: 162.871\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 4000] loss: 36.948\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 4000] loss: 38.068\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 4000] loss: 21.904\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 4000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 4000] loss: 39.606\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 5000] loss: 17.155\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 5000] loss: 59.797\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 4000] loss: 130.008\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 5000] loss: 192.767\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 5000] loss: 35.493\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 5000] loss: 30.443\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 5000] loss: 19.073\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 5000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 5000] loss: 38.136\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 6000] loss: 14.746\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 6000] loss: 55.935\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 5000] loss: 102.455\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 6000] loss: 34.861\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 6000] loss: 140.779\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 6000] loss: 26.952\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 6000] loss: 16.889\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 6000] loss: 37.102\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 7000] loss: 15.327\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 6000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 7000] loss: 56.787\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 6000] loss: 81.781\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 7000] loss: 37.368\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 7000] loss: 88.045\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 7000] loss: 23.444\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 7000] loss: 16.409\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 7000] loss: 37.894\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 8000] loss: 13.925\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 7000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 8000] loss: 55.639\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 7000] loss: 53.875\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 8000] loss: 35.786\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 8000] loss: 54.566\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 8000] loss: 15.157\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 8000] loss: 22.672\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 8000] loss: 38.776\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 8000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [ 9000] loss: 12.321\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [ 9000] loss: 50.196\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 8000] loss: 43.476\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [ 9000] loss: 36.418\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [ 9000] loss: 39.324\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [ 9000] loss: 16.132\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [ 9000] loss: 20.813\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [ 9000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [ 9000] loss: 36.259\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [10000] loss: 11.255\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [ 9000] loss: 68.790\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [10000] loss: 49.965\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [10000] loss: 36.236\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [10000] loss: 37.885\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [10000] loss: 16.526\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [10000] loss: 19.050\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [10000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [10000] loss: 36.859\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [11000] loss: 11.173\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [10000] loss: 35.682\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [11000] loss: 46.569\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [11000] loss: 35.739\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [11000] loss: 20.427\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [11000] loss: 38.894\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [11000] loss: 15.144\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [11000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [11000] loss: 37.260\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [12000] loss: 12.442\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [11000] loss: 36.132\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [12000] loss: 43.701\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [12000] loss: 37.627\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [12000] loss: 20.850\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [12000] loss: 13.366\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [12000] loss: 36.847\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [12000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [13000] loss: 10.602\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [12000] loss: 39.312\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [12000] loss: 37.046\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [13000] loss: 42.133\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [13000] loss: 35.175\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [13000] loss: 13.663\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [13000] loss: 36.855\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [13000] loss: 21.603\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [13000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [14000] loss: 11.239\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [13000] loss: 39.468\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [13000] loss: 34.955\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [14000] loss: 39.039\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [14000] loss: 36.466\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [14000] loss: 11.879\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [14000] loss: 20.192\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [14000] loss: 36.174\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [14000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [15000] loss: 10.942\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [14000] loss: 36.631\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [14000] loss: 38.469\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [15000] loss: 38.139\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [15000] loss: 35.506\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [15000] loss: 12.956\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [15000] loss: 19.808\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [15000] loss: 36.349\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [15000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [15000] loss: 37.896\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [16000] loss: 10.665\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [16000] loss: 38.084\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [15000] loss: 40.010\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [16000] loss: 37.093\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [16000] loss: 11.011\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [16000] loss: 16.540\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [16000] loss: 36.300\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [16000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [16000] loss: 37.787\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [17000] loss: 10.702\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [16000] loss: 39.826\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [17000] loss: 34.923\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [17000] loss: 37.776\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [17000] loss: 11.940\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [17000] loss: 15.234\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [17000] loss: 35.532\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [17000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [17000] loss: 38.550\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [18000] loss: 9.974\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [18000] loss: 33.200\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [17000] loss: 38.840\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [18000] loss: 35.789\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [18000] loss: 18.212\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [18000] loss: 11.616\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [18000] loss: 35.894\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [18000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [18000] loss: 38.629\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [19000] loss: 11.481\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [19000] loss: 34.198\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [18000] loss: 36.149\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [19000] loss: 37.259\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [19000] loss: 21.462\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [19000] loss: 11.883\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [19000] loss: 36.331\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [19000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [19000] loss: 37.278\n",
            "Result for train_a2047_00015:\n",
            "  date: 2020-10-18_17-59-16\n",
            "  done: false\n",
            "  experiment_id: 71b65986816e4515a697b1d70fe97809\n",
            "  experiment_tag: 15_batch_size=100,h1=128,h2=32,lr=0.017787,momentum=0.94495\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20452\n",
            "  time_since_restore: 141.24354314804077\n",
            "  time_this_iter_s: 141.24354314804077\n",
            "  time_total_s: 141.24354314804077\n",
            "  timestamp: 1603031356\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00015\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m [20000] loss: nan\n",
            "== Status ==\n",
            "Memory usage on this node: 6.4/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=3\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=8, Milestone (r)=27, completed=-1.9%): {RUNNING: 1, TERMINATED: 7} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-0.2%): {RUNNING: 11} \n",
            "Resources requested: 12/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 24 (12 RUNNING, 12 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------|\n",
            "| train_a2047_00012 | RUNNING    |                   |            1 |   16 |   64 | 2.95773e-05 |   0.987101 |          |\n",
            "| train_a2047_00013 | RUNNING    |                   |          100 |   64 |   16 | 2.01472e-05 |   0.673017 |          |\n",
            "| train_a2047_00014 | RUNNING    |                   |          100 |   32 |   32 | 0.000135655 |   0.721037 |          |\n",
            "| train_a2047_00015 | RUNNING    | 192.168.1.4:20452 |          100 |  128 |   32 | 0.0177869   |   0.944948 | nan      |\n",
            "| train_a2047_00016 | RUNNING    |                   |          100 |   64 |   16 | 0.0643478   |   0.887535 |          |\n",
            "| train_a2047_00017 | RUNNING    |                   |         1000 |  128 |    8 | 0.00029944  |   0.524602 |          |\n",
            "| train_a2047_00018 | RUNNING    |                   |          100 |  128 |   32 | 0.0401815   |   0.684186 |          |\n",
            "| train_a2047_00019 | RUNNING    |                   |         1000 |   32 |   64 | 0.094647    |   0.612066 |          |\n",
            "| train_a2047_00020 | RUNNING    |                   |           10 |  128 |    8 | 0.0128129   |   0.674578 |          |\n",
            "| train_a2047_00021 | RUNNING    |                   |            1 |   32 |   32 | 0.0750197   |   0.673524 |          |\n",
            "| train_a2047_00000 | TERMINATED |                   |           10 |  128 |   32 | 1.13376e-05 |   0.571503 |  50.9755 |\n",
            "| train_a2047_00001 | TERMINATED |                   |            1 |   64 |    8 | 0.0737988   |   0.678238 |  38.4506 |\n",
            "| train_a2047_00002 | TERMINATED |                   |         1000 |    8 |   16 | 1.07313e-05 |   0.589369 |  52.5931 |\n",
            "| train_a2047_00003 | TERMINATED |                   |         1000 |   64 |   32 | 0.00486594  |   0.528756 | nan      |\n",
            "| train_a2047_00004 | TERMINATED |                   |         1000 |    8 |   16 | 0.000676748 |   0.921247 | 111.528  |\n",
            "| train_a2047_00005 | TERMINATED |                   |            1 |   32 |  128 | 0.00198688  |   0.776994 |  12.6583 |\n",
            "| train_a2047_00006 | TERMINATED |                   |          100 |   16 |  128 | 0.00337964  |   0.717471 |  36.8515 |\n",
            "| train_a2047_00007 | TERMINATED |                   |         1000 |   64 |  128 | 0.012411    |   0.644994 | nan      |\n",
            "| train_a2047_00008 | TERMINATED |                   |          100 |   64 |   32 | 0.012294    |   0.52366  |  35.8471 |\n",
            "| train_a2047_00009 | TERMINATED |                   |         1000 |  128 |   32 | 0.0158148   |   0.852333 | nan      |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "... 4 more trials not shown (2 RUNNING, 2 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=20452)\u001b[0m Finished Training\n",
            "Result for train_a2047_00013:\n",
            "  date: 2020-10-18_17-59-16\n",
            "  done: false\n",
            "  experiment_id: ca923e5ebcd04e24a81b94f7cae3c797\n",
            "  experiment_tag: 13_batch_size=100,h1=64,h2=16,lr=2.0147e-05,momentum=0.67302\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 31.905716679573057\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20599\n",
            "  time_since_restore: 143.0763339996338\n",
            "  time_this_iter_s: 143.0763339996338\n",
            "  time_total_s: 143.0763339996338\n",
            "  timestamp: 1603031356\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00013\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m [20000] loss: 31.906\n",
            "\u001b[2m\u001b[36m(pid=20599)\u001b[0m Finished Training\n",
            "Result for train_a2047_00012:\n",
            "  date: 2020-10-18_17-59-16\n",
            "  done: false\n",
            "  experiment_id: c4e47e9fd18642bd91fb556e9e0f76ca\n",
            "  experiment_tag: 12_batch_size=1,h1=16,h2=64,lr=2.9577e-05,momentum=0.9871\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 10.243699727326632\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20487\n",
            "  time_since_restore: 144.4879608154297\n",
            "  time_this_iter_s: 144.4879608154297\n",
            "  time_total_s: 144.4879608154297\n",
            "  timestamp: 1603031356\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00012\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m [20000] loss: 10.244\n",
            "\u001b[2m\u001b[36m(pid=20487)\u001b[0m Finished Training\n",
            "Result for train_a2047_00016:\n",
            "  date: 2020-10-18_17-59-16\n",
            "  done: false\n",
            "  experiment_id: 168e948742484341a80a9f5eb26058ff\n",
            "  experiment_tag: 16_batch_size=100,h1=64,h2=16,lr=0.064348,momentum=0.88753\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20527\n",
            "  time_since_restore: 141.34990978240967\n",
            "  time_this_iter_s: 141.34990978240967\n",
            "  time_total_s: 141.34990978240967\n",
            "  timestamp: 1603031356\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00016\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20527)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [19000] loss: 37.991\n",
            "Result for train_a2047_00020:\n",
            "  date: 2020-10-18_17-59-17\n",
            "  done: false\n",
            "  experiment_id: d782eed71a8a4978ad5ce3eb1af1fee7\n",
            "  experiment_tag: 20_batch_size=10,h1=128,h2=8,lr=0.012813,momentum=0.67458\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.565705539226535\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20582\n",
            "  time_since_restore: 141.4854109287262\n",
            "  time_this_iter_s: 141.4854109287262\n",
            "  time_total_s: 141.4854109287262\n",
            "  timestamp: 1603031357\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00020\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m [20000] loss: 36.566\n",
            "\u001b[2m\u001b[36m(pid=20582)\u001b[0m Finished Training\n",
            "Result for train_a2047_00018:\n",
            "  date: 2020-10-18_17-59-18\n",
            "  done: false\n",
            "  experiment_id: 53afa43f454e48d7be707c6bdd9f6f40\n",
            "  experiment_tag: 18_batch_size=100,h1=128,h2=32,lr=0.040182,momentum=0.68419\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20548\n",
            "  time_since_restore: 143.046062707901\n",
            "  time_this_iter_s: 143.046062707901\n",
            "  time_total_s: 143.046062707901\n",
            "  timestamp: 1603031358\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00018\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20548)\u001b[0m Finished Training\n",
            "Result for train_a2047_00014:\n",
            "  date: 2020-10-18_17-59-18\n",
            "  done: false\n",
            "  experiment_id: e1e44e9482414eb5b4c3998aa9ee0d47\n",
            "  experiment_tag: 14_batch_size=100,h1=32,h2=32,lr=0.00013566,momentum=0.72104\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 40.328874995470045\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20415\n",
            "  time_since_restore: 144.1750111579895\n",
            "  time_this_iter_s: 144.1750111579895\n",
            "  time_total_s: 144.1750111579895\n",
            "  timestamp: 1603031358\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00014\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m [20000] loss: 40.329\n",
            "\u001b[2m\u001b[36m(pid=20415)\u001b[0m Finished Training\n",
            "Result for train_a2047_00022:\n",
            "  date: 2020-10-18_17-59-19\n",
            "  done: false\n",
            "  experiment_id: bb9c33a6e1ee4709b11672fd38565c74\n",
            "  experiment_tag: 22_batch_size=10,h1=8,h2=128,lr=0.00060056,momentum=0.75402\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 11.974321422994137\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20503\n",
            "  time_since_restore: 142.21405696868896\n",
            "  time_this_iter_s: 142.21405696868896\n",
            "  time_total_s: 142.21405696868896\n",
            "  timestamp: 1603031359\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00022\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m [20000] loss: 11.974\n",
            "\u001b[2m\u001b[36m(pid=20503)\u001b[0m Finished Training\n",
            "Result for train_a2047_00017:\n",
            "  date: 2020-10-18_17-59-19\n",
            "  done: false\n",
            "  experiment_id: eb78e3e12ae148559ff711565e2e54e8\n",
            "  experiment_tag: 17_batch_size=1000,h1=128,h2=8,lr=0.00029944,momentum=0.5246\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 37.07228740143776\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20427\n",
            "  time_since_restore: 144.44582343101501\n",
            "  time_this_iter_s: 144.44582343101501\n",
            "  time_total_s: 144.44582343101501\n",
            "  timestamp: 1603031359\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00017\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m [20000] loss: 37.072\n",
            "\u001b[2m\u001b[36m(pid=20427)\u001b[0m Finished Training\n",
            "Result for train_a2047_00019:\n",
            "  date: 2020-10-18_17-59-20\n",
            "  done: false\n",
            "  experiment_id: 84bdb10f823247078411c5c1fe244ba1\n",
            "  experiment_tag: 19_batch_size=1000,h1=32,h2=64,lr=0.094647,momentum=0.61207\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: .nan\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20466\n",
            "  time_since_restore: 143.56667971611023\n",
            "  time_this_iter_s: 143.56667971611023\n",
            "  time_total_s: 143.56667971611023\n",
            "  timestamp: 1603031360\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00019\n",
            "  \n",
            "Result for train_a2047_00023:\n",
            "  date: 2020-10-18_17-59-20\n",
            "  done: false\n",
            "  experiment_id: e95cab7e9d54450c9203ae9c2bbda2a1\n",
            "  experiment_tag: 23_batch_size=1000,h1=16,h2=128,lr=8.3862e-05,momentum=0.90374\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 36.58466723680496\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20924\n",
            "  time_since_restore: 139.56245017051697\n",
            "  time_this_iter_s: 139.56245017051697\n",
            "  time_total_s: 139.56245017051697\n",
            "  timestamp: 1603031360\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00023\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m [20000] loss: nan\n",
            "\u001b[2m\u001b[36m(pid=20466)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m [20000] loss: 36.585\n",
            "\u001b[2m\u001b[36m(pid=20924)\u001b[0m Finished Training\n",
            "Result for train_a2047_00021:\n",
            "  date: 2020-10-18_17-59-21\n",
            "  done: false\n",
            "  experiment_id: 597459deccc34969b15d1e24e792ed14\n",
            "  experiment_tag: 21_batch_size=1,h1=32,h2=32,lr=0.07502,momentum=0.67352\n",
            "  hostname: mahi-ROG-Strix-G531GT-G531GT\n",
            "  iterations_since_restore: 1\n",
            "  loss: 37.525093465566634\n",
            "  node_ip: 192.168.1.4\n",
            "  pid: 20530\n",
            "  time_since_restore: 144.57737946510315\n",
            "  time_this_iter_s: 144.57737946510315\n",
            "  time_total_s: 144.57737946510315\n",
            "  timestamp: 1603031361\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a2047_00021\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=3\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=15, Milestone (r)=9, completed=-2.7%): {RUNNING: 1, TERMINATED: 10} \n",
            "Resources requested: 1/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 24 (1 RUNNING, 23 TERMINATED)\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc               |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------|\n",
            "| train_a2047_00021 | RUNNING    | 192.168.1.4:20530 |            1 |   32 |   32 | 0.0750197   |   0.673524 |  37.5251 |\n",
            "| train_a2047_00000 | TERMINATED |                   |           10 |  128 |   32 | 1.13376e-05 |   0.571503 |  50.9755 |\n",
            "| train_a2047_00001 | TERMINATED |                   |            1 |   64 |    8 | 0.0737988   |   0.678238 |  38.4506 |\n",
            "| train_a2047_00002 | TERMINATED |                   |         1000 |    8 |   16 | 1.07313e-05 |   0.589369 |  52.5931 |\n",
            "| train_a2047_00003 | TERMINATED |                   |         1000 |   64 |   32 | 0.00486594  |   0.528756 | nan      |\n",
            "| train_a2047_00004 | TERMINATED |                   |         1000 |    8 |   16 | 0.000676748 |   0.921247 | 111.528  |\n",
            "| train_a2047_00005 | TERMINATED |                   |            1 |   32 |  128 | 0.00198688  |   0.776994 |  12.6583 |\n",
            "| train_a2047_00006 | TERMINATED |                   |          100 |   16 |  128 | 0.00337964  |   0.717471 |  36.8515 |\n",
            "| train_a2047_00007 | TERMINATED |                   |         1000 |   64 |  128 | 0.012411    |   0.644994 | nan      |\n",
            "| train_a2047_00008 | TERMINATED |                   |          100 |   64 |   32 | 0.012294    |   0.52366  |  35.8471 |\n",
            "| train_a2047_00009 | TERMINATED |                   |         1000 |  128 |   32 | 0.0158148   |   0.852333 | nan      |\n",
            "| train_a2047_00010 | TERMINATED |                   |           10 |   16 |   16 | 4.4709e-05  |   0.865333 |  14.925  |\n",
            "| train_a2047_00011 | TERMINATED |                   |           10 |   64 |   32 | 0.0094289   |   0.642795 |  35.9953 |\n",
            "| train_a2047_00012 | TERMINATED |                   |            1 |   16 |   64 | 2.95773e-05 |   0.987101 |  10.2437 |\n",
            "| train_a2047_00013 | TERMINATED |                   |          100 |   64 |   16 | 2.01472e-05 |   0.673017 |  31.9057 |\n",
            "| train_a2047_00014 | TERMINATED |                   |          100 |   32 |   32 | 0.000135655 |   0.721037 |  40.3289 |\n",
            "| train_a2047_00015 | TERMINATED |                   |          100 |  128 |   32 | 0.0177869   |   0.944948 | nan      |\n",
            "| train_a2047_00016 | TERMINATED |                   |          100 |   64 |   16 | 0.0643478   |   0.887535 | nan      |\n",
            "| train_a2047_00017 | TERMINATED |                   |         1000 |  128 |    8 | 0.00029944  |   0.524602 |  37.0723 |\n",
            "| train_a2047_00018 | TERMINATED |                   |          100 |  128 |   32 | 0.0401815   |   0.684186 | nan      |\n",
            "+-------------------+------------+-------------------+--------------+------+------+-------------+------------+----------+\n",
            "... 4 more trials not shown (4 TERMINATED)\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m [20000] loss: 37.525\n",
            "\u001b[2m\u001b[36m(pid=20530)\u001b[0m Finished Training\n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/15.5 GiB\n",
            "Using HyperBand: num_stopped=0 total_brackets=3\n",
            "Round #0:\n",
            "  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} \n",
            "  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} \n",
            "  Bracket(Max Size (n)=5, Milestone (r)=27, completed=-2.7%): {TERMINATED: 11} \n",
            "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/6.88 GiB heap, 0.0/2.34 GiB objects (0/1.0 accelerator_type:GTX)\n",
            "Result logdir: /home/mahi/ray_results/train\n",
            "Number of trials: 24 (24 TERMINATED)\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "| Trial name        | status     | loc   |   batch_size |   h1 |   h2 |          lr |   momentum |     loss |\n",
            "|-------------------+------------+-------+--------------+------+------+-------------+------------+----------|\n",
            "| train_a2047_00000 | TERMINATED |       |           10 |  128 |   32 | 1.13376e-05 |   0.571503 |  50.9755 |\n",
            "| train_a2047_00001 | TERMINATED |       |            1 |   64 |    8 | 0.0737988   |   0.678238 |  38.4506 |\n",
            "| train_a2047_00002 | TERMINATED |       |         1000 |    8 |   16 | 1.07313e-05 |   0.589369 |  52.5931 |\n",
            "| train_a2047_00003 | TERMINATED |       |         1000 |   64 |   32 | 0.00486594  |   0.528756 | nan      |\n",
            "| train_a2047_00004 | TERMINATED |       |         1000 |    8 |   16 | 0.000676748 |   0.921247 | 111.528  |\n",
            "| train_a2047_00005 | TERMINATED |       |            1 |   32 |  128 | 0.00198688  |   0.776994 |  12.6583 |\n",
            "| train_a2047_00006 | TERMINATED |       |          100 |   16 |  128 | 0.00337964  |   0.717471 |  36.8515 |\n",
            "| train_a2047_00007 | TERMINATED |       |         1000 |   64 |  128 | 0.012411    |   0.644994 | nan      |\n",
            "| train_a2047_00008 | TERMINATED |       |          100 |   64 |   32 | 0.012294    |   0.52366  |  35.8471 |\n",
            "| train_a2047_00009 | TERMINATED |       |         1000 |  128 |   32 | 0.0158148   |   0.852333 | nan      |\n",
            "| train_a2047_00010 | TERMINATED |       |           10 |   16 |   16 | 4.4709e-05  |   0.865333 |  14.925  |\n",
            "| train_a2047_00011 | TERMINATED |       |           10 |   64 |   32 | 0.0094289   |   0.642795 |  35.9953 |\n",
            "| train_a2047_00012 | TERMINATED |       |            1 |   16 |   64 | 2.95773e-05 |   0.987101 |  10.2437 |\n",
            "| train_a2047_00013 | TERMINATED |       |          100 |   64 |   16 | 2.01472e-05 |   0.673017 |  31.9057 |\n",
            "| train_a2047_00014 | TERMINATED |       |          100 |   32 |   32 | 0.000135655 |   0.721037 |  40.3289 |\n",
            "| train_a2047_00015 | TERMINATED |       |          100 |  128 |   32 | 0.0177869   |   0.944948 | nan      |\n",
            "| train_a2047_00016 | TERMINATED |       |          100 |   64 |   16 | 0.0643478   |   0.887535 | nan      |\n",
            "| train_a2047_00017 | TERMINATED |       |         1000 |  128 |    8 | 0.00029944  |   0.524602 |  37.0723 |\n",
            "| train_a2047_00018 | TERMINATED |       |          100 |  128 |   32 | 0.0401815   |   0.684186 | nan      |\n",
            "| train_a2047_00019 | TERMINATED |       |         1000 |   32 |   64 | 0.094647    |   0.612066 | nan      |\n",
            "| train_a2047_00020 | TERMINATED |       |           10 |  128 |    8 | 0.0128129   |   0.674578 |  36.5657 |\n",
            "| train_a2047_00021 | TERMINATED |       |            1 |   32 |   32 | 0.0750197   |   0.673524 |  37.5251 |\n",
            "| train_a2047_00022 | TERMINATED |       |           10 |    8 |  128 | 0.000600559 |   0.754024 |  11.9743 |\n",
            "| train_a2047_00023 | TERMINATED |       |         1000 |   16 |  128 | 8.38624e-05 |   0.903744 |  36.5847 |\n",
            "+-------------------+------------+-------+--------------+------+------+-------------+------------+----------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLY1ZriB-xFl"
      },
      "source": [
        "### Best Hyperparameter of Ray Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woYpslj28rBo",
        "outputId": "3584cd39-4e61-435f-cfaa-6670b5086501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best trial config: {'h1': 16, 'h2': 64, 'lr': 2.9577306339734983e-05, 'num_batch': 20000, 'momentum': 0.9871012279732239, 'batch_size': 1}\n",
            "Best trial final validation loss: 10.243699727326632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B9pMxez-1fE"
      },
      "source": [
        "### Testing the Best of RayTune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRMTHZQoLzJj",
        "outputId": "d9aa78d6-9f7e-4c77-9114-464a23e14da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "l2 = test(best_trial.config)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1000] loss: 56.992\n",
            "[ 2000] loss: 27.107\n",
            "[ 3000] loss: 19.867\n",
            "[ 4000] loss: 17.406\n",
            "[ 5000] loss: 16.877\n",
            "[ 6000] loss: 16.603\n",
            "[ 7000] loss: 14.255\n",
            "[ 8000] loss: 14.378\n",
            "[ 9000] loss: 15.342\n",
            "[10000] loss: 12.868\n",
            "[11000] loss: 13.885\n",
            "[12000] loss: 11.768\n",
            "[13000] loss: 11.658\n",
            "[14000] loss: 10.750\n",
            "[15000] loss: 11.651\n",
            "[16000] loss: 12.002\n",
            "[17000] loss: 10.952\n",
            "[18000] loss: 11.181\n",
            "[19000] loss: 10.897\n",
            "[20000] loss: 10.713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOrmjWCG-7P7"
      },
      "source": [
        "### Plot and Comparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCo3utwFLzC3",
        "outputId": "6333af7e-6696-4a85-bf05-41e193efa2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_me([l,l2])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAq6UlEQVR4nO3deXwV9b3/8dcn+75BgLCEsLsgKkQUETdcqKLS3ltbf6211l/trV201latt721q9XWq221rbbeWtvban+1SnGXCloVEBBZBFkTtrAlIQGy53x/f8wEQkzCIck5J8m8n4/HPObMcs58Mhw+M+c738Wcc4iISHDExToAERGJLiV+EZGAUeIXEQkYJX4RkYBR4hcRCZiEWAcQjoEDB7qioqJYhyEi0qcsW7Zsn3Muv+36PpH4i4qKWLp0aazDEBHpU8ystL31KuoREQkYJX4RkYBR4hcRCRglfhGRgFHiFxEJGCV+EZGAUeIXEQmY/p34178Eb9wf6yhERHqV/p34Ny+E1+8DjTkgInJY/078OYXQWAM15bGORESk1+j/iR9gf7utlkVEAikgiX9rbOMQEelF+nniH+HNlfhFRA7r34k/JRtScpT4RURa6d+JH7ziHiV+EZHDgpH4K/VwV0SkRf9P/LlF3h2/6vKLiABBSPw5hdBUC4f2xToSEZFeIRiJH1TOLyLiC1DiVzm/iAgEIfFnqy6/iEhr/T/xp2RBaq4Sv4iIr/8nflBdfhGRVgKU+FXGLyICgUn8I1WXX0TEF5zE31QHh/bGOhIRkZgLSOJXXX4RkRYBS/wq5xcRCUjiV11+EZEWwUj8yZmQmqfELyJCUBI/qC6/iIgvWIlf/fKLiAQs8VdtU11+EQm84CT+3CKvLv/BPbGOREQkpoKT+FWXX0QEiHDiN7MSM1tlZivMbKm/Ls/MXjGzDf48N5IxHKa6/CIiQHTu+C9wzp3mnCv2l+8A5jvnxgHz/eXIU7/8IiJAbIp6rgIe918/DsyJylGTMyBtgBK/iARepBO/A142s2VmdqO/brBzrgzAnw9q741mdqOZLTWzpXv39lDnaqrLLyJCQoQ/f7pzbqeZDQJeMbN14b7ROfcI8AhAcXFxz9TBzCmE3Wt65KNERPqqiN7xO+d2+vM9wN+BqcBuMysA8OfRq1+ZUwj7t0EoFLVDioj0NhFL/GaWbmaZLa+BS4DVwFzgOn+364BnIxXDh+SMhOZ6OKS6/CISXJEs6hkM/N3MWo7zv865F83sHeApM7sB2Ap8PIIxHC1npDffvxUyh0TtsCIivUnEEr9zbjNwajvry4GZkTpup1o34hoxNSYhiIjEWnBa7kKrfvnViEtEgitYiT8pHdIGqkqniARasBI/qC6/iASeEr+ISMAEN/GrLr+IBFQwE39zAxzcHetIRERiIniJP7fIm6u4R0QCKniJXwOyiEjABS/xZ6suv4gEW/ASf1IapOfrjl9EAit4iR9UpVNEAk2JX0QkYIKb+KvUL7+IBFNwE39zAxzcFetIRESiLqCJv8ibq7hHRAIooIlfdflFJLgCmvhVl19EgiuYiT8xFdIH6Y5fRAIpmIkfVKVTRAJLiV9EJGACnvi3Qag51pGIiERVsBN/qBEOqC6/iARLcBN/7khvruIeEQmY4Cb+HCV+EQmm4Cb+7OHeXIlfRAImuIk/MRUyBqsRl4gETnATP6hKp4gEkhK/Er+IBIwSf9V21eUXkUBR4g81woGyWEciIhI1AU/8qtIpIsGjxA9K/CISKMdM/GY23czS/defNrP7zWxk5EOLAtXlF5EACueO/1dAjZmdCnwTKAX+ENGooiUxBTKGqC6/iARKOIm/yTnngKuAB51zDwKZ4R7AzOLN7F0zm+cv55nZK2a2wZ/ndi30HqIqnSISMOEk/gNmdifwaeA5M4sHEo/jGDcDa1st3wHMd86NA+b7y7GjxC8iARNO4v8EUA/c4JzbBQwD7gvnw81sOHA58NtWq68CHvdfPw7MCTfYiFBdfhEJmLDu+PGKeN4ws/HAacCfw/z8B/CeC4RarRvsnCsD8OeD2nujmd1oZkvNbOnevXvDPFwX5BRCqAmqd0buGCIivUg4if91INnMhuEVzVwP/P5YbzKz2cAe59yyrgTmnHvEOVfsnCvOz8/vykeEJ6fQm6u4R0QCIpzEb865GuBjwC+ccx8FTg7jfdOBK82sBPgLcKGZ/RHYbWYFAP58T5ci7ym5Rd5ciV9EAiKsxG9m04BPAc/56+KP9Sbn3J3OueHOuSLgk8A/nXOfBuYC1/m7XQc8e9xR9yTV5ReRgAkn8d8C3An83Tm3xsxGA69145j3ABeb2QbgYn85dhKSIbNAiV9EAiPhWDs45xYCC80s08wynHObga8ez0GccwuABf7rcmDm8YcaQTmFasQlIoERTpcNp5jZu8Bq4H0zW2Zm4ZTx9x2qyy8iARJOUc9vgFudcyOdc4XA14FHIxtWlLXU5W9uinUkIiIRF07iT3fOHS7T94tt0iMWUSzkFIJrhgOqyy8i/V84iX+zmX3bzIr86T+BLZEOLKpUl19EAiScxP85IB942p8GAp+NYEzRp375RSRAwqnVU0mbWjxm9iReHz79Q/ZwwJT4RSQQujoC17QejSLWVJdfRAIk2EMvtqYqnSISEB0W9ZjZ5I42cXz98cfMo69v5s1N+/j99VOPvXNOIWxbFPmgRERirLMy/p91sm1dTwcSCQ7Hgg/2UrLvEEUDj1EDNacQVv/Nq8sff8xHHyIifVaHRT3OuQs6m6IZZFddPmkoAM+tKjv2zi11+at3RDgqEZHY6tdl/MNyUplcmMM/3gujYZbq8otIQPTrxA8we9JQ1u06wMY9BzvfMVd1+UUkGPp94r98UgFmMG/lMe76s1SXX0SCIZzeOSe3M40xsz7xBHRwVgpnFOUxb2UZzrmOd0xIgqyhSvwi0u+Fc8f/MLAIeASvV8638YZSXG9ml0Qwth5zxaQCNu45yAe7D3S+o+ryi0gAhJP4S4DT/YHPpwCn4/XNfxFwbwRj6zGzJhYQZzDvvWPU7lHiF5EACCfxn+CcW9Oy4Jx7H+9CsDlyYfWs/Mxkpo0ZwLyVOzsv7skp9Kpzql9+EenHwkn8H5jZr8zsPH96GK+YJxlojHB8PWb2pKGUlNewZmd1xzsdrsu/PXqBiYhEWTiJ/7PARrxB178GbPbXNQJ9oiEXwKyTh5AQZ/yjs9o9qssvIgFwzMTvnKt1zv3MOfdR59wc59xPnXM1zrmQc+4YleN7j9z0JKaPHchzndXuUb/8IhIA4VTnnG5mr5jZejPb3DJFI7ieNntSAdsra3lve1X7O2QNA4tT4heRfi2cop7fAfcD5wBntJr6nEtOHkJSfBzzOurCISEJMlWXX0T6t3ASf5Vz7gXn3B7nXHnLFPHIIiA7NZFzxw/kuVVlhEIdFfeoSqeI9G/hJP7XzOw+M5vWuvVuxCOLkNmThlJWVcfyrZXt76DELyL9XDjdLpzpz4tbrXPAhT0fTuTNPHEQSQlxzFtZRnFR3od3yCmEVU9BcyPE94nxZkREjks4g633mSqb4chMSeSCCfk8t6qMb88+ifg4O3qHnEJwIajaDnmjYhOkiEgEdTb04qedc380s1vb2+6cuz9yYUXW7ElDeWnNbpZsqWDamAFHb2xdl1+JX0T6oc7K+FvGKszsYOqzZp44iNTE+Pa7alYjLhHp5zq843fO/caf3x29cKIjLSmBC08cxIurd3H3lSeTEN/q+pc9XHX5RaRfO2YZv5nlA58Hilrv75z7XOTCirwrJhXw3Moy3t5czoxx+Uc2xCd6DbmU+EWknwqnVs+zwBvAq0BzZMOJnvMnDCI9KZ5575UdnfhBVTpFpF8LJ/GnOeduj3gkUZaSGM/FJw3mxTW7+P6ciSQltCruySmELW/ELjgRkQgKpwHXPDO77Hg/2MxSzGyJmb1nZmvM7G5/fZ7f988Gf5573FH3kNmThlJV28ibG/cdvSGnEA7shKaG2AQmIhJB4ST+m/GSf62ZVZvZATPrpFP7w+qBC51zpwKnAbPM7CzgDmC+c24cMN9fjokZ4weSmZLw4a6aW+ryq19+EemHwumWOdM5F+ecS3XOZfnLWWG8z7XqtjnRnxxwFfC4v/5xYE7XQu++5IR4Lj15CK+s2U1dY6vHF6rSKSL9WDh3/JjZMDM728zObZnCfF+8ma0A9gCvOOcWA4Odc2UA/nxQF2PvEbMnFXCgvonX1+89slKJX0T6sXCqc/4E+ATwPkdq9Tjg9WO91znXDJxmZjnA381sYriBmdmNwI0AhYWF4b7tuE0fO5DctETmrSzjkpOHeCuzhoPFK/GLSL8UTq2eOcAE51x9Vw/inNtvZguAWcBuMytwzpWZWQHer4H23vMI8AhAcXFxJyOkd09ifByzJg7h2RU7qW1oJjUpHuITVJdfRPqtcIp6NuOVzx8XM8v37/Qxs1TgImAdMBe4zt/tOrx2AjE1e9JQahqaee2DVtcg1eUXkX4qnDv+GmCFmc3Hq6kDgHPuq8d4XwHwuJnF411gnnLOzTOzt4GnzOwGYCvw8a6F3nPOHJXHwIwk5q3cyWWnFHgrcwphy8LYBiYiEgHhJP65/nRcnHMrgdPbWV8OzDzez4ukhPg4PjKxgL8u28ah+ibSkxO8xF/t1+VPSIp1iCIiPSac/vgfP9Y+/cHsSQU8saiUV9fu5qrThvk1exxUbYMBY2IdnohIjzlmGb+ZbTGzzW2naAQXTWcU5TE4K5l5K8u8FarSKSL9VDhFPa2HXEzBK5NvZ8zCvi0uzrjslAL+tGgr1XWNZCnxi0g/FU7L3fJW0w7n3AP00fF2j2X2pKE0NId4Zc1urzqn6vKLSD8UTgOuya0W4/B+AfTpEbg6Mrkwh2E5qcxbuZN/mzIcslWXX0T6n3CKen7W6nUTUEIvqIIZCWbG5ZMKeOxfW9hf00BOzkglfhHpd8Ip6rmg1XQx8EXgjMiHFhuzJxXQFHK8tGaX94C3YhOEQrEOS0Skx3SY+M0sy8zuNLNfmtnF5vkysBG4OnohRtcpw7IpzEvzaveMnQmH9sKap2MdlohIj+nsjv8JYAKwCm/M3ZfxinjmOOeuikJsMWFmzJ5UwFubyikfeRkMOhle+xE0N8U6NBGRHtFZ4h/tnPusc+43wDV4D3VnO+dWRCWyGJo9aSjNIccLa/bAhXd5xT3v/TnWYYmI9IjOEn9jywu/e+UtzrkDkQ8p9k4syGR0fjrzVu6ECZfB0Mmw8CfQ1OUOSkVEeo3OEv+p/lCL1WZ2AJh0nEMv9llecc9QFm+pYM+BerjwP72uG5b/IdahiYh0W4eJ3zkX7w+12DLcYsLxDL3Y110xqQDn4PlVZTDmQig8G16/DxpqYh2aiEi3hDX0YhCNG5zJhMGZ/L/l2znU0Awzvw0Hd8M7v411aCIi3aLE34kbZoxi9Y5qLn3gdd5oGAdjZsK//hvq+nVJl4j0c0r8nbi6eARPfWEaSfFxXPu7JfzcXQ21FbD417EOTUSky5T4j2HqqDyev3kGXzx/DA+uy2KBTaXxjQehpiLWoYmIdIkSfxhSEuO5fdYJPHPTdJ7M/AzxjYd46dG72HtA1TtFpO9R4j8OpwzP5uc3f4qNgy9hRsXf+MT9z/L08u0452IdmohI2JT4j1NifBzjr/4RqXFN3Joyj1ufeo/rf/8OO/bXxjo0EZGwKPF3xcCx2GnXcHnDC9x7cR6LN1dwyf0LeWJRKaGQ7v5FpHdT4u+q827HnOPqmr/w8tfO5fTCXL79zGo++cgiNu89GOvoREQ6pMTfVTmFUHw9vPtHRrCLJ26Yyr3/Pol1u6r5yINv8OuFm2hqVj/+ItL7KPF3x4yvQ1wiLPgJZsbVxSN49dbzOH9CPve8sI45D7/J+zvV2EtEehcl/u7IHAJTPw8rn4Q96wAYlJXCrz89hYf+z2R2VdVx5S//xX0vraOusTnGwYqIeJT4u2v6LZCUAa/98PCqlrF7X/naecw5fRgPvbaJyx58g0Wby2MXp4iIT4m/u9IHwLSbYO1c2LniqE256Un89OOn8sQNU2kMhfjkI4u48+lVVNc1tv9ZIiJRoMTfE6Z9CVJyjrrrb23GuHxeuuVcPj9jFE++s5WLfrbQG8xdRCQGlPh7Qko2TL8ZNrwMWxe3u0taUgJ3XX4Sz3xpOgMykvnCE8v44h+Xsae6LsrBikjQKfH3lDO/AOn58M/vd7rbpOE5zP3ydL45awLz1+1h5v0L+cuSrer2QUSiRom/pySle9U7S96AzQs63TUxPo6bzh/LizfP4KSCLO54ehXXPLqILfsORSdWEQk0Jf6eNOV6yBoG//wBhHEHPzo/gz9//ix+/LFTWLOzmlkPvM7DCzbSqIZfIhJBSvw9KTEFzvsmbH8H1r8U1lvi4oxrphby6q3nccGEQdz74gdc9cs3WbW9KsLBikhQKfH3tNM+Bbmj4LUfQCj8O/fBWSn8+top/PrTk9l3sJ6rHvoXP3p+LbUNavglIj0rIVIfbGYjgD8AQ4AQ8Ihz7kEzywOeBIqAEuBq51xlpOKIuvhEOP9O+PuNsPZZOPmjx/X2WRMLmDZmIPe8sI5HXt/MHxeVkpWSSGpSPCmJ8aQmxpGaFE9qYoI/jyM1MZ6UpHhSE/0p6ci8MC+NScNzIvO3ikifZJGqTWJmBUCBc265mWUCy4A5wGeBCufcPWZ2B5DrnLu9s88qLi52S5cujUicERFqhl+dDS4ENy2CuPgufczizeW8sHoXNQ1N1DaGqG1opq6xmdrG5qNf+8v1Te3/wrhu2kjuvOxEUhK7FoeI9E1mtsw5V9x2fcTu+J1zZUCZ//qAma0FhgFXAef7uz0OLAA6Tfx9Tlw8XPAteOozsPIpOO2aLn3MmaMHcOboAWHv3xxy1Dd5F4GaBu+C8Jcl23jszS0sKankF9eczthBGV2KRUT6j4jd8R91ELMi4HVgIrDVOZfTalulcy63nffcCNwIUFhYOKW0tDTicfYo5+A358LBPfDvj0HR9JiF8s91u7ntryupbWjmu1eexNXFIzCzmMUjItHR0R1/xB/umlkG8DfgFudc2H0UO+cecc4VO+eK8/PzIxdgpJjBVb/0avr8/jJ47jaoj80ALReeMJgXbp7B6YU53P63VXzlz++qvyCRAIto4jezRLyk/yfn3NP+6t1++X/Lc4A9kYwhpgpOhS++BWfdBO/8Fh6eBptei0kog7NSeOKGM/nGpRN4YfUuLv/5G7y7tf88UxeR8EUs8ZtXlvA7YK1z7v5Wm+YC1/mvrwOejVQMvUJSOsz6MXzuJUhIhifmwNyvQF306+nHxxlfumAsT31hGqEQfPzXb/Pwgo0aJ1gkYCJZq+cc4A1gFV51ToBvAYuBp4BCYCvwcedcRWef1edq9XSksQ4W3gNvPggZQ2D2f8OEWTEJpaq2kW89vYrnVpVxztiB3H/1qQzKSolJLCISGR2V8Ufl4W539ZvE32LHcnj2y7BnDUz6BMy6B9Lyoh6Gc46/vLONu/+xhvSkBH569alcMGFQ1OMQkciI2cNdacewyXDjAq+h1+q/wUNT4f3ol3iZed1F/OPL55Cfmcz1//MOP5j3PvVNai0s0p8p8cdKQhKcfwfcuNDr2O2pz8CT13rVP6Ns3OBMnvnSdK49ayS//dcW/u1Xb6mnUJF+TIk/1oZMhP87Hy76rtex20NT4b0nw+rdsyelJMbz/TkT+c21U9hWUcvsn7/B08u3RzUGEYkOlfH3JnvXw7Nfgu1LYNyl3sPf7GFRD2Pn/lpu+csKlpRUMPOEQZw8LJshWSkUZKcwOCuFIdkp5KYlqhGYSC+nh7t9RagZljwCr97tdfh27m0wdDLkjYbMAoiLzo+0puYQD722iT8uLmXfwfoP/QBJSohjSFYKQ7JSGJydwpCsZIZkp3rrspMZnJXCoMwUkhL0o1IkVpT4+5qKzTD3q96IXi0SUrwun/NGQ94oGDDGfz3ae07Qxc7gjqWxOcSeA/Xsqqrzpuo6dlfXHbW8q7qOhjadxJnBqIHp3PmRE7n4pMERiU1EOqbE3xc5B1XbvItA+SZvXrHFm1dugaZWA7XHJ0Fu0ZELQcuUM9KrKpqSHbELgxeqY39NI2VV/kXBvzC8sLqM9bsPctGJg/nulScxPDctYjG0tr2yhp++9AErtu3nxnPH8IkzRhAfp6IpCRYl/v4mFIIDZVDRckHYfPSFobGmzRvMS/5peZCaB6m57bzObfM6D5IzvVv3LmpsDvHYv7bwwKsbcDhunjmeG84ZFbEioOq6Rh5+bROPvbkFA8YOymDNzmpOHZ7N966ayKkjciJyXJHeSIk/SJyDg7u9XwlV26G2Amoroaaindf7ob6TvvMyBsMlP4BTPt6tC8CO/bXcPXcNL7+/m3GDMvj+nImcdRxdTh9LY3OI/128lQfnb6DiUAMfO30YX790AkOzU5j73k5+8Nxa9h2s55qphXzjkgnkpif12LFFeislfulYc6N3MWjv4vD+M7BjGYy+AGbf7xUfdcP8tbv5r7lr2F5Zy8cmD+Nbl53IwIzkLn+ec46X39/NPS+sY8u+Q0wbPYC7Lj+RicOyj9rvQF0jD7y6gd+/VUJWSgK3zzqBq4tHEKfiH+nHlPila0LNsPQxr5ZRqBHO/Qac/VWvAVoX1TY084t/buDRNzaTlpTAN2dN4JozCo87Ca/Ytp8fPbeWJSUVjB2UwbcuO4ELJgzqtJrpul3VfOeZNSwpqeC0ETl8/6qJnDI8u8P9RfoyJX7pnuoyePF2r2uJ/BPhigeg8KxufeTGPQf4z2dWs2izl4R/MGfih+7U27Otoob7XvqAue/tZGBGEl+7eDyfKB5BQnx4zw2cczyzYgc/fG4d5Yfq+dSZhdx2yQRy0lT8I/2LEr/0jA9ehOdv82obTfms1+I49UMDqIXtSBJeS8WhBq47u4hbLx5PZkrih/atqm3k4dc28j9vlhAXB5+fMZovnDeGjOSujSBaVdvIf7+ynj+8XUJOWhJ3zDqBf58yXMU/0m8o8UvPqT8IC34Mi34FaQO88QYm/lu3Hv5W1TRy38vr+NPireRnJPOdK07i8lMKMDMamkL8aXEpD87fQFVtIx87fTi3XTqeguzU9j/MOdj7AWx5HWr2wZn/0Wnvp+/vrOY7z65maWklkwtz+N5V4f3y6O2cc1QcaiA9OYHkhDi1tA4gJX7peWXvwT9ugZ3LYcxMuPxnXsOyblixbT//+cwqVu+oZsa4gVwxaSgPL9hISXkN08cO4FuXncjJQ9skZee8dg1bXvenN+BQq87u0gd5sZ10ZYfHDYUcT7+7gx8/v5bKmgY+fdZIvn7JBLJTP/zLo7cKhRwf7D7Aki0VLN5SzpItFew72ABAUnwcWamJZKUmkJ2aSFZKojf3l49ed2Q5LyOpy7+oJPaU+CUyQs3esJLzv+89/D3vdjj7K153E13UHHI88XYJP3t5PQfqmxg3KINvXX4i54/PP3LXWrXDa9XckuyrtnnrM4bAqHNh1AxvXn8AnrkJdq2Ek+bAZT+FjI7HcK6qbeT+lz/giUWl5KYlcdMFYxmYkUTIOUIhcEDIOZxzhJx3zWlZdnjJN+S8/ZxzJMQZI/LSGDkgnRF5qSQn9FwjuqbmEO+XVbNkSwWLNlfwTkkFVbXeWMpDs1M4c/QAJg7Lpr6pmaraRqprm6iubaS6rpGq2kZ/XSPVdU00dzIK25j8dIpH5jGlKJcpI3MZPTBdvx76CCV+iayqHd7D37X/gEEnwRUPwoip3frIPdV1rNt1gLPHDCChtvzoRF+xydspNQ+KzvGT/XkwcNyHi5yaG+HNB2DhvV6DtI/ce8yiqdU7qvjOs6tZvnV/t/6G1sxgaHYqRQO9C0HRgJZ5OoV5aaQmdX5RaGgKsWrHfhZvqWDx5gqWlVZysL4JgKIBaUwdlceZowYwdVQeI/LCbyHtnONQg3dxqKo5cmGorm1kd3Udy7fuZ1lp5eGLSl56EpMLcykuyqV4ZC4Th2WTktgzFzTnHHsP1LOtsoZtFbVUHGpg8shcThmWrZbXXaDEL9Gx7nl4/htQvQOKr4eZ/wXJWV73Ek110FQPTbXevNGfH95W5w1P2Xq/6jIv4e953/v8pEwomu4n+nNh0Mnhd1y3Z613979zOZwwGy6/HzI77kMoFHJsragh5BxxZsSZYeYl8JbXR83h8H4YxBnUN4XYVlFDaXkNJeWHKC2vYcu+Q5SWH6KypvGo4w3JSmHkgDSKBqQzcqA3z0hO4N2t+1m8pZzlWyupa/T6Qxo3KMNL9KMHMLUojyHZkR02MxRybNp7kGWllSwtrWRZaeXhMRuS4uOYOCyL4qI8poz0fhV01jajuq6RbRVeYt9eWcPWihpvudJbbvkbW8tNS2TGuHzOG5/PuePzyc/setuPIFHil+ipPwiv/QgW/8pbdh/+jxy2hFSv2mjLHX3BqRDfjTLn5iZY9BD884eQmAof+Yk3/GUMii6qahoprThESXkNpfv8ebk333ew/vB+ZnDikCymjsrjrNF5nFGUx4BuNHrrKfsO1rPcvwgsLa1k1fYqGpq9f+uiAWlMGZnHiQWZ7D1Yz/aKWi/BV9awv80FLzMlgcK8NEbkpjEiL5XCvDSG+8uZKQks2lzOwvV7eX393sPPLE4emsX5E/I5b/wgTi/MITHMqrx9RU1DEyu27WdpSSWfOGMEg7s4HrYSv0TfzhVe0U98otezaEIKJCR7CTchudW6FEhstT2hzfZIdEW9b4M39sG2xd7YB1c8AFlDe+7znYPdq70isLEzj/uZx8H6JkrLD7G/ppGJQ7PJTuv9D5nrGptZs7OKpSVHfhVUHGogKT6O4bmpDM9LozAv1U/waYeTfbh/WyjkeL+smoXr97Lwg70s21pJc8iRmZzA9LEDOW+C92tgWE4Htb16sX0H673zVlLBO6WVrNlRRVPIYQaPXlvMRV3s3VaJX6StUDMs/g3M/56XmC/9IZx+bdfv/qvLYPMC2PRPb95Ss2jgeLjkhzDu4pj8sogV5xyVNY3kpCZGpG1EdV0jb23cd/hCsLPK66123KAMzhufz3kT8jmjKK/Hnj/0FOccpeU1LCmpYGlJBUtLKtncUmyWEMdpI3I4oyiX4qI8JhfmdqtmmRK/SEfKN8Hcr0DpmzDmQrji55Az4tjva6iB0rf8RP/akecQ6fkw+nzvsxJTvRpPFZu8/o4u/SEMPjmif04QOefYuOegdxFYv5fFmytoaA6RFB9HQY43YNDQnFSGZHsjyXkjyqVSkJNCXlpSRBvttdS+eqfljr6k8nBRXk5aIsUj8w4n+onDsnq05pcSv0hnQiFY+jt45b+8u/KLvwdTrj+6mCkUgl3vwabXvGS/bTE0N0B8Moyc5iX60RfA4IlHv6+pwfvsBfd4PaFO/gxccBdkDIr+3xkQNQ1NLN5cwaIt5ezcX8euqtrDY0U0Nh+d85Li4xicnUxBVqsLQ7Z3YcjPTKY55Khvaqa+MUR9U8h73RSirtGbe+vbrGsKUd/o1ZRataOKmoZmAEbkpXLGyDyKi7xkPyY/I6IXHSV+kXBUlngjn21ZCEUzvC4p9qz1Ev2WhVBT7u03+BQYc76X7AuneXf2x1JT4VUpfedR7znGjFvhrJu85xsSFaGQo/xQA2X+hWBXVZ0/95erveW2o8kdS2K8kZwQT3JCHCmJ3jwpIY705AROGZbtV32NfO2rtpT4RcLlHCz7Pbz8bWg44K3LGAJjLvDv6s/v3t36vg3wynfgg+chpxAuuhtO/migyv97s5auLsqq6th7sJ7EuDhSEuO8xJ4YR3KC97plXVJCXK9tY6DEL3K8qrZ7xTrDpsCgE3s+MW9eAC/d5dX+GXEmXPpjGD6lZ48hgdZR4u9flV9FelL2cJh8LQw+KTJ346PPhy+8Dlf+whsy87cXwt/+L+zf1vPHEmlFiV8kluLivYe9X10OM27z2j38stirCVR/MNbRRZ9z3rOQlt5V1z0PB/fGOqp+R0U9Ir3J/m0w/25Y9VdvvONzvgbZI/zGbEnePD6pzXKy3+AtGeISeuezgoZDcHCPP+32pz0fnh/a49WUaqvgNK8h3NiLYPgZ3eoEMEhUxi/Sl2xfCi/eCduXHN/7LO7oC0FylpcoR57tTXmjI3thcA72rffaRJS+7fWLdGAXNLT368W8Ng8Zg72H5e3N4xO9vpo2+tVnXbP3N40617sIjJ3pPSCXdinxi/Q1znmNyxoP+Z3W+VNzfauO7Fqvqz/S6V1zgzc/VA7bFh2phpox5MhFYOTZ3jCa3ekSo7kJdq/yGrKVvgVb3z5yrPRBXg+t2SNaJfRWST1twPH1u1RXBZsXwqb5sHH+ka64B473LgJjZnod+IVTtTYglPhFguqou/C3oORNOLDT25aSc/SFYMgxOsFrrPPu4lvu6LctPnI3n1sEhWd7jdlGTo/sr4uWv2njq95FoORf3sUvIcU7dkux0MDxXgzOecVN9dXeBaSuZV4F9VXtrPNfN9RASpbX/XeaP6XmeRetNH/espya4z2z6UWU+EXE4xzsLz1yl1761pHxDZIyvLv0kWd7CXTgBCh719/vbdix9EgZ/KCTvMZrLReNnuzk7ngd7j5jvncx2LfeW5820Osdtq7KKybqTHwSpGR7U3KWN09M8y4CNRVQW+H9mmnvGQQA5r2n7UUhOcM7r0np3ngQSen+coa/rc1yQkqPXTCV+EWkYwd2HX0h2LPm6O0WD0NP8xP9dK+r7E7GMY65/Vu9XwLbl3oto1sSeUq2dwefku392mm9PpwW1C2/HFouAjUVrS4K/rrW22orvVHgGg5CqCm82C2+1YUiA2Y/4BVhdUHUE7+ZPQbMBvY45yb66/KAJ4EioAS42jlXeazPUuIXibKaCti6yLtzLjjVe0CcnBHrqPq2pnqvim5Dy3TIvygc8pY/tM1/fe5tMOSULh0yFon/XOAg8IdWif9eoMI5d4+Z3QHkOuduP9ZnKfGLiBy/qLfcdc69DlS0WX0V8Lj/+nFgTqSOLyIi7Yt2y93BzrkyAH/eYU9XZnajmS01s6V796rlnohIT+m1XTY45x5xzhU754rz8/NjHY6ISL8R7cS/28wKAPz5nigfX0Qk8KKd+OcC1/mvrwOejfLxRUQCL2KJ38z+DLwNTDCz7WZ2A3APcLGZbQAu9pdFRCSKjqOjjOPjnLumg00zI3VMERE5tl77cFdERCKjT3TZYGZ7gdIuvn0gsK8Hw+lpiq97FF/3KL7u680xjnTOfahaZJ9I/N1hZkvba7nWWyi+7lF83aP4uq8vxNiWinpERAJGiV9EJGCCkPgfiXUAx6D4ukfxdY/i676+EONR+n0Zv4iIHC0Id/wiItKKEr+ISMD0m8RvZrPM7AMz2+gP8tJ2u5nZz/3tK81schRjG2Fmr5nZWjNbY2Y3t7PP+WZWZWYr/Ok70YrPP36Jma3yj/2hUW9ifP4mtDovK8ys2sxuabNPVM+fmT1mZnvMbHWrdXlm9oqZbfDnuR28t9PvagTju8/M1vn/fn83s5wO3tvpdyGC8X3XzHa0+je8rIP3xur8PdkqthIzW9HBeyN+/rrNOdfnJyAe2ASMBpKA94CT2uxzGfACYMBZwOIoxlcATPZfZwLr24nvfGBeDM9hCTCwk+0xO3/t/FvvwmuYErPzB5wLTAZWt1p3L3CH//oO4CcdxN/pdzWC8V0CJPivf9JefOF8FyIY33eB28L494/J+Wuz/WfAd2J1/ro79Zc7/qnARufcZudcA/AXvNG+WrsKbxhI55xbBOS0dBEdac65Mufccv/1AWAtMCwax+5BMTt/bcwENjnnutqSu0e4ro8wF853NSLxOededs61jPi9CBje08cNVwfnLxwxO38tzMyAq4E/9/Rxo6W/JP5hwLZWy9v5cGINZ5+IM7Mi4HRgcTubp5nZe2b2gpmdHN3IcMDLZrbMzG5sZ3uvOH/AJ+n4P1wszx+EN8JcbzmPn8P7BdeeY30XIunLflHUYx0UlfWG8zcD2O2c29DB9liev7D0l8Rv7axrW081nH0iyswygL8BtzjnqttsXo5XfHEq8AvgmWjGBkx3zk0GPgJ8yczObbO9N5y/JOBK4K/tbI71+QtXbziPdwFNwJ862OVY34VI+RUwBjgNKMMrTmkr5ucPuIbO7/Zjdf7C1l8S/3ZgRKvl4cDOLuwTMWaWiJf0/+Sce7rtdudctXPuoP/6eSDRzAZGKz7n3E5/vgf4O95P6tZiev58HwGWO+d2t90Q6/PnC2eEuVh/D68DZgOfcn6BdFthfBciwjm32znX7JwLAY92cNxYn78E4GPAkx3tE6vzdzz6S+J/BxhnZqP8u8JP4o321dpc4DN+7ZSzgKqWn+WR5pcJ/g5Y65y7v4N9hvj7YWZT8f5tyqMUX7qZZba8xnsIuLrNbjE7f610eKcVy/PXSjgjzIXzXY0IM5sF3A5c6Zyr6WCfcL4LkYqv9TOjj3Zw3JidP99FwDrn3Pb2Nsby/B2XWD9d7qkJr9bJerwn/nf56/4D+A//tQEP+dtXAcVRjO0cvJ+jK4EV/nRZm/i+DKzBq6WwCDg7ivGN9o/7nh9Drzp//vHT8BJ5dqt1MTt/eBegMqAR7y70BmAAMB/Y4M/z/H2HAs939l2NUnwb8crHW76Dv24bX0ffhSjF94T/3VqJl8wLetP589f/vuU712rfqJ+/7k7qskFEJGD6S1GPiIiESYlfRCRglPhFRAJGiV9EJGCU+EVEAkaJX0QkYJT4RUQC5v8DLZcx4/GBTjUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[14.140532826066018, 10.712656000852585]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}